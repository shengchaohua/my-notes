# 简介

Redis（Remote Dictionary Service，远程字典服务）是一个非关系型的、基于内存的键值数据库，可以存储键和值之间的映射。键的类型只能为字符串，值支持五种数据类型：字符串String、列表List、集合Set、散列表Hash、有序集合Sorted Set。

Redis主要用来做缓存，而且支持很多特性：

-   Redis有丰富的数据类型。MemCached缓存支持字符串类型，键和值都是字符串。
-   Redis使用内存存储数据，数据读取和写入速度非常快。
-   Redis支持持久化，也就是可以把将内存中的数据持久化到硬盘中。
-   Redis支持集群模式来扩展读性能。

除了做缓存之外，Redis 也可以用来做分布式锁，甚至是消息队列。

## 为什么要用缓存？

缓存的基本思想其实很简单，就是用空间换时间，可以提高系统的性能。通常的做法是在关系型数据库（比如MySQL）之上增加了缓存，把用户经常访问的热点数据保存在缓存中，提高用户的请求速度。

使用缓存的主要优点有：

-   高性能：提高系统的性能，因为访问缓存速度比较快。
-   高并发：提高系统的并发量，因为缓存支持的并发量要高于关系型数据库。关系型数据库（比如MySQL）支持的QPS最高大概在1w 左右，而Redis 很容易达到 10w+。所以，直接操作缓存能够承受的请求数量远远大于直接访问数据库。

使用缓存也会带来一些问题：

-   系统复杂性增加：需要维护缓存和数据库的数据一致性、维护热点缓存等。
-   系统开发成本往往会增加：比如Redis是一个单独的缓存服务，部署需要花费相应的成本。

## 缓存分类

根据缓存和应用程序是否属于同一个进程，可以把缓存分为本地缓存和分布式缓存。基于本地缓存和分布式缓存，又衍生出了多级缓存的概念。

### 本地缓存

本地缓存是指在和应用程序在相同的进程中进行缓存读写操作。

优点：

-   本地缓存不需要远程网络请求，没有额外的性能消耗，所以读取速度快。

缺点：

-   本地缓存容量有限，因此不能进行大数据量存储。
-   数据会随着应用程序的重启而丢失。
-   本地缓存只在当前服务有效。如果应用程序如果使用集群部署，相同的服务可能部署在不同的机器上，那么不同机器之间的缓存无法共用，会造成缓存浪费。

### 分布式缓存

分布式缓存是独立部署的服务进程，和应用程序没有部署在同一台服务器上，所以分布式缓存的读写操作需要通过远程网络请求来完成。

优点：

-   分布式缓存是独立部署的进程，拥有自身独自的内存空间，不需要占用应用程序进程的内存空间，并且还支持横向扩展的集群方式部署，所以可以进行大数据量存储。
-   数据不会随着应用程序重启而丢失。分布式缓存拥有自身独立的内存空间，不会受到应用程序进程重启的影响。在应用程序重启时，分布式缓存的存储数据仍然存在。
-   数据集中存储，保证数据的一致性。应用程序如果使用集群部署，每个部署节点都会访问同一个分布式缓存进行读写操作。
-   分布式缓存一般支持数据副本机制，实现读写分离，可以解决高并发场景中的数据读写性能问题。

目前使用比较多的分布式缓存主要是 Memcached 和 Redis。分布式缓存刚开始兴起的时候，Memcached 比较常用。但是，随着 Redis 的发展，大家都慢慢转而使用更加强大的 Redis 。

Memcached 和 Redis的共同点有：

-   都是基于内存的数据库，一般都用来当做缓存使用。
-   都有过期策略。
-   两者的性能都非常高。

Memcached 和 Redis的不同点有：

-   Redis 支持更丰富的数据类型。Redis 不仅仅支持简单的 k/v 类型的数据，同时还支持列表List、集合Set、哈希表Hash 、有序集合Sorted Set等数据类型。Memcached 只支持最简单的 k/v 数据类型。
-   Redis 支持数据的持久化，可以把内存中的数据保存在磁盘中；重启的时候可以加载磁盘中的数据进行使用，而 Memecache 不支持持久化，只是把数据全部存在内存中。
-   Redis 有灾难恢复机制。 因为可以把缓存中的数据持久化到磁盘上。
-   Redis支持内存淘汰。Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。
-   Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。
-   Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型 （Redis 6.0 引入了多线程 IO ）。
-   Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。
-   Memcached过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。

## 缓存读写模式

### 旁路缓存模式

在旁路缓存模式中，服务端需要同时维系数据库和缓存，并且是以数据库的结果为准。

-   读数据时，先从缓存中读取数据，如果存在，则直接返回；如果不存在，就去数据库中查询，写入到缓存后在返回。
-   写数据时，先更新数据库，成功后再删除缓存。

旁路缓存模式可以说是最常用的一个缓存读写模式，比较适合读请求比较多的场景。在这种模式下可以尽可能的保证缓存的一致性，适合对一致性要求较高的场景。

另外，旁路缓存模式有首次请求数据一定不在缓存的问题，对于热点数据可以提前放入缓存中。

### 读写穿透模式

在旁路缓存模式中，业务应用需要同时维护数据库和缓存两个数据存储。

在读写穿透模式中，服务端封装了所有的数据处理细节：

-   读数据时，先从缓存中读取数据，如果存在，就直接返回；如果不存在，就去数据库中查询，写入到缓存后在返回。
-   写数据时，先查缓存，如果缓存中不存在，直接更新数据库。如果缓存中存在，就先更新缓存，然后缓存负责更新数据库。

存储服务封装了所有的数据处理细节，业务应用端代码只用关注业务逻辑本身，系统的隔离性更佳。

### 异步缓存写入模式

异步缓存写入模式类似于读写穿透模式。在异步缓存写入模式下，更新数据时只更新缓存，不直接更新数据库，通过异步的方式将缓存结果合并后再更新到数据库。

这种方式的特点是效率非常高，但不是强一致性，甚至会丢失数据，适用于访问量、点赞数等对于性能要求高，但一致性要求不高的场景。

### 数据库和缓存之间的一致性问题？

> [https://zhuanlan.zhihu.com/p/408515044](https://zhuanlan.zhihu.com/p/408515044 "https://zhuanlan.zhihu.com/p/408515044")

保证数据库和缓存之间的数据一致性并不容易。另外，一致性也可以分为强一致性和弱一致性。

如果要保证强一致性，就需要在更新数据库时同时更新缓存，如果更新缓存失败就需要返回错误，甚至要回滚数据库，这增加了系统的复杂性。

所以，只能保证弱一致性，通常是最终一致性。

-   在更新数据库时同时，同时写入缓存。如果写入失败，不返回错误，而是直接忽略。
-   可以在更新完数据后，写一条数据更改的消息，接收消息的处理器可以异步地写入缓存。但是，这种方案同样增加了系统的复杂性，不推荐。
-   可以通过 canel 工具订阅数据库的 binlog，异步地写入缓存。

另外，因为缓存空间是比较昂贵的，所以应该尽可能提高缓存的利用率，而一旦数据库更新数据就更新缓存则不利于这一点。

通常来说，旁路缓存模式是一个比较好的模式，可以保证一定的一致性，而且缓存利用率比较高，因为缓存中只保留最近访问的「热数据」。

-   读数据时，先从缓存中读取数据，如果存在，则直接返回；如果不存在，就去数据库中查询，写入到缓存后在返回。
-   写数据时，先更新数据库，成功后再删除缓存。

#### 问题

1）在旁路缓存模式中，写操作为什么是“先更新数据库，成功后再删除缓存”，而不是“先更新数据库，成功后直接更新缓存”或“先更新缓存，成功后直接更新数据库”？

a）先更新缓存，成功后直接更新数据库。

如果缓存更新成功了，但数据库更新失败，那么此时缓存中是最新值，但数据库中是「旧值」。

虽然此时读请求可以命中缓存，拿到正确的值，但是，一旦缓存「失效」，就会从数据库中读取到「旧值」，重建缓存也是这个旧值。

这时用户会发现自己之前修改的数据又「变回去」了，对业务造成影响。

b）先更新数据库，成功后直接更新缓存。

如果数据库更新成功了，但缓存更新失败，那么此时数据库中是最新值，缓存中是「旧值」。

之后的读请求读到的都是旧数据，只有当缓存「失效」后，才能从数据库中得到正确的值。

这时用户会发现，自己刚刚修改了数据，但却看不到变更，一段时间过后，数据才变更过来，对业务也会有影响。

#### 总结

我们引入缓存的目的是什么？**性能**！

一旦我们决定使用缓存，那必然要面临一致性问题。性能和一致性就像天平的两端，无法做到都满足要求。而且，当操作数据库和缓存完成之前，只要有其它请求可以进来，都有可能查到「中间状态」的数据。

所以如果非要追求强一致，那必须要求所有更新操作完成之前期间，不能有「任何请求」进来。此时可以通过加「分布锁」的方式来实现，但我们也要付出相应的代价，甚至很可能影响程序性能。

总结，既然决定使用缓存，就必须容忍「一致性」问题，我们只能尽可能地去降低问题出现的概率。

# 基本数据类型

## 字符串 String

> [https://redis.io/docs/data-types/strings/](https://redis.io/docs/data-types/strings/ "https://redis.io/docs/data-types/strings/")

字符串 String 可以用来存储字节序列，包括文本、序列化对象和二进制数组。字符串也可以用来保存数字，并且支持数字加减、按位运算等操作。默认情况下，单个 Redis 字符串最大为512MB。

String 底层是简单动态字符串（Simple Dynamic String，SDS）。相比于 C 的原生字符串，SDS 获取字符串长度复杂度为 `O(1)`（C 字符串为 `O(N)`）。

应用场景：

-   计数：比如用户的访问次数、热点文章的点赞转发数量等。
-   缓存不可变的数据：对于程序中不可变的数据，可以序列化后写入缓存，减少数据库查询次数。

### 常用命令

1）SET：设置一个字符串值。

2）GET：查询一个字符串值。

3）SETNX：仅当键不存在时才设置一个字符串值，用于实现锁。SETNX 无法同时设置过期时间，因此该命令已经被废弃。要想同时实现这两点，可以使用SET 命令和 NX 参数作为替代。

4）INCRBY：当值是数字时，自动加1。

### 演示

1）字符串的基本操作

```bash
127.0.0.1:6379> set key value
OK
127.0.0.1:6379> get key 
"value"
127.0.0.1:6379> exists key
(integer) 1
127.0.0.1:6379> mset key1 value1 key2 value2 # 批量设置 key-value 类型的值
OK
127.0.0.1:6379> mget key1 key2 # 批量获取多个 key 对应的 value
1) "value1"
2) "value2"
```

2）实现计数器

```bash
127.0.0.1:6379> set number 1
OK
127.0.0.1:6379> incr number
(integer) 2
127.0.0.1:6379> get number
"2"
127.0.0.1:6379> decr number
(integer) 1
127.0.0.1:6379> get number
"1"
```

3）设置过期

```bash
127.0.0.1:6379> expire key 60 # 数据在 60s 后过期
(integer) 1
127.0.0.1:6379> ttl key
(integer) 56
```

## 列表 List

列表 List 是字符串值的链表。链表是一种常见的数据结构，特点是数据插入和删除容易，但是随机访问困难。List 底层是双向链表，支持反向查找和遍历，更方便操作。

在 Redis 3.2 版本以前，列表  List 底层的数据结构是压缩列表 ziplist 和双向链表 LinkedList。从 Redis3.2 版本开始，列表 List 底层的数据结构变为快速列表 quicklist，也就是压缩列表 ziplist 和双向链表 LinkedList 的组合。

应用场景：

-   实现栈和队列。
-   为后台工作系统构建队列管理，即消息队列。

常用命令：

-   RPUSH：在右边（Right）插入一个元素。
-   RPOP：在右边（Right）弹出一个元素。
-   LPUSH：在左边（Left）插入一个元素。
-   LPOP：在左边（Left）弹出一个元素。

### 演示

1）实现队列

```bash
127.0.0.1:6379> rpush myList value1 # 向 list 的头部（右边）添加元素
(integer) 1
127.0.0.1:6379> rpush myList value2 value3 # 向list的头部（最右边）添加多个元素
(integer) 3
127.0.0.1:6379> lpop myList # 将 list的尾部(最左边)元素取出
"value1"
127.0.0.1:6379> lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end
1) "value2"
2) "value3"
127.0.0.1:6379> lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一
1) "value2"
2) "value3"
```

2）实现栈

```bash
127.0.0.1:6379> rpush myList2 value1 value2 value3
(integer) 3
127.0.0.1:6379> rpop myList2 # 将 list的头部(最右边)元素取出
"value3"
```

### 底层实现和原理

> [https://zhuanlan.zhihu.com/p/375414918](https://zhuanlan.zhihu.com/p/375414918 "https://zhuanlan.zhihu.com/p/375414918")

在较早版本的 Redis 中，List 有两种底层实现：

-   当列表对象中元素的长度比较小或者数量比较少的时候，采用压缩列表 ziplist 来存储。
-   当列表对象中元素的长度比较大或者数量比较多的时候，则会转而使用双向链表LinkedList 来存储。

两者各有优缺点：

-   ziplist 的优点是内存紧凑，访问效率高，缺点是更新效率低，并且数据量较大时，可能导致大量的内存复制。
-   LinkedList 的优点是节点修改的效率高，但是需要额外的内存开销，并且节点较多时，会产生大量的内存碎片。

为了结合两者的优点，在Redis 3.2 版本中，List 底层实现使用了新的数据结构——快速列表 quicklist。简单来说，快速列表quicklist是 LinkedList 与 ziplist 的结合：quicklist 包含多个内存不连续的节点，但每个节点本身就是一个 ziplist。

#### ziplist

> [https://mp.weixin.qq.com/s?\_\_biz=MzA4NTg1MjM0Mg==\&mid=2657261265\&idx=1\&sn=e105c4b86a5640c5fc8212cd824f750b#rd](https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==\&mid=2657261265\&idx=1\&sn=e105c4b86a5640c5fc8212cd824f750b#rd "https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==\&mid=2657261265\&idx=1\&sn=e105c4b86a5640c5fc8212cd824f750b#rd")

对于一个普通的双向链表，链表中每一项都占用独立的一块内存，各项之间用地址指针（或引用）连接起来。这种方式会带来大量的内存碎片，而且地址指针也会占用额外的内存。

ziplist（压缩列表）是Redis为了节约内存、提高存储效率而设计的一种线性数据结构。

ziplist是一个经过特殊编码的双向链表，本质上就是一个字节数组，占有连续的内存空间。

ziplist可以包含任意多个元素，每个元素可以是一个字节数组或一个整数，其中相邻的元素存放在连续的内存空间。

Redis的有序集合Zset、哈希Hash以及列表List都直接或者间接使用了压缩列表ziplist：

-   对于有序集合Zset或哈希Hash，当其中的元素数目比较少且元素都是短字符串时，Redis使用压缩列表作为底层数据存储。
-   对于列表List，Redis在3.2 版本及之后，使用快速链表quicklist数据结构作为List的底层实现，而快速链表quicklist就是双向链表与压缩列表ziplist的组合。

从宏观上看，ziplist的内存结构如下：

`<zlbytes><zltail><zllen><entry>...<entry><zlend>`

各个部分在内存上是前后相邻的，它们分别的含义如下：

-   `<zlbytes>`: 32bit，表示ziplist占用的字节总数（也包括`<zlbytes>`本身占用的4个字节）。
-   `<zltail>`: 32bit，表示ziplist表中最后一项（entry）在ziplist中的偏移字节数。`<zltail>`的存在，使得我们可以很方便地找到最后一项（不用遍历整个ziplist），从而可以在ziplist尾端快速地执行push或pop操作。
-   `<zllen>`: 16bit， 表示ziplist中数据项（entry）的个数。zllen字段因为只有16bit，所以可以表达的最大值为2^16-1。这里需要特别注意的是，如果ziplist中数据项个数超过了16bit能表达的最大值，ziplist仍然可以来表示。那怎么表示呢？这里做了这样的规定：如果`<zllen>`小于等于2^16-2（也就是不等于2^16-1），那么`<zllen>`就表示ziplist中数据项的个数；否则，也就是`<zllen>`等于16bit全为1的情况，那么`<zllen>`就不表示数据项个数了，这时候要想知道ziplist中数据项总数，那么必须对ziplist从头到尾遍历各个数据项，才能计数出来。
-   `<entry>`: 表示真正存放数据的数据项，长度不定。一个数据项（entry）也有它自己的内部结构，这个稍后再解释。
-   `<zlend>`: ziplist最后1个字节，是一个结束标记，值固定等于255。

上面的定义中还值得注意的一点是：`<zlbytes>`, `<zltail>`,`<zllen>`既然占据多个字节，那么在存储的时候就有大端（big endian）和小端（little endian）的区别，而 ziplist 采取的是小端模式来存储。

#### quicklist

quicklist的源代码如下所示：

```go
typedef struct quicklistNode {
    struct quicklistNode *prev;  // 上一个 ziplist 
    struct quicklistNode *next;  // 下一个 ziplist 
    unsigned char *zl;           // 数据指针，指向 ziplist 结构，或者 quicklistLZF 结构
    unsigned int sz;             // ziplist 占用内存长度（未压缩）
    unsigned int count : 16;     // ziplist 记录数量
    unsigned int encoding : 2;   // 编码方式，1 表示 ziplist ，2 表示 quicklistLZF
    unsigned int container : 2;  // 
    unsigned int recompress : 1;         // 临时解压，1 表示该节点临时解压用于访问
    unsigned int attempted_compress : 1; // 测试字段
    unsigned int extra : 10;             // 预留空间
} quicklistNode;

typedef struct quicklistLZF {
    unsigned int sz;    // 压缩数据长度
    char compressed[];  // 压缩数据
} quicklistLZF;

typedef struct quicklist {
    quicklistNode *head;        // 列表头部
    quicklistNode *tail;        // 列表尾部
    unsigned long count;        // 记录总数
    unsigned long len;          // ziplist 数量
    int fill : 16;              // ziplist 长度限制，每个 ziplist 节点的长度（记录数量/内存占用）不能超过这个值
    unsigned int compress : 16; // 压缩深度，表示 quicklist 两端不压缩的 ziplist 节点的个数，为 0 表示所有 ziplist 节点都不压缩
} quicklist;
```

quicklist的优点包括：

-   无缝切换：结合了 LinkedList 与 ziplist 的优点，无需在两种结构之间进行切换。
-   中间压缩：作为队列使用的场景下，list 中间的数据被访问的频率比较低，可以选择进行压缩以减少内存占用。

## 哈希表 Hash

哈希表 Hash 是一个 key-value 的映射表，底层实现是数组和链表。类似 Java 中的 HashMap，Hash适合用于存储有多种属性的结构化数据，比如用户信息，商品信息等。

哈希表 Hash 底层的数据结构是压缩列表（ziplist）、字典（dict）。

-   当数据较少时，Hash底层为一种称为ziplist的数据结构。
-   当数据增加到一定数量时，ziplist可能会转成一种称为dict的数据结构。

应用场景：应用程序中对象数据的存储。

常用命令包括：

-   HSET：创建或更新一个 Hash 类型的数据，并设置一个 Key-value 对。
-   HMSET：创建或更新一个 Hash 类型的数据，并设置多个 Key-value 对。

### 演示

1）基本操作

```bash
127.0.0.1:6379> hset userInfoKey name "guide"
OK
127.0.0.1:6379> hset userInfoKey description "dev"
OK
127.0.0.1:6379> hset userInfoKey age "24"
OK
127.0.0.1:6379> hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在
(integer) 1
127.0.0.1:6379> hget userInfoKey name # 获取存储在哈希表中指定字段的值。
"guide"
127.0.0.1:6379> hget userInfoKey age
"24"
127.0.0.1:6379> hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值
1) "name"
2) "guide"
3) "description"
4) "dev"
5) "age"
6) "24"
127.0.0.1:6379> hkeys userInfoKey # 获取 key 列表
1) "name"
2) "description"
3) "age"
127.0.0.1:6379> hvals userInfoKey # 获取 value 列表
1) "guide"
2) "dev"
3) "24"
127.0.0.1:6379> hset userInfoKey name "Guide" # 修改某个字段对应的值
127.0.0.1:6379> hget userInfoKey name
"Guide"
```

### 底层实现和原理

> [https://mp.weixin.qq.com/s?\_\_biz=MzA4NTg1MjM0Mg==\&mid=2657261265\&idx=1\&sn=e105c4b86a5640c5fc8212cd824f750b#rd](https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==\&mid=2657261265\&idx=1\&sn=e105c4b86a5640c5fc8212cd824f750b#rd "https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==\&mid=2657261265\&idx=1\&sn=e105c4b86a5640c5fc8212cd824f750b#rd")

#### ziplist

当Hash中的元素较少时，Redis使用ziplist作为Hash的底层存储。

因为当ziplist变得很大的时候，它有如下几个缺点：

-   每次插入或修改引发的realloc操作会有更大的概率造成内存拷贝，从而降低性能。
-   一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。
-   当ziplist数据项过多的时候，查找指定的数据项性能比较低，因为查找需要进行遍历。

所以，随着数据的插入，ziplist可能会转成dict。转变的条件由Redis配置来决定，如下所示：

```bash
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
```

对于上面的配置来说，解释：

-   当Hash中的数据项（即field-value对）的数目超过512时，也就是ziplist数据项超过1024（请参考t\_hash.c中的`hashTypeSet`函数）。
-   当hash中插入的任意一个value的长度超过了64时（请参考t\_hash.c中的`hashTypeTryConversion`函数）。

当上面两个条件之一满足的时候，ziplist会转成dict。

#### dict

TODO

## 集合 Set

> [https://redis.io/docs/data-types/sets/](https://redis.io/docs/data-types/sets/ "https://redis.io/docs/data-types/sets/")

集合 Set 是一个用于保存唯一字符串（成员）的无序集合，集合中的成员没有顺序关系。

类似于 Java 中的 HashSet，集合 Set 适合用来存储并跟踪唯一的元素、以及实现集合之间的交集、并集、差集等操作。

应用场景：需要存放的数据不能重复以及需要计算多个数据源的交集和并集等场景，比如歌曲收藏夹。

常用命令：

-   SADD：创建一个 Set 类型的数据，并添加一个或多个元素。
-   SPOP：从 Set 中弹出一个元素。
-   SMEMBERS：查看 Set 中的所有元素。

### 演示

```bash
127.0.0.1:6379> sadd mySet value1 value2 # 添加元素进去
(integer) 2
127.0.0.1:6379> sadd mySet value1 # 不允许有重复元素
(integer) 0
127.0.0.1:6379> smembers mySet # 查看 set 中所有的元素
1) "value1"
2) "value2"
127.0.0.1:6379> scard mySet # 查看 set 的长度
(integer) 2
127.0.0.1:6379> sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素
(integer) 1
127.0.0.1:6379> sadd mySet2 value2 value3
(integer) 2
127.0.0.1:6379> sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中
(integer) 1
127.0.0.1:6379> smembers mySet3
1) "value2"
```

## 有序集合 Sorted Set

> [https://juejin.cn/post/6844903446475177998](https://juejin.cn/post/6844903446475177998 "https://juejin.cn/post/6844903446475177998")

有序集合 Sorted Set 是一个用于保存唯一字符串（成员）的有序集合，集合中的成员有顺序关系。Sorted Set 通常也可以称为Zset。

和集合 Set 相比，有序集合为集合中每一个成员增加了一个对应的权重参数 score，使得集合中的元素能够按 score 进行有序排列。

有序集合底层的数据结构是压缩列表（ziplist）、字典（dict）和跳表（skip list）。

-   当数据较少时，有序集合底层为一种称为ziplist的数据结构。
-   当数据增加到一定数量时，ziplist可能会转成一种称为zset的数据结构，其中zset包含一个字典（dict）和一个跳表（skip list）。

应用场景：需要存放的数据不能重复，并且要求有序，比如实时排行榜。

常用命令：

-   ZADD：添加一个元素。
-   ZCARD：查看集合中的元素数量。
-   ZSCORE：查看某个元素的 score。

### 演示

```bash
127.0.0.1:6379> zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重
(integer) 1
127.0.0.1:6379> zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素
(integer) 2
127.0.0.1:6379> zcard myZset # 查看 sorted set 中的元素数量
(integer) 3
127.0.0.1:6379> zscore myZset value1 # 查看某个 value 的权重
"3"
127.0.0.1:6379> zrange  myZset 0 -1 # 顺序输出某个范围区间的元素，0 -1 表示输出所有元素
1) "value3"
2) "value2"
3) "value1"
127.0.0.1:6379> zrange  myZset 0 1 # 顺序输出某个范围区间的元素，0 为 start  1 为 stop
1) "value3"
2) "value2"
127.0.0.1:6379> zrevrange  myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start  1 为 stop
1) "value1"
2) "value2"
```

### 底层实现和原理

#### ziplist

> [https://mp.weixin.qq.com/s?\_\_biz=MzA4NTg1MjM0Mg==\&mid=2657261265\&idx=1\&sn=e105c4b86a5640c5fc8212cd824f750b#rd](https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==\&mid=2657261265\&idx=1\&sn=e105c4b86a5640c5fc8212cd824f750b#rd "https://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==\&mid=2657261265\&idx=1\&sn=e105c4b86a5640c5fc8212cd824f750b#rd")

当 Zset 中的元素较少时，Redis 使用 ziplist 作为 Zset 的底层存储。

因为当 ziplist 变得很大的时候，它有如下几个缺点：

-   每次插入或修改引发的 realloc 操作会有更大的概率造成内存拷贝，从而降低性能。
-   一旦发生内存拷贝，内存拷贝的成本也相应增加，因为要拷贝更大的一块数据。
-   当ziplist数据项过多的时候，查找指定的数据项性能比较低，因为查找需要进行遍历。

所以，随着数据的插入，ziplist可能会转成zset。转变的条件由Redis配置来决定，如下所示：

```
zset-max-ziplist-entries 128
zset-max-ziplist-value 64
```

对于上面的配置来说，解释：

-   当有序集合中的元素个数，即数据和 score对的数目超过128。
-   当有序集合中插入的任意一个数据的长度超过64。

当上面两个条件之一满足的时候，ziplist会转成zset。

#### zset和跳表

> [https://www.cnblogs.com/yuarvin/p/14755673.html](https://www.cnblogs.com/yuarvin/p/14755673.html "https://www.cnblogs.com/yuarvin/p/14755673.html")

zset 由一个字典（dict）和一个跳表（skip list）组成，其中dict用来查询数据到分数（score）的对应关系，而skiplist用来根据分数查询数据。

zset 的代码定义如下：

```c
typedef struct zset {
    dict *dict;
    zskiplist *zsl;
} zset;
```

跳表是一种比较优秀的动态数据结构，它允许快速查询，插入和删除一个有序连续元素的数据链表。平均查找、插入和删除的间复杂度都是都是`O(lgn)`。

跳表由多个层次的链表组成：

-   每层包含一个链表，而且每个链表都是有顺序的。
-   链表中的结点包含两个指针，一个指向同一层的下一个结点，另一个指向下一层的结点。需要注意的是，一个结点和其指向的下一层的结点的值是相同的。
-   第一层的链表包含了所有数据，往上每一层的链表都只包含了下一层的部分数据，一般是二分之一。上层的数据可以当作下一层的索引。

如下图所示：

![image_ZRFuES2xL4](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202311272141884.png)

解释：

-   第一层（最下层）的链表包含了所有数据，其余层只包含了部分数据。
-   链表中的结点包含两个指针：一个指向同一层的下一个结点，另一个指向下一层的结点。

跳表操作分析：

1）查找：

-   从最稀疏的顶层到包含所有数据的最底层，遍历当前层次的链表。
-   如果需要查找的数据落在当前结点和同一层的下一个结点之间，查找下一层。
-   重复该搜索过程，直到找到需要查找的数据。

2）插入：

-   插入数据需要借助查找，找到该数据在最底层待插入的位置，并在最底层插入该数据。
-   因为跳表有多层，不可能在每一层都插入数据。所以，接着按照投硬币的方式，往上建立索引层。
    -   投硬币：50%的概率在上层建立索引层，通过概率事件，避免某一段区间内节点过多，导致性能退化成数组`O(n)`。
    -   建立索引需要使用其他层的结点。所以在实际查找过程中，需要额外保存查询路径中，经过每层的最小&最大结点。

3）删除：删除数据也需要借助查找。如果可以找到，删除该数据及其他层的相同数据（如果有的话）。

问题：

1）为什么使用调表而是平衡树？

-   跳表结构简单，算法实现相比平衡树容易。
-   对于范围查找，跳表比平衡树简单。在平衡树上，在找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的结点。而在跳表中，只需要在找到小值之后，对第1层链表进行遍历即可。
-   对于插入和删除操作，跳表的代价比平衡树低。平衡树的插入和删除操作可能引发子树的调整，逻辑复杂；而跳表的插入和删除只需要修改相邻结点的指针，操作简单。
-   跳表占用空间比平衡树小。平衡树每个节点包含2个指针，而跳表平均每个结点的指针位`1/(1-p)`，少于2个

# 高级数据类型

## Bitmaps

> https://juejin.cn/post/7021822201779191815

Bitmaps 并不是一个数据类型，本质上还是一个 String，主要是定义了一个面向比特（bit）操作的集合。Bitmaps 可以称为位图，或者二进制位数组。

用途：用于大量数据去重，用户登录统计等需求。

Bitmaps 的操作可以分为两组：

- 对单个 bit 操作，例如把某个 bit 设置为0或者1，或者获取某bit的值。
- 对一组 bit 的操作，例如统计给定范围的 bit。

常用命令：

-   SETBIT：为指定偏移量上的二进制位 bit 设置值，偏移量从 0 开始计数，值只能为 0 或 1。返回原位置的值。
-   GETBIT：获取指定偏移量上的二进制位的值。
-   BITCOUNT：统计值为1的二进制位数量，范围可以指定。
-   BITOP：对多个位数组进行按位与、或、异或运算。

### 演示

```bash
127.0.0.1:6379> SETBIT first 0 1    # binary: 0000 0001
(integer) 0
127.0.0.1:6379> SETBIT first 3 1    # binary: 0000 1001
(integer) 0
127.0.0.1:6379> SETBIT first 0 0    # binary: 0000 1000
(integer) 1
127.0.0.1:6379> GETBIT first 0
(integer) 0
127.0.0.1:6379> GETBIT first 3
(integer) 1

127.0.0.1:6379> BITCOUNT first      # binary: 0000 1000
(integer) 1
127.0.0.1:6379> SETBIT first 0 1    # binary: 0000 1001
(integer) 0
127.0.0.1:6379> BITCOUNT first      # binary: 0000 1001
(integer) 2
127.0.0.1:6379> SETBIT first 1 1    # binary: 0000 1011
(integer) 0
127.0.0.1:6379> BITCOUNT first      # binary: 0000 1011
(integer) 3
```

### 实际应用

#### 数字去重

如果有 40 亿个数字（假设是10位的QQ号），如何去除重复的数字，相同数字只保留一个。内存限制 1G。

如果没有内存限制，直接把所有数字放进一个 SET 集合，即可达到去重目的。假设每个数字占 4 字节，大约需要 15GB （40亿 * 4 / 1024 / 1024 / 1024）内存，不满足内存要求。

使用位图，可以用数字作为偏移量，设置对应的二进制位为1，表示该数字出现。最后，统计二进制位为 1 的位置，即可得到去重后的所有数字。假设所有数字均不重复，位图大约需要  476.8MB（40亿 / 8 / 1024 / 1024）内存，可以满足内存要求。

#### 用户登录统计

某网站有大量用户，如何统计每日用户登录（或签到）的数量？

简单来说，使用 SET 集合可以统计用户登录数量，如果用户登录，就把 ID 放入集合。

和数字去重类似，使用位图也可以实现。通过把用户 ID 作为偏移量（也就是把每个偏移量标识为一个用户），如果用户登录，就把对应偏移量的二进制位设置为 1。统计二进制位为 1 的数量，即可得到用户登录的数量。

假设用户 ID 为 32 位，对比一下使用位图和 SET 集合的占用内存分别是多少？在用户总量为 1 亿的情况下，位图占用内存大约为12MB（1亿 / 8 / 1024 / 1024），使用 SET 集合大约为 381 MB。

缺点：假设某天只有一个用户签到，用户 ID=100000000（1 亿），那么会创建出比特位数等于 1 亿的位图，占用 12MB 内存。因此，位图适合数据比较连续的高频场景。

### 布隆过滤器

布隆过滤器一种基于位图的算法，用于快速检索一个元素是否可能存在于一个集合（Bitmaps）中。

它的基本原理是使用多个哈希函数，将一个元素映射成多个位，然后将这些位设置为 1。当查询一个元素时，如果发现这些位都是1，则认为元素**可能**存在于集合中，否则肯定不存在。

因为存在哈希冲突，布隆过滤器没办法判断一个元素一定存在，只能判断可能存在。如下图所示，

![在这里插入图片描述](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202401232151853.png)



要想降低这种误判概率，主要的办法就是降低哈希冲突的概率及引入更多的哈希算法。

因为布隆过滤器效率非常高，比较典型的使用场景有以下几个：

1、网页爬虫： 爬虫程序可以使用布隆过滤器来过滤掉已经爬取过的网页，避免重复爬取和浪费资源。

2、缓存系统： 缓存系统可以使用布隆过滤器来判断一个查询是否可能存在于缓存中，从而减少查询缓存的次数，提高查询效率。布隆过滤器也经常用来解决缓存穿透的问题。

3、分布式系统： 在分布式系统中，可以使用布隆过滤器来判断一个元素是否存在于分布式缓存中，避免在所有节点上进行查询，减少网络负载。

4、垃圾邮件过滤： 布隆过滤器可以用于判断一个邮件地址是否在垃圾邮件列表中，从而过滤掉垃圾邮件。

5、黑名单过滤： 布隆过滤器可以用于判断一个IP地址或手机号码是否在黑名单中，从而阻止恶意请求。

## HyperLogLog

HyperLogLog 本质是一种概率性统计算法，可以用来实现基数统计，也就是统计一个集合中有多少不重复的元素。

HyperLogLog 的优点是在**海量数据**的情况下，可以使用**很小的内存空间**进行统计。虽然 SET 数据结构也可以用来实现相同的任务，但是 SET 需要保存所有元素，对于海量数据场景，会消耗大量的内存。

需要注意的是，HyperLogLog 的统计并不是完全精确，也就是说 HyperLogLog 是在牺牲一定准确率的情况下，减少了使用的内存。HyperLogLog 可以在使用 12KB 内存的情况下，可以统计多达 2^64 个元素，并提供小于 1%（大约为0.81%）的标准错误概率，这样的错误概率通常是可以接受的。

用途：

- 统计注册 IP 数
- 统计每日访问 IP 数
- 统计页面实时 UV 数
- 统计在线用户数
- 统计用户每天搜索不同词条的个数

常用命令如下：

-   PFADD：用于添加一个元素到 HyperLogLog 统计中。
-   PFCOUNT：用于获取 HyperLogLog中 的唯一元素个数（近似值）。
-   PFMERGE：用执行多个 HyperLogLog 之间的合并操作。

演示：

```shell
127.0.0.1:6379> PFADD hll a b c d d c
(integer) 1
127.0.0.1:6379> PFCOUNT hll
(integer) 4
127.0.0.1:6379> PFADD hll e
(integer) 1
127.0.0.1:6379> PFCOUNT hll
(integer) 5
```

### 底层实现和原理

> https://juejin.cn/post/6844903785744056333
> https://zhuanlan.zhihu.com/p/650908870

HyperLogLog 使用了伯努利试验和极大似然估计理论，通过实验结果估计总的实验次数。	

在 Redis 中，HyperLogLog 底层使用了 16384 个桶记录结果，每个桶占 6 个比特位，用来记录一次估计出来的集合基数。所以，可以得出，HyperLogLog 底层数据占用内存为 12KB（16834 * 6 / 8 / 1024）。

```
  第0组     第1组                       .... 第16833组
[000 000] [000 000] [000 000] [000 000] .... [000 000]
```

当添加一个元素时，HyperLogLog 使用 Hash 函数对其计算出一个 64 位的哈希值，哈希值的前 50 位被看作一种实验结果，后 14 位被看作分桶。因为 14 个比特位最大可以表示 16384 （2^14），所以 HyperLogLog 底层数据结构总共分了 16384 个桶。

```
      50位              14位        
[00000000 ... 0000] [0000 00000000]
```

对于 Hash 值的前 50 位，只需要记录从右往左数第一个不是 0 的位数。因为位数最大为 50，用 6 个比特位就可以表示，所以每个桶的大小占 6 个比特。最后，把该位数存入通过 Hash 值的后 14 位计算出的桶中。 注意，如果桶中已有的数据更大，则不用存入。

举例，如果一个元素的哈希值为 [00001100 ... 1000] [0000 00001100]，则 HyperLogLog 底层数据的第 12 个桶会被记录为 4（二进制为 000100），其中 4 表示哈希值中前 50 个二进制位中从右往左数第一个为 1 的位数。因此这个桶估计出来的集合基数为 2^4。

由于每个桶都记录了估计出来的集合基数，HyperLogLog 会对所有桶使用调和平均数。如下图，其中 m 是桶数，$R_j$表示每个桶的估计值。

![img](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202401240903656.png)

偏差修正：在估算的计算公式中，const 变量不是一个定值，它会根据实际情况而设置。

最后，因为 HyperLogLog 通过 Hash 函数把一个元素转为 64 位的二进制，并记录到每个桶中，所以最多可以记录 2^64 个元素。

### 实际应用

#### 用户登录统计

和 Bitmaps 一样，HyperLogLog 也可以用来统计用户登录数量。不一样的是，Bitmaps 占用内存多，可以做到精确统计，甚至可以得到每个统计对象；HyperLogLog 占用内存小，但是无法精确统计，存在误差。

## GEO

GEO 数据类型在 Redis3.2 版本中引入，主要用于存储地理位置信息，并对存储的信息进行操作。

常用命令有：

- GEOADD：添加地理位置的坐标。
- GEOPOS：获取地理位置的坐标。
- GEODIST：计算两个位置之间的距离。
- GEORADIUS：根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。
- GEORADIUSBYMEMBER：根据储存在位置集合里面的某个地点获取指定范围内的地理位置集合。
- GEOHASH：返回一个或多个位置对象的 geohash 值。

# 事务

Redis的事务是通过MULTI，EXEC，DISCARD和WATCH这四个命令来完成。Redis的单个命令都是原子性的，所以这里确保事务性的对象是命令集合。Redis将命令集合序列化并确保处于一事务的命令集合连续且不被打断的执行。Redis不支持回滚的操作。

相关命令：

-   MULTI：用于标记事务块的开始。Redis会把后续的命令逐个放入队列中，然后使用EXEC命令原子化地执行这个命令序列。
-   EXEC：在一个事务中执行所有先前放入队列的命令，然后恢复正常的连接状态。
-   DISCARD：清除所有先前在一个事务中放入队列的命令，然后恢复正常的连接状态。
-   WATCH：当某个事务需要按条件执行时，就要使用这个命令将给定的键设置为受监控的状态。注：该命令可以实现redis的乐观锁。
-   UNWATCH：清除所有先前为一个事务监控的键。

举例：

```bash
TODO
```

Redis不支持事务回滚：

1.  大多数事务失败是因为语法错误或者类型错误，这两种错误，在开发阶段都是可以避免的。
2.  Redis为了性能方面就忽略了事务回滚。

# 持久化

持久化数据是指把内存中的数据写入到硬盘，其主要原因是为了防止数据的意外丢失，确保数据安全性。比如机器故障之后，我们可以借助持久化恢复数据。

不同于 Memcached 的很重要一点是，Redis 支持持久化，而且支持两种不同的持久化方式：

-   RDB 持久化：保存数据库的状态到一个二进制文件，即快照 snapshot。
-   AOF（Append-only file）持久化：以固定的格式把每一个命令保存到 AOF 文件中。

RDB和AOF的比较：

-   RDB占用存储空间小，因为是二进制文件；AOF占用空间大，但是可以重写。
-   RDB存储速度较慢，AOF速度快。
-   RDB恢复速度快，AOF恢复速度慢。
-   RDB安全性低，会丢失数据，AOF丢失数据比较少。
-   RDB资源消耗比较大，AOF比较轻量。
-   RDB启动优先级低，AOF优先级高，先启动。

## RDB

RDB持久化是指Redis 通过创建快照来保存数据在某个时间点上的副本。在创建快照之后，Redis可以对快照进行备份，也可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。

应用场景：服务器中每X小时执行BGSAVE命令进行备份，并将RDB文件拷贝到远程机器中，用于灾难恢复。

RDB持久化的优点：

-   保存的是二进制文件，存储效率高。
-   保存的是某个时间点的数据，非常适合备份、全量复制等场景。
-   RDB恢复数据比较快，快于AOF。

RDB持久化的缺点：

-   基于快照思想，如果数据量比较大，IO开销比较大。
-   无论是指令还是配置，无法做到实时持久化，存在丢失数据的风险。
-   每次执行BGSAVE命令都要fork子进程，牺牲了一定的性能。
-   Redis一些版本 的RDB文件格式不统一，有可能出现不兼容的情况。

#### 手动触发

RDB持久化是 Redis 默认采用的持久化方式。在Redis客户端执行SAVE命令可以立即启动RDB持久化，每执行一次就触发一次持久化。

```bash
127.0.0.1:6379> save
```

执行SAVE命令会阻塞Redis服务器，直到当前RDB持久化过程完成为止。

如果数据量过大有可能造成长时间阻塞（因为Redis是单线程模型），导致Redis服务器无法处理后续的命令。所以，线上环境几乎不会使用。

另一种启动RDB持久化的命令是BGSAVE，表示在后台执行RDB持久化，而不是阻塞Redis服务器的主进程。BGSAVE命令是针对SAVE阻塞问题做的优化。

在Redis中，所有涉及到RDB持久化的操作都应该使用BGSAVE命令。

```bash
127.0.0.1:6379> bgsave
Background saving started
```

执行BGSAVE命令后会立即返回`Background saving started`。BGSAVE的原理是Redis生成一个子进程来执行RDB持久化，创建RDB文件；持久化结束后返回消息，消息会存放在日志文件中。

SAVE和BGSAVE的区别在于：

-   读写：SAVE是同步方式，BGSAVE是异步。
-   阻塞客户端指令：SAVE阻塞，BGSAVE非阻塞。
-   额外内存消耗：SAVE不消耗，BGSAVE消耗。
-   启动新进程：SAVE不启动，BGSAVE启动。

#### 自动触发

需要注意的是，我们通常不需要手动执行BGSAVE命令，而是在配置文件中设置RDB持久化的条件。如果RDB持久化的条件满足，Redis服务器会自动执行BGSAVE命令进行后台RDB持久化。举例：

```纯文本
save 300 10   # 在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
save 60 10000 # 在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
```

## AOF

AOF持久化是指Redis通过记录客户端的操作命令，来实现数据持久化的目的。与RDB持久化相比，AOF 持久化的实时性更好，因此在使用RDB持久化的同时，通常也会开启AOF持久化。

默认情况下，Redis 没有开启 AOF 持久化，需要在配置文件中设置：

```纯文本
appendonly yes
```

开启 AOF 持久化后，每执行一条写入或更新数据的命令，Redis 就会自动将该命令写入硬盘中的 AOF 文件。AOF 文件的保存位置和 RDB 文件的位置相同，文件名需要在配置文件中设置，默认的文件名是 `appendonly.aof`。

在 Redis 的配置文件中，可以设置三种不同的 AOF 持久化写入文件的方式：

```纯文本
appendfsync always   # 只要有数据修改，就写入AOF文件，数据没有误差，但是会降低Redis的性能，不建议使用
appendfsync everysec # 每秒钟同步一次，准确性较高，性能较高，是默认配置
appendfsync no       # 让操作系统决定何时进行同步，整体过程不可控
```

为了兼顾数据完整性和性能，我们通常使用`appendfsync everysec`方式 ，让 Redis 每秒同步一次 AOF 文件。即使出现 Redis 崩溃的情况，最多也只会丢失一秒之内的数据。另外，当硬盘忙于执行写入AOF文件的时候，Redis 还会优雅地放慢自己的速度以便适应硬盘的最大写入速度。

### AOF 重写

> [https://redisbook.readthedocs.io/en/latest/internal/aof.html](https://redisbook.readthedocs.io/en/latest/internal/aof.html "https://redisbook.readthedocs.io/en/latest/internal/aof.html")

随着运行时间的增加，执行的命令越来越多，AOF文件也会越来越大。当AOF文件过大时，Redis会执行重写机制来压缩AOF文件，并产生一个新的 AOF 文件。这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。

AOF重写的一些策略：

-   同一个key的值，只保留最后一次写入。
-   删除已删除或者已过期数据的相关命令。

AOF重写避免了，AOF文件过大而实际内存数据少的问题：比如频繁修改数据，内存中数据很少，但是AOF中的命令很多。

AOF 重写其实是一个有歧义的词语。实际上， AOF重写并不需要对原有的 AOF 文件进行任何写入和读取，而是针对数据库中的数据。

AOF重写的作用和优点包括：

-   降低磁盘占用量，提高磁盘利用率。
-   提高持久化效率，降低持久化写时间。
-   降低数据恢复用时，提高数据恢复效率。

#### AOF后台重写

和RDB后台持久化类似一样，AOF重写也被放到后台执行，称为AOF后台重写。在Redis客户端执行 BGREWRITEAOF 命令可以触发一次AOF后台重写，并立即返回一串消息。

```bash
127.0.0.1:6379> bgrewriteaof
Background append only file rewriting started
```

因为Redis 不希望 AOF 重写造成服务器无法处理请求， 所以 Redis 决定将 AOF 重写程序放到（后台）子进程里执行， 这样处理的好处是：

-   子进程进行 AOF 重写期间，主进程可以继续处理命令请求。
-   子进程带有主进程的数据副本，使用子进程而不是线程，可以在避免锁的情况下，保证数据的安全性。

不过， 使用子进程也有一个问题需要解决： 因为子进程在进行 AOF 重写期间， 主进程还需要继续处理命令， 而新的命令可能对现有的数据进行修改， 这会让当前数据库的数据和重写后的 AOF 文件中的数据不一致。

为了解决这个问题， Redis 增加了一个 **AOF 重写缓存**， 这个缓存在主进程 fork 出子进程之后开始启用。如下图所示，Redis 主进程在接到新的写命令之后， 除了会将这个写命令的协议内容追加到现有的 AOF 文件之外， 还会追加到这个缓存中。

![image_uPZUdipcoq](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202311272140748.png)

换言之， 当子进程在执行 AOF 重写时，Redis服务的主进程需要执行以下三个工作：

1.  处理命令请求。
2.  将写命令追加到现有的 AOF 文件中。
3.  将写命令追加到 AOF 重写缓存中。

这样一来可以保证：

1.  现有的 AOF 功能会继续执行，即使在 AOF 重写期间发生停机，也不会有任何数据丢失。
2.  所有对数据库进行修改的命令都会被记录到 AOF 重写缓存中。

当子进程完成 AOF 重写之后， 它会向父进程发送一个完成信号， 父进程在接到完成信号之后， 会调用一个信号处理函数， 阻塞主进程并完成以下工作：

1.  将 AOF 重写缓存中的内容全部写入到新 的AOF 文件中。
2.  对新的 AOF 文件进行改名，覆盖原有的 AOF 文件。

当步骤 1 执行完毕之后， 现有 AOF 文件、新 AOF 文件和数据库三者的状态就完全一致了。当步骤 2 执行完毕之后， 程序就完成了新旧两个 AOF 文件的交替。

这个信号处理函数执行完毕之后， 主进程就可以继续像往常一样接受命令请求了。 在整个 AOF 后台重写过程中， 只有最后的信号处理函数会造成主进程阻塞。在其他时候， AOF 后台重写都不会对主进程造成阻塞， 这将 AOF 重写对性能造成的影响降到了最低。

#### 配置AOF后台重写

需要注意的是，我们通常不需要手动执行BGREWRITEAOF命令，而是在配置文件中配置AOF后台重写的条件。如果条件满足，Redis服务器自动执行BGREWRITEAOF命令进行AOF后台重写。

```纯文本
auto-aof-rewrite-min-size 64MB      // 当文件小于64M时不进行重写
auto-aof-rewrite-min-percenrage 100 // 当文件比上次重写后的文件大100%时进行重写
```

在服务器在 AOF 功能开启的情况下， 会维持以下三个变量：

-   记录当前 AOF 文件大小的变量 aof\_current\_size 。
-   记录最后一次 AOF 重写之后， AOF 文件大小的变量 aof\_rewrite\_base\_size 。
-   增长百分比变量 aof\_rewrite\_perc 。

每次当 serverCron 函数执行时， Redis会检查以下条件：

1.  没有 BGSAVE 命令在进行。
2.  没有 BGREWRITEAOF 在进行。
3.  当前 AOF 文件大小大于 server.aof\_rewrite\_min\_size （默认值为 1 MB）。
4.  当前 AOF 文件的大小和最后一次 AOF 重写之后的大小之间的比率大于等于指定的增长百分比，即aof\_current\_size/aof\_rewrite\_base\_size>=aof\_rewrite\_perc。

如果是的话， 就会触发自动的 AOF 重写。默认情况下， 增长百分比为 100% 。 也即是说， 如果前面三个条件都已经满足， 并且当前 AOF 文件大小比最后一次 AOF 重写后的大小大一倍的话， 那么会触发AOF 后台重写。

# 集群

> [Redis集群详解](https://blog.csdn.net/miss1181248983/article/details/90056960 "Redis集群详解")

Redis服务有三种集群模式：主从模式、哨兵模式、集群（Cluster）模式。

## 主从模式

主从模式是三种模式中最简单的。在主从模式中，Redis服务集群中的实例分为两类：

-   master：可以称为主服务器、主数据库、主节点。
-   slave：可以称为从服务器、从数据库、从节点。

主从模式通过主从复制机制使得 slave 拥有与 master 几乎完全一致的数据。

主从模式如下图所示：

![image_aYrFG7PQke](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202311272140043.png)

主从模式有如下特点：

-   master 可以进行读写操作，当操作导致数据变化时会自动将数据同步给 slave。
-   slave是只读的，但是会接收主数据库同步过来的数据。
-   一个 master 可以拥有多个slave，但是一个slave只能对应一个master。
-   一个slave挂了不影响其他master的读写操作和slave的读操作，重启后会将数据从master同步过来。
-   如果master挂了，Redis集群将无法提供写服务，但是不影响slave的读操作。master重启后，Redis才能重新提供写服务。注意：master挂了以后，不会在slave节点中重新选一个master。

主从模式的作用：读写分离、负载均衡、故障恢复、数据冗余、高可用的基础。

主从模式的缺点：master 节点是唯一的，如果 master 挂掉，则Redis无法对外提供写服务。

主从模式的工作机制：

-   master 启动后，可以直接对外提供读写服务。
-   slave 启动后，主动向master发送SYNC命令。
-   master在接收到SYNC命令之后，在后台进行RDB持久化得到一个数据库快照，以及缓存保存快照这段时间的命令，然后将保存的快照文件和缓存的命令发送给slave。
-   slave 在接收到快照文件和命令后，加载快照文件以及执行所有命令。
-   在slave初始化之后，master每次接收到写命令都会发送给slave，然后slave执行收到的命令，这样就可以保证主从数据库数据的一致性。

## 哨兵模式

> [https://www.51cto.com/article/712529.html](https://www.51cto.com/article/712529.html "https://www.51cto.com/article/712529.html")
> [https://zhuanlan.zhihu.com/p/354720754](https://zhuanlan.zhihu.com/p/354720754 "https://zhuanlan.zhihu.com/p/354720754")
> [https://www.cnblogs.com/kevingrace/p/9004460.html](https://www.cnblogs.com/kevingrace/p/9004460.html "https://www.cnblogs.com/kevingrace/p/9004460.html")

主从模式的缺点是不具备高可用性，如果主数据库master宕机，Redis将不能再对外提供写入操作。哨兵（sentinel）模式在主从模式的基础上，引入了单独的哨兵服务来监控Redis集群的运行状况。如果Redis集群中的主节点宕机了，哨兵服务会通过一系列的机制实现选主及主从切换，实现故障转移，确保整个Redis系统的可用性。

哨兵模式如下图所示：

![image_VujD4U_qvD](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202311272140677.png)

哨兵模式的特点包括：

-   监控：哨兵可以持续监控Redis集群中的主节点、从节点是否处于预期的工作状态。
-   通知：哨兵可以把Redis实例的运行故障信息通过API通知监控系统或者其他应用程序。
-   自动故障恢复：当Redis集群的主节点运行故障时，哨兵会启动自动故障恢复流程，使某个正常的从节点升级为主节点，其他从节点会使用新的主节点进行主从复制，并通知客户端使用新的主节点。
-   配置中心：哨兵可以作为客户端服务发现的授权源，客户端连接到哨兵请求给定服务的Redis主节点地址。如果发生故障转移，哨兵会通知新的地址。这里要注意：哨兵并不是Redis代理，只是为客户端提供了Redis主从节点的地址信息。

注意，哨兵服务应该以集群方式部署，即哨兵服务应该拥有多个哨兵实例（官方建议至少要有三个节点）共同协作。哨兵集群具有以下优势：

-   Redis集群主节点的系统故障是在多个哨兵实例共同认可的情况下完成的，大大降低了误报的概率。
-   即使不是所有的哨兵实例都正常运行，哨兵集群也能正常工作，这大大增加了系统的鲁棒性。

哨兵模式的工作机制：

-   哨兵集群具有自动发现机制，不同哨兵实例之间会一直保持连接，并且每2秒通过一个发布订阅的频道（`__sentinel__:hello`）进行信息交换。
-   一般情况下，每个哨兵每隔10秒向Redis集群中的主节点和从节点发送INFO 命令，以此获取主从节点的信息。第一次执行时，哨兵仅知道主节点的信息，通过主节点执行INFO命令就可以获取其从节点列表。如此周期性执行，就可以不断发现新加入的节点。
    -   如果INFO命令目标是主节点：哨兵从返回信息中获取主节点的从机列表，如果从节点是新增的，则将其加入监控列表。
    -   如果INFO命令目标是从节点：哨兵从返回信息中获取从节点所属的最新主节点ip和port，如果与历史记录不一致，则执行更新；获取从节点的优先级、复制偏移量以及与主节点的链接状态并更新。
-   每个哨兵以每秒钟一次的频率向它所知的Redis主节点、从节点以及其他哨兵实例发送一个PING命令，这其实是一个心跳检测。
-   如果一个哨兵发现一个Redis主节点距离最后一次有效回复 PING 命令的时间超过`down-after-milliseconds` 选项所指定的值， 则这个实例会被该哨兵标记为主观下线（SDOWN，Subjective Down）。
    -   主观下线是指一个哨兵实例通过检测发现某个Redis主节点发生故障的一种状态，也称为主管宕机。
-   &#x20;如果一个Redis主节点被标记为主观下线，那么
    -   正在监视这个主节点的所有哨兵要以每秒钟一次的频率向其发送PING命令，确认该主节点的确进入了主观下线状态。
    -   哨兵向下线的主节点对应的所有从节点发送 INFO命令的频率会从10秒一次提高为每秒一次。
-   如果有足够数量的哨兵（大于等于配置文件指定的值）在指定的时间范围内确认该主节点的确进入了主观下线状态， 则该主节点会被标记为客观下线（ODOWN，Objective Down）。
    -   客观下线是指是指一个哨兵检测到某个主节点发生故障，通过命令`SENTINEL is-master-down-by-addr`与其他哨兵节点协商，在指定时间内共同确认该主节点发生故障的一种状态，也称为客观宕机。
-   如果没有足够数量的哨兵确认主节点已经宕机，那么主节点的客观下线状态就会被移除。或者，如果哨兵随后发送给主节点的PING命令得到有效回复，那么主观下线状态也会被移除。

### 脑裂问题

> https://www.cnblogs.com/javamianshi365/p/16383900.html

当 Redis 主从集群环境出现两个主节点为客户端提供服务，这时客户端请求命令可能会发生数据丢失的情况。

主从哨兵集群中如果当发生主从集群切换时，那么一定是超过预设quorum数量的哨兵和主库连接超时了，这时哨兵集群才会将主库判断为客观下线，然后哨兵开始选举新的主节点，进行故障转移，转移完毕后客户端和新的主节点通信恢复正常请求。

如果在哨兵进行选举，故障转移的过程中原主节点恢复和客户端的通信，那么证明原主节点没有真正的故障，这时客户端依旧可以向原主节点正常通信。

![img](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202402032110924.png)

#### 脑裂的影响

脑裂出现后带来最严重的后果就是数据丢失，为什么会出现数据丢失的问题呢，主要原因是新主库确定后会向所有的实例发送slave of命令，让所有实例重新进行全量同步，而全量同步首先就会将实例上的数据先清空，所以在主从同步期间在原主库执行的命令将会被清空。

![img](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202402032111949.png)

#### 如何应对脑裂

脑裂的主要原因其实就是哨兵集群认为主节点已经出现故障了，重新选举其它从节点作为主节点，而原主节点其实是假故障，从而导致短暂的出现两个主节点，那么在主从切换期间客户端一旦给原主节点发送命令，就会造成数据丢失。

所以应对脑裂的解决办法应该是去限制原主库接收请求，Redis提供了两个配置项。

- min-slaves-to-write：与主节点通信的从节点数量必须大于等于该值主节点，否则主节点拒绝写入。
- min-slaves-max-lag：主节点与从节点通信的ACK消息延迟必须小于该值，否则主节点拒绝写入。

这两个配置项必须同时满足，不然主节点拒绝写入。

在假故障期间满足min-slaves-to-write和min-slaves-max-lag的要求，那么主节点就会被禁止写入，脑裂造成的数据丢失情况自然也就解决了。

**脑裂可以采用min-slaves-to-write和min-slaves-max-lag合理配置尽量规避，但无法彻底解决**。脑裂最本质的问题是主从集群内部没有共识算法来维护多个节点的强一致性，它不像Zookeeper那样，每次写入必须大多数节点成功后才算成功，当脑裂发生时，Zookeeper节点被孤立，此时无法写入大多数节点，写请求会直接失败，因此Zookeeper才能保证集群的强一致性。

## Cluster模式

> [https://www.bilibili.com/video/BV1F44y1C7N8/](https://www.bilibili.com/video/BV1F44y1C7N8/ "https://www.bilibili.com/video/BV1F44y1C7N8/")
> [https://www.redis.com.cn/topics/cluster-tutorial.html](https://www.redis.com.cn/topics/cluster-tutorial.html "https://www.redis.com.cn/topics/cluster-tutorial.html")

哨兵模式基本上可以满足一般生产的需求，具备高可用性。但是，当数据量多到一台服务器存放不下的情况时，哨兵模式也不能满足需求。Cluster模式就是为了解决Redis单机容量有限的问题，将Redis的数据根据一定的规则分配到多个Redis实例。

Redis从3.0版本开始支持Cluster模式，如下图所示。

![image_k6iSpF1Urz](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202311272141933.png)

Cluster模式的特点包括：

-   不通Redis节点通过网络进行互相连接，并使用gossip协议进行通信。
-   支持在线增加和删除节点。
-   负载均衡：
-   故障切换：
-   主从复制：

### 负载均衡

在Cluster模式中，一个Redis Cluster包含多个Redis节点，其中每个节点通常都是一主一从或者一主多从模式，其中从数据库不提供服务，仅作为备用。

和主从模式、哨兵模式不同的是，

-   Cluster模式是一个无中心的结构，每个节点是相互平等的，而且每个节点中的master节点都可以对外提供服务。
-   每个节点中的master和slave节点

Cluster模式给整个Redis集群分配了16384（2^14）个哈希槽（Hash Slot），其中每个节点平均分配，对应一个到多个哈希槽。

在读写数据时，Redis使用CRC16算法来决定一个key应该分配到哪个槽，算法公式为`target_slot=CRC16(key) % 16384`。得到目标的槽之后，就可以找到对应的Redis节点进行读写。

举例，如果一个Cluster集群包含3个Redis节点，3个节点都是主节点，那么

-   节点A存储的哈希槽范围是：0-5500。
-   节点B存储的哈希槽范围是：5501-11000。
-   节点C存储的哈希槽范围是：11001-16383。

Cluster模式支持在线增加和删除节点。比如，新增一个节点Ｄ，只需要把Ａ、Ｂ、Ｃ中的部分哈希槽数据移到Ｄ节点。同样，如果希望在集群中删除Ａ节点，只需要把Ａ节点的哈希槽的数据移到Ｂ和Ｃ节点，当Ａ节点的数据全部被移走后，Ａ节点就可以完全从集群中删除。因为把哈希槽从一个节点移到另一个节点是不需要停机的，所以，增加或删除节点也是不需要停机的。

需要注意的是，Cluster模式不支持同时处理多个key的命令（比如MSET和MGET），因为Redis需要把key均匀分布在各个节点上，并发量很高的情况下同时创建key-value会降低性能并导致不可预测的行为。

> 为什么使用16384？
> 在绝大多数情况下，Redis集群不会部署超过10000个节点，因此16384就能够保证每个节点至少对应一个槽。

### 主从复制和故障切换

> 为了保证高可用性，官方要求一个Redis Cluster至少要有6个节点，即3个一主一从。

为了保证在部分节点故障或网络不通时集群依然能正常工作，集群使用了主从模型，每个哈希槽可以有N个节点（1个主节点和N-1个从节点）。

在我们刚才的Cluster集群例子中，有A、B、C三个节点，如果B节点故障集群就不能正常工作了，因为Ｂ节点中的哈希槽数据5501-11000没法操作。

但是，如果我们给每一个节点都增加一个从节点，就变成了：A、B、C三个节点是主节点，A1、B1、C1 分别是他们的从节点。

如果B节点故障，集群会提升B1为主节点，从而让集群继续正常工作。但是，如果B和B1同时故障，集群就不能继续工作了。

### 如何使用Cluster模式

TODO

# 常见面试问题

### Redis线程模型

Redis 基于 Reactor 模式开发了自己的网络事件处理器，称为文件事件处理器（File Event Handler）。由于文件事件处理器是单线程方式运行的，所以我们一般都说 Redis 是单线程模型。既然是单线程，那怎么监听大量的客户端连接呢？

通过文件事件处理器，Redis使用 I/O 多路复用（Multiplexing）程序来同时监听多个套接字（Socket），并根据套接字目前执行的任务来关联不同的事件处理器。当被监听的套接字准备好执行连接应答（Accept）、读取（Read）、写入（Write）、关闭（Close）等操作时，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。

这样的好处非常明显：I/O多路复用技术让Redis不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗。

可以看出，文件事件处理器主要是包含 4 个部分：

-   多个 socket：多个客户端连接。
-   IO 多路复用程序：支持多个客户端连接的关键。
-   文件事件分派器：将 socket 关联到相应的事件处理器。
-   事件处理器：连接应答处理器、命令请求处理器、命令回复处理器。

总结，文件事件处理器实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。

### Redis6.0之后为何引入了多线程？

Redis6.0 之前不使用多线程的原因有:

-   单线程编程容易并且更容易维护。
-   Redis 的性能瓶颈不在 CPU，主要在内存和网络。
-   多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。

Redis 6.0 引入多线程主要为了提高网络 IO 读写性能，因为 Redis 在网络数据的读写这类耗时操作上存在一定的性能瓶颈。

需要注意的是，Redis 6.0 的多线程默认是禁用的，只使用单线程。如果要开启多线程，可以在Redis 配置文件添加下面的配置（必须设置线程数）：

```纯文本
io-threads-do-reads yes
io-threads 4 # 官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程
```

虽然Redis6.0 引入了多线程，但是执行命令仍然是单线程顺序执行。因此，不需要担心线程安全问题。

### Redis 给缓存数据设置过期时间有啥用？

一般情况下，我们设置保存的缓存数据的时候都会设置一个过期时间。

因为内存是有限的，如果缓存中的所有数据都是一直保存的话，可能导致内存不够用（Out of memory）。

Redis 自带了给缓存数据设置过期时间的功能，比如：

```bash
127.0.0.1:6379> expire key 60 # 数据在 60s 后过期
(integer) 1
127.0.0.1:6379> setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)
OK
127.0.0.1:6379> ttl key # 查看数据还有多久过期
(integer) 56
```

很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在1分钟内有效，用户登录的 token 可能只在 1 天内有效。如果使用传统的数据库来处理的话，一般都是自己判断过期，这样更麻烦并且性能要差很多。

### Redis 如何删除过期数据？

> [https://redis.io/commands/expire/](https://redis.io/commands/expire/ "https://redis.io/commands/expire/")

Redis数据库中有两个字典：一个是数据字典，保存了数据库中的所有数据（键值对）；另一个是过期字典，保存了数据库中所有设置过期的数据的地址及数据的过期时间。

常用的过期数据的删除策略有三个：

1）定时删除：在保存一个带有过期时间的数据时，需要手动创建一个定时器（比如借助编程语言实现），当过期时间到达时，由定时器立即执行键的删除操作。

优点：定时删除对内存比较友好，能够保存键一旦过期就能立即从内存中删除。

缺点：定时删除对 CPU 不太友好，因为删除操作会抢占 CPU。如果 Redis 服务器 CPU 负载比较高，或者过期键比较多，定时删除操作会严重影响 Redis 服务器的性能。

2）惰性删除：对于一个设置了过期时间的键，在读取的时候才对其进行过期检查，没有过期则返回正常数据，反之则删除这个键。

优点：对 CPU 友好，只会在使用该键时才会进行过期检查，对于用不到不用浪费时间进行过期检查。

缺点：对内存不友好，如果一个键已经过期，但是一直没有使用，那么该键就会一直存在内存中。如果有很多这种键，这些键便永远不会被删除，内存永远不会释放。

3）定期删除：每隔一段时间从过期字典中抽取一批 key 执行删除过期key操作。这样对内存比较友好，但是消耗CPU。Redis底层会并通过限制删除操作的时间和频率来减少删除操作对CPU的影响。

定期删除对内存更加友好，惰性删除对CPU更加友好，两者各有千秋，所以Redis采用定期删除和惰性删除的策略。具体地，Redis定期（默认每100ms一次）从过期字典中随机抽查20个key，并删除其中过期的key。

### Redis 内存淘汰机制

Redis内存淘汰策略是指当缓存内存不足时，通过淘汰旧数据处理新加入数据选择的策略。

即使给 key 设置了过期时间，仍然可能会出现内存不足的问题。比如Redis可能在定期删除和惰性删除中漏掉了很多过期的key ，导致大量这样的key 堆积在内存里，进而导致内存不足。要解决这个问题，需要使用Redis 内存淘汰机制。

#### Redis最大内存

1）在Redis配置文件中添加如下的配置：

```text
maxmemory 1024mb // 设置Redis最大占用内存大小为1024M
```

注意：maxmemory默认配置为0，在64位操作系统下redis最大内存为操作系统剩余内存，在32位操作系统下redis最大内存为3GB。&#x20;

2）通过动态命令配置：

```bash
127.0.0.1:6379> config set maxmemory 200mb //设置Redis最大占用内存大小为200M
127.0.0.1:6379> config get maxmemory //获取设置的Redis能使用的最大内存大小
1) "maxmemory"
2) "209715200"
```

#### 内存淘汰策略

Redis 提供了 8 种内存淘汰策略

1.  volatile-lru（least recently used）：从已设置过期时间的数据中挑选最近最少使用的数据淘汰。
2.  volatile-ttl：从已设置过期时间的数据中挑选将要过期的数据淘汰。
3.  volatile-random：从已设置过期时间的数据中任意选择数据淘汰。
4.  allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。
5.  allkeys-random：从数据集（server.db\[i].dict）中任意选择数据淘汰。
6.  no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！
7.  volatile-lfu（least frequently used）：从已设置过期时间的数据挑选最不经常使用的数据淘汰。
8.  allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key。

在关于LRU的两个策略中，使用LRU数据结构和算法即可。

在关于LFU的两个策略中，需要设置一个最近的时间值，给定时间内才能计算最不经常使用的数据。

## 发现并处理大Key和热Key

> https://help.aliyun.com/zh/redis/user-guide/identify-and-handle-large-keys-and-hotkeys

在使用Redis的过程中，如果未能及时发现并处理Big keys（下文称为“大Key”）与Hotkeys（下文称为“热Key”），可能会导致服务性能下降、用户体验变差，甚至引发大面积故障。

### 定义

大Key通常以Key的大小和Key中成员的数量来综合判定，例如：

-   Key本身的数据量过大：一个String类型的Key，它的值为5MB。
-   Key中的成员数过多：一个ZSET类型的Key，它的成员数量为10,000个。
-   Key中成员的数据量过大：一个Hash类型的Key，它的成员数量虽然只有1,000个但这些成员的Value（值）总大小为100 MB。

热Key通常以其接收到的Key被请求频率来判定，例如：

-   QPS集中在特定的Key：Redis实例的总QPS（每秒查询率）为10,000，而其中一个Key的每秒访问量达到了7,000。
-   带宽使用率集中在特定的Key：对一个拥有上千个成员且总大小为1 MB的HASH Key每秒发送大量的**HGETALL**操作请求。
-   CPU使用时间占比集中在特定的Key：对一个拥有数万个成员的Key（ZSET类型）每秒发送大量的**ZRANGE**操作请求。

### 大Key和热Key引发的问题

大Key可能导致：

-   客户端执行命令的时长变慢，因为通过网络传输数据，越大的数据消耗时间越长。
-   Redis内存达到maxmemory参数定义的上限引发操作阻塞或重要的Key被逐出，甚至引发内存溢出（Out Of Memory）。
-   集群架构下，某个数据分片的内存使用率远超其他数据分片，无法使数据分片的内存资源达到均衡。
-   对大Key执行读请求，会使Redis实例的带宽使用率被占满，导致自身服务变慢，同时容易波及相关的服务。
-   对大Key执行删除操作，由于使用单线程模型，易造成主库较长时间的阻塞，进而可能引发同步中断或主从切换。

热Key可能导致：

-   占用大量的CPU资源，影响其他请求并导致整体性能降低。
-   集群架构下，产生访问倾斜，即某个数据分片被大量访问，而其他数据分片处于空闲状态，可能引起该数据分片的连接数被耗尽，新的连接建立请求被拒绝等问题。
-   在抢购或秒杀场景下，可能因商品对应库存Key的请求量过大，超出Redis处理能力造成超卖。
-   热Key的请求压力数量超出Redis的承受能力易造成缓存击穿，即大量请求将被直接指向后端的存储层，导致存储访问量激增甚至宕机，从而影响其他业务。

### 大Key和热Key产生的原因

产生大Key与热Key的原因有很多，比如未正确使用Redis、业务规划不足、无效数据的堆积、访问量突增等。

大Key产生的原因包括：

-   在不适用的场景下使用Redis，易造成Key的value过大，如使用String类型的Key存放大体积二进制文件型数据；
-   业务上线前规划设计不足，没有对Key中的成员进行合理的拆分，造成个别Key中的成员数量过多；
-   未定期清理无效数据，造成如HASH类型Key中的成员持续不断地增加；
-   使用List类型Key的业务消费侧发生代码故障，造成对应Key的成员只增不减。

热Key产生的原因包括：

-   预期外的访问量陡增，如突然出现的爆款商品、访问量暴涨的热点新闻、直播间某主播搞活动带来的大量刷屏点赞、游戏中某区域发生多个工会之间的战斗涉及大量玩家等。

### 快速找出大Key和热Key

Redis提供多种方案来找出大Key与热Key。

1）实时Top Key统计（推荐）

-   优点：准确性高、对性能几乎无影响。
-   缺点：展示的Key数量有一定限制，但能满足常规场景下的需求。

这种方法可实时展示实例中的大Key和热Key信息，同时支持查看几天内的大Key和热Key的历史信息。

该功能可帮助您掌握Key在内存中的占用、Key的访问频次等信息，溯源分析问题，为您的优化操作提供数据支持。

2）离线全量Key分析

-   优点：可对历史备份数据进行分析，对线上服务无影响。
-   缺点：时效性差，RDB文件较大时耗时较长。

这种方法可以对Redis的RDB备份文件进行定制化的分析，帮助您发现实例中的大Key，掌握Key在内存中的占用和分布、Key过期时间等信息，为您的优化操作提供数据支持，帮助您避免因Key倾斜引发的内存不足、性能下降等问题。

3）通过redis-cli的bigkeys和hotkeys参数查找大Key和热Key

Redis提供了bigkeys参数能够使redis-cli以遍历的方式分析Redis实例中的所有Key，并返回Key的整体统计信息与每个数据类型中Top1的大Key，bigkeys仅能分析并输入六种数据类型（STRING、LIST、HASH、SET、ZSET、STREAM），命令示例为`redis-cli -h <host> -a <password> --bigkeys`。

同时，自Redis 4.0版本起提供了hotkeys参数，可以快速帮您找出业务中的热Key，具体操作，请参见[通过redis-cli的hotkeys参数查找热Key](https://help.aliyun.com/document_detail/101108.htm#concept-pw3-snd-ggb "通过redis-cli的hotkeys参数查找热Key")。

4）通过Redis内置命令对目标Key进行分析

-   优点：方便、对线上服务影响小。
-   缺点：返回的Key序列化长度并不等同于它在内存空间中的真实长度，因此不够准确，仅可作为参考。

对不同数据类型的目标Key，分别通过如下风险较低的命令进行分析，来判断目标Key是否符合大Key判定标准。

-   STRING类型：执行STRLEN命令，返回对应Key的value的字节数。
-   LIST类型：执行LLEN命令，返回对应Key的列表长度。
-   HASH类型：执行HLEN命令，返回对应Key的成员数量。
-   SET类型：执行SCARD命令，返回对应Key的成员数量。
-   ZSET类型：执行ZCARD命令，返回对应Key的成员数量。
-   STREAM类型：执行XLEN命令，返回对应Key的成员数量。

5）通过业务层定位热Key，通过在业务层增加相应的代码对Redis的访问进行记录并异步汇总分析。

-   优点：可准确并及时地定位热Key。
-   缺点：业务代码复杂度的增加，同时可能会降低一些性能。

6）通过redis-rdb-tools工具以定制化方式找出大Key。[Redis-rdb-tools](https://github.com/sripathikrishnan/redis-rdb-tools "Redis-rdb-tools")是通过Python编写，支持定制化分析Redis RDB快照文件的开源工具。您可以根据您的精细化需求，全面地分析Redis实例中所有Key的内存占用情况，同时也支持灵活地分析查询。

-   优点：支持定制化分析，对线上服务无影响。
-   缺点：时效性差，RDB文件较大时耗时较长。

7）通过MONITOR命令找出热Key。MONITOR命令能够实时地打印Redis中的所有请求，包括时间信息、Client信息、命令以及Key信息。

在发生紧急情况时，可以通过短暂执行MONITOR命令并将返回信息输入至文件，在关闭MONITOR命令后，对文件中请求进行归类分析，找出这段时间中的热Key。

-   优点：方便、安全。
-   缺点：会占用CPU、内存、网络资源，时效性与准确性较差。

## 缓存穿透

缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍，然后返回空。

如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至击垮数据库系统。

解决方案：

1）最基本的解决方案就是做更严格的参数校验，对一些不合法的参数请求直接抛出异常信息返回给客户端。

2）缓存无效 key。如果缓存和数据库都查不到某个 key ，就在Redis 中写一个空数据去并设置过期时间。这可以解决请求的 key 变化不频繁的情况，但是并不能从根本上解决问题。

3）布隆过滤器：布隆过滤器是包含一个比特位数组与多个个哈希函数的数据结构，用来判断一个给定数据是否存在于海量数据中。布隆过滤器说某个元素不在，那么这个元素一定不在。布隆过滤器说某个元素存在，小概率会误判。

优点：

-   节省空间：不需要存储数据本身，只需要存储数据对应hash比特位。
-   时间复杂度低：插入和查找的时间复杂度都为O(k)，k为哈希函数的个数。

缺点：

-   存在假阳性：布隆过滤器判断存在，可能出现元素不在集合中；判断准确率取决于哈希函数的个数。
-   不能删除元素：如果一个元素被删除，但是却不能从布隆过滤器中删除，这也是造成假阳性的原因了。

#### 布隆过滤器

如果在平时我们要判断一个元素是否在一个集合中，通常会采用查找比较的方法，下面分析不同的数据结构查找效率：

-   采用线性表存储，查找时间复杂度为O(N)。
-   采用平衡二叉排序树（AVL、红黑树）存储，查找时间复杂度为O(logN)。
-   采用哈希表存储，考虑到哈希碰撞，整体时间复杂度也要O\[log(n/m)]。

当需要判断一个元素是否存在于海量数据集合中，不仅查找时间慢，还会占用大量存储空间。接下来看一下布隆过滤器如何解决这个问题。

布隆过滤器由一个长度为m比特的位数组（bit array）与k个哈希函数（hash function）组成的数据结构。位数组初始化均为0，所有的哈希函数都可以分别把输入数据尽量均匀地散列。

当要向布隆过滤器中插入一个元素时，该元素经过k个哈希函数计算产生k个哈希值，以哈希值作为位数组中的下标，将所有k个对应的比特值由0置为1。

当要查询一个元素时，同样将其经过哈希函数计算产生哈希值，然后检查对应的k个比特值：如果有任意一个比特为0，表明该元素一定不在集合中；如果所有比特均为1，表明该集合有可能性在集合中。为什么不是一定在集合中呢？因为不同的元素计算的哈希值有可能一样，会出现哈希碰撞，导致一个不存在的元素有可能对应的比特位为1，这就是所谓“假阳性”（false positive）。相对地，“假阴性”（false negative）在BF中是绝不会出现的。

总结一下：如果布隆过滤器认为一个数据不存在，那么一定不在集合中；布隆过滤器认为存在，可能在也可能不在集合中。

布隆过滤器适用于：爬虫系统url去重、垃圾邮件过滤、黑名单等。

## 缓存击穿

缓存击穿，是指一个key非常热点，在不停的扛着大量请求。当这个key在失效的瞬间，持续的大量请求就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。

缓存击穿的危害是数据库瞬时压力骤增，造成大量请求阻塞。

解决方案包括：

1）使用互斥锁（Mutex Lock）。

这种思路比较简单，就是查询缓存和数据库之前获取互斥锁，这样当一个线程发现缓存数据不存在时，就可以重写缓存，而其他线程等待回写缓存线程执行完，重新读缓存即可。

同一时间只有一个线程读数据库然后回写缓存，其他线程都处于阻塞状态。如果是高并发场景，大量线程阻塞势必会降低吞吐量。

2）设置热点数据永远不过期。

有两种方法，一是物理不过期，针对热点key不设置过期时间。

二是逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建。

从实战看这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程（非构建缓存的线程）可能访问的是老数据，对于不追求严格强一致性的系统是可以接受的。

## 缓存雪崩

缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，请求直接落到数据库上，引起数据库压力过大甚至宕机。

和缓存击穿不同的是，缓存击穿指通常指大量并发查询一条热点数据，而缓存雪崩是指很多不同数据都过期了，这些数据都查不到从而只能查数据库。这就好比雪崩一样，会给数据库带来巨大的压力，可能会导致宕机。

解决办法包括：

1）均匀或随机过期。设置不同的过期时间，增加随机性，让缓存失效的时间点尽量均匀。通常可以为有效期增加随机值或者统一规划有效期。

2）缓存永不过期。跟缓存击穿解决思路一致，同一时间只让一个线程构建缓存，其他线程阻塞排队。

3）加互斥锁。跟缓存击穿解决思路一致，同一时间只让一个线程构建缓存，其他线程阻塞排队。

4）双层缓存策略。增加本地缓存，形成多级缓存。

5）限流。避免同时处理大量的请求。

6）采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。

## 缓存预热

存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统，这样就可以避免在用户请求的时候，先查询数据库，然后再将数据回写到缓存。

如果不进行预热， 那么 Redis 初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。

操作方法：

1）数据量不大的时候，工程启动的时候执行加载缓存的操作。

2）数据量大的时候，设置一个定时任务脚本，进行缓存的刷新。

3）数据量太大的时候，优先保证热点数据进行提前加载到缓存。

## 缓存降级

缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。

另外，也可以将部分热点数据缓存到服务的内存中，这样一旦缓存出现异常，可以直接使用服务的内存数据，从而避免数据库遭受巨大压力。

降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。

## Redis中的Rehash机制

> [redis rehash机制](https://www.jianshu.com/p/6114d0eabd67 "redis rehash机制")

在Redis中，键值以哈希表的方式进行存储，使用链地址法解决哈希冲突。在键值对的数目比较多时，哈希冲突的次数就会变多，有的链表就会越来越长，会降低检索效率。为了减少哈希表中的地址冲突次数，Redis会增加数组空间，并把数据移到新的空间中，这个过程称为rehash，类似于Java中HashMap的扩容。

Redis中维护了一个大小为2的数组ht，存放了两个存储数据的哈希表，ht\[0]是旧表，ht\[1]是新表。当开始rehash时，为新表申请一个更大的空间，把旧表中的元素往新表中迁移。旧表中的数据迁移完之后，释放旧表的空间，交换两张表。

Redis什么时候进行rehash？

-   服务器目前没有在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的数据数量与哈希表大小的比例大于或等于1。
-   服务端目前正在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的数据数量与哈希表大小的比例大于或等于5。
-   当哈希表的哈希表的数据数量与哈希表大小的比例小于0.1时，Redis会自动开始对哈希表进行缩容操作。

rehash是渐进式的过程，并不是一次性完成，而是分步完成的：每步完成一个bucket（桶）的迁移，直至所有数据迁移完毕。一个bucket对应哈希表数组中的一条链表。Redis中维护了一个索引计数器`rehshidx`，可以用来表示是否正在进行rehash（-1表示没有进行rehash），还可以用来记录迁移的位置。具体过程为：

-   为ht\[1]分配空间，让字典同时持有ht\[0]和ht\[1]两个哈希表。
-   在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。
-   在rehash执行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作外，还会顺带将ht\[0]哈希表在rehashidx索引上的所有键值对rehash到ht\[1]，当rehash工作完成后，程序将rehashidx属性的值增1。
-   随着字典操作的不断执行，最终在某个时间点上，ht\[0]的所有键值对都会被rehash至ht\[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。

rehash为什么要渐进式迁移？如果dict数据结构中存储了海量的数据，那么一次性迁移势必带来Redis性能的下降，而且Redis是单线程模型，在实时性要求高的场景下这可能是致命的。而渐进式哈希则将这种代价可控地分摊了，调用方可以在插入、删除、更新数据的时候执行dictRehash()，最小化数据迁移的代价。在迁移的过程中，数据是在新表还是旧表中并不重要，数据并不会丢失，在旧表中找不到再到新表中寻找就是了。

## 如何使用Redis实现分布式锁-单机版

> [https://www.cnblogs.com/niceyoo/p/13711149.html](https://www.cnblogs.com/niceyoo/p/13711149.html "https://www.cnblogs.com/niceyoo/p/13711149.html")
> [https://redis.io/commands/setnx/](https://redis.io/commands/setnx/ "https://redis.io/commands/setnx/")
>

分布式锁一般有三种实现方式：

-   基于数据库的分布式锁。
-   基于Redis的分布式锁。
-   基于ZooKeeper的分布式锁。

为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件：

1.  互斥性。在任意时刻，只有一个客户端能持有锁。
2.  不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
3.  具有容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。
4.  解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。

### 加锁

加锁实际上就是在Redis中，给Key键设置一个值，为避免死锁，并给定一个过期时间。

加锁可以使用SETNX和EXPIRE命令，如下所示：

```bash
SETNX lock_key random_value
EXPIRE lock_key expire_time
```

说明：

-   SETNX：表示只在键不存在时，才对键进行设置操作。注意，SETNX命令不支持同时设置过期时间。
-   random\_value 是客户端生成的随机字符串，而且要保证唯一。
-   expire\_time是过期时间，时间单位是秒。

使用SETNX和EXPIRE两个命令进行加锁有些问题：

1）原子操作问题：执行两个命令不是原子操作。如果在执行SETNX命令后，Redis发生宕机，EXPIRE命令没有设置成功，锁就无法释放。

2）刷新过期时间问题：当多个请求到达时，虽然只有一个请求的 SETNX命令 可以成功，但是任何一个请求的 EXPIRE命令 却都可以成功。这就意味着一个请求即便获取不到锁，也可以刷新过期时间。如果请求比较密集的话，那么过期时间会一直被刷新，导致锁一直有效。

对于上面两个问题，首先在Redis在2.6.12版本，就把SETNX命令标记为废弃（deprecated）了，并为SET命令引入了NX参数。

因此，Redis推荐使用SET命令和NX参数替代SETNX，如下所示：

```bash
SET lock_key random_value NX PX expire_time
```

说明：

-   random\_value 是客户端生成的随机字符串，而且要保证唯一。
-   NX：表示只在键不存在时，才对键进行设置操作。
-   PX expire\_time：表示设置键的过期时间，时间单位为毫秒。

如果上面的命令执行成功，则证明客户端获取到了锁。

使用SET命令和NX参数以及PX expire\_time是原子操作，也避免了请求过期时间被锁的非持有者刷新的问题。

### 解锁

解锁的过程就是将SET命令设置的Key删除。删除之前，必须要检查Key 对应的 Value 是否和指定的值一样，相等才可以进行删除操作。伪代码如下所示：

```go
value := redis.get(key)
if value == <random_value> {
    redis.del(key)
}
```

但是，上面的解锁逻辑并非原子操作，存在一个线程的锁被其他线程误删除的问题。具体地，

-   线程A执行`redis.get(key)`时，顺利获得对应的value。
-   线程A执行到`value == <random_value>`时，线程A持有的锁正好过期。
-   与此同时，线程B恰好获得相同Key的锁，那么线程A就会把线程B锁给删除掉，进而失去了锁的保护。

为了保证解锁操作的原子性，一般调用Lua脚本完成这一操作，因为Lua脚本是原子操作。类似地，也是先判断当前锁的字符串是否与传入的值相等，如果是就删除Key，解锁成功。

```lua
-- Lua删除锁：
-- KEYS和ARGV分别是以集合方式传入的参数，对应上文的Test和uuid。
-- 如果对应的value等于传入的uuid。
if redis.call('get', KEYS[1]) == ARGV[1] 
    then -- 执行删除操作
        return redis.call('del', KEYS[1]) 
    else -- 不成功，返回0
        return 0 
end
```

### 总结

注意，上文的Redis分布式锁仍然有缺点：一是不具有可重入性，二是只适用于单节点Redis（或主从模式）。

在哨兵模式、或者Cluster 模式下，如果 master 节点由于宕机发生主从切换，那么就会出现锁丢失的情况。举例，

1.  在 Redis 的 master 节点上拿到了锁；
2.  但是这个加锁的 key 还没有同步到 slave 节点；
3.  master 故障，发生故障转移，slave 节点升级为 master节点；
4.  最终 master 节点上的锁丢失。

有的时候甚至不单单是锁丢失这么简单，新选出来的 master 节点可以重新获取同样的锁，出现一把锁被获得两次的场景。

所以，如果Redis在你的项目中是多机部署的，那么可以尝试使用RedLock（红锁）算法，并根据编程语言找到适合的客户端，比如Java可以使用Redission。

