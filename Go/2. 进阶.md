# 10.协程和通道

## 10.1. 协程Goroutines

在Go语言中，并发的执行单元可以叫作协程（Goroutines）。简单来说，可以把Goroutines理解为一种更轻量的用户级线程。

> 问题：线程与协程的区别？
> 1）占用资源：线程占用资源多于协程。线程初始一般为 2MB，而且无法变化；协程初始一般为 2KB，可随需要而增大。
> 2）调度：线程由操作系统内核完成；协程由用户完成，所以协程也可以称为用户态线程。
> 3）切换开销：线程切换开销大于协程。线程切换涉及模式切换（从用户态切换到内核态）、16个寄存器、PC、SP等寄存器的刷新等；协程切换只有三个寄存器的值修改。
> 4）性能：线程性能没有协程好。线程资源占用太高，频繁创建销毁会带来严重的性能问题；协程资源占用小，不会带来严重的性能问题。
> 5）数据同步：线程需要用锁等机制确保数据的一直性和可见性；协程可以使用锁机制，也可以使用channel进行通信实现数据同步。

当一个程序启动时，其主函数（main函数）在一个单独的goroutine中运行，称之为main goroutine。主函数返回时，所有的goroutine都会被直接打断，程序退出。

创建一个新的goroutine需要使用go语句：在一个函数或方法调用前加上go关键字。go语句会使其语句中的函数或方法在一个新创建的goroutine中运行，而go语句本身会迅速地完成。

```go
f()    // call f(); wait for it to return
go f() // create a new goroutine that calls f(); don't wait

```

举例：

```go
func main() {
    go spinner(100 * time.Millisecond)
    const n = 45
    fibN := fib(n) // slow
    fmt.Printf("\rFibonacci(%d) = %d\n", n, fibN)
}

func spinner(delay time.Duration) {
    for {
        for _, r := range `-\|/` {
            fmt.Printf("\r%c", r)
            time.Sleep(delay)
        }
    }
}

func fib(x int) int {
    if x < 2 {
        return x
    }
    return fib(x-1) + fib(x-2)
}
```

最后，主函数返回时，所有的goroutine都会被直接打断，程序退出。

## 10.2. 通道Channels

如果说Goroutines是Go语言的并发体，那么通道（Channels）就是不同Goroutines之间的通信机制。

内置的make关键字可以用来声明一个channel，并且需要指定channel发送数据的类型。另外，也可以指定第二个整型参数，对应channel的容量。如果channel的容量大于零，那么该channel就是带缓存的channel。

```go
ch2 := make(chan int)    // ch has type 'chan int'
ch3 := make(chan int, 0) // unbuffered channel
ch4 := make(chan int, 3) // buffered channel with capacity 3

```

和map类似，返回的channel对应着一个由make创建的底层数据结构的引用。当一个channel被复制或用于函数参数传递时，其实只是复制了一个channel引用，因此调用者和被调用者将引用同一个channel对象。和其它的引用类型一样，channel的零值也是nil。

一个channel有发送和接收两个主要操作，都是通信行为。发送操作表示向一个channel发送数据，接收操作表示从一个channel接收数据。需要注意的是，在nil值的channel上的发送和接收操作会永远阻塞。

发送和接收两个操作都使用`<-`运算符。在发送语句中，`<-`运算符用来分割channel和要发送的值。在接收语句中，`<-`运算符被放在channel对象之前。一个不使用接收结果的接收操作也是合法的。

```go
ch <- x  // a send statement
x = <-ch // a receive expression in an assignment statement
<-ch     // a receive statement; result is discarded
```

channel还有一个关闭操作，使用内置的close函数就可以关闭一个channel：

```go
close(ch) 
```

当一个channel被关闭后，再向该channel发送数据将导致panic异常。对于一个已经被关闭的channel，如果再一次调用close，会导致panic。如果一个channel发送完所有数据，那么后续的接收操作将不再阻塞，而是会立即返回一个零值。另外，close一个channel具有广播性，之后可以看到。

### 10.2.1. 不带缓存的通道

对于一个无缓存channel，如果一个发送者goroutine向其发送数据，那么该发送操作将阻塞该goroutine，直到另一个goroutine在相同的channel上执行接收操作。当发送的数据通过channel成功传输之后，两个goroutine可以继续执行后面的语句。反之，如果接收操作先发生，那么接收者goroutine也将阻塞，直到有另一个goroutine在相同的channel上执行发送操作。

举例，主goroutine将会被阻塞5秒钟。

```go
func main() {
    ch := make(chan int)
    go func() {
        time.Sleep(5)
        ch <- 1
    }()
  
    res := <-ch // blocked for 5 seconds
    fmt.Println(res)
}

```

一个无缓存Channels的发送和接收操作将导致两个goroutine做一次同步操作。因此，无缓存Channels有时候也被称为同步Channels。当通过一个无缓存Channels发送数据时，接收者收到数据**发生在**再次唤醒发送者goroutine之前（译注：*happens before*，这是Go语言并发内存模型的一个关键术语！）。

> happens before有哪些原则？
> 1）程序次序规则。在一个线程/协程中，按照代码的顺序，前面的操作Happens-Before于后面的任意操作。
> 2）可见性规则。在一个线程/协程中，按照代码的顺序，前面的数据修改对于后面的操作是可见的。
> 3）传递规则。如果A Happens-Before B，并且B Happens-Before C，则A Happens-Before C。
> 4）锁规则。对一个锁的解锁操作 Happens-Before于后续对这个锁的加锁操作。

在讨论并发编程时，当我们说x事件在y事件之前发生（*happens before*），并不是表示x事件在时间上比y时间更早，而是要保证在此之前的事件都已经完成了。比如在此之前的更新某些变量的操作已经完成，其他逻辑放心依赖这些已完成的事件了。

如果说x事件既不是在y事件之前发生也不是在y事件之后发生，那么就可以认为x事件和y事件是并发的。这并不是意味着x事件和y事件就一定是同时发生的，我们只是不能确定这两个事件发生的先后顺序。如果并发事件的发生顺序不同可能导致程序的结果无法预测，那么就有必要保证某些事件的执行顺序，以避免出现并发问题。

基于channels发送消息有两个重要方面。首先每个消息都有一个值，但是有时候通讯的事实和发生的时刻也同样重要。当我们更希望强调通讯发生的时刻时，我们将它称为**消息事件**。有些消息事件并不携带额外的信息，它仅仅是用作两个goroutine之间的同步，这时候通常使用struct{}空结构体作为channels元素的类型。

### 10.2.2. 串联的通道

Channels也可以用于将多个goroutine连接在一起，一个Channel的输出作为下一个Channel的输入。这种串联的Channels就是所谓的管道（pipeline）。

下面的程序用两个channels将三个goroutine串联起来：第一个goroutine是一个计数器，并发送给地二个goroutine；第二个goroutine用来求平方，并把结果发送给第三个goroutine；第三个goroutine是一个打印程序，打印收到的每个整数。

```go
func main() {
    naturals := make(chan int)
    squares := make(chan int)

    // Counter
    go func() {
        for x := 0; ; x++ {
            naturals <- x
        }
    }()

    // Squarer
    go func() {
        for {
            x := <-naturals
            squares <- x * x
        }
    }()

    // Printer (in main goroutine)
    for {
        fmt.Println(<-squares)
    }
}


```

上述的程序一直向naturals通道发送数据，同时主函数也包含一个死循环，会一直打印结果，所以程序不会自然停止。但是，如果只发送有限的数据，该如何处理并停止程序呢？

方法如下：

1）如果发送者知道没有更多的数据需要处理，就关闭channel。需要注意，

-   当一个channel被关闭后，再向该channel发送数据将导致panic异常。
-   当一个channel被关闭并且其中所有数据都被成功接收后，后续的接收操作将不再阻塞，而是立即返回一个通道数据类型的零值。
-   重复关闭一个已经被关闭的channel将导致panic异常，关闭一个nil值的channel也将导致panic异常。
-   close具有广播机制。如果有多个goroutine被同一个channel的接收操作阻塞，那么close这个channel会让这些goroutine继续运行，因为一个已经关闭的channel的接收操作不会阻塞。
-   关闭一个单向的只用于接收操作的channel将导致编译失败。

2）接收者可以使用接收操作的变体形式来一个channel是否还有值需要被接收。这种形式多接收一个结果，多接收的第二个结果是一个布尔值ok，true表示成功从channels接收到值，false表示channels已经被关闭并且里面没有值可接收。

```go
x, ok := <- channel
```

所以，可以得到第二个版本的代码。

```go
func main() {
    naturals := make(chan int)
    squares := make(chan int)
  
    // Counter
    go func() {
        for x := 0; x < 100; x++ { // assume 100 data
            naturals <- x
        }
        close(naturals)
    }()
  
    // Squarer
    go func() {
        for {
            x, ok := <-naturals
            if !ok {
                break
            }
            squares <- x * x
        }
        close(squares)
    }()
  
    // Printer (in main goroutine)
    for {
        s, ok := <-squares
        if !ok {
            break
        }
        fmt.Println(s)
    }
}
```

但是，上面的语法稍显笨拙，而且因为这种处理模式很常见，所以Go语言支持使用range循环在channels上面迭代：循环依次从channel接收数据，当channel被关闭并且没有值可接收时跳出循环。因此，可以得到第三个版本的代码：

```go
func main() {
    naturals := make(chan int)
    squares := make(chan int)

    // Counter
    go func() {
        for x := 0; x < 100; x++ {
            naturals <- x
        }
        close(naturals)
    }()

    // Squarer
    go func() {
        for x := range naturals {
            squares <- x * x
        }
        close(squares)
    }()

    // Printer (in main goroutine)
    for x := range squares {
        fmt.Println(x)
    }
}

```

其实并不需要关闭每一个channel。只有当需要告诉接收者goroutine，所有的数据已经全部发送完时才需要关闭channel。不管一个channel是否被关闭，当它没有被引用时将会被Go语言的垃圾回收器回收。

### 10.2.3. 单方向的通道

当一个channel作为一个函数参数时，它一般总是被专门用于只发送或者只接收。为了表明这种意图并防止被滥用，Go语言的类型系统提供了单方向的channel类型，分别用于只发送或只接收的channel。

-   类型`chan<- int`表示一个只发送int的channel，只能发送不能接收。
-   类型`<-chan int`表示一个只接收int的channel，只能接收不能发送。
-   这种限制将在编译期检测。

上一节的例子中使用了三个goroutine，然后用两个channels来连接它们，它们都是main函数的局部变量。可以把三个goroutine拆分为以下三个函数，代码如下：

```go
func counter(out chan<- int) {
    for x := 0; x < 100; x++ {
        out <- x
    }
    close(out)
}

func squarer(out chan<- int, in <-chan int) {
    for v := range in {
        out <- v * v
    }
    close(out)
}

func printer(in <-chan int) {
    for v := range in {
        fmt.Println(v)
    }
}

func main() {
    naturals := make(chan int)
    squares := make(chan int)
    go counter(naturals)
    go squarer(squares, naturals)
    printer(squares)
}

```

注意，三个函数都使用了单方向的通道类型：

-   counter函数使用了用于只发送的通道`chan<- int`。
-   printer函数使用了用于只接收的通道`chan<- int`。
-   squarer函数既使用了使用了用于只发送的通道，也使用了用于只接收的通道。

双向channel向单向channel变量的赋值操作将导致该隐式转换。比如，调用counter时，naturals的类型将隐式地从`chan int`转换成`chan<- int`。需要注意的是，没有反向转换的语法，也就是不能将一个类似`chan<- int`类型的单向型的channel转换为`chan int`类型的双向型的channel。

最后，因为关闭操作只用于断言不再向channel发送新的数据，所以只有在发送者所在的goroutine才会调用close函数，因此对一个只接收的channel调用close函数将是一个编译错误。

### 10.2.4. 带缓存的通道

带缓存的通道内部持有一个元素队列。队列的最大容量是在调用make函数创建channel时通过第二个参数指定的。

使用make函数创建一个可以持有3个字符串元素的带缓存Channel，通过内置的len函数和cap函数可以分别获取其拥有的元素个数和容量。

```go
ch = make(chan string, 3)
fmt.Println(len(ch)) // "0"
fmt.Println(cap(ch)) // "3"

```

向缓存Channel的发送操作就是向内部缓存队列的尾部插入元素，接收操作则是从队列的头部删除元素。

-   如果通道的内部缓存队列是满的，那么
    -   发送操作将阻塞，直到有另一个goroutine执行接收操作而释放了新的队列空间。
    -   接收操作将不会阻塞，而是立即接收到队列的第一个元素。
-   如果通道的内部缓存队列是空的，那么
    -   发送操作不会阻塞，而且可以连续发送和容量相等数量的元素。
    -   接收操作将阻塞，直到有另一个goroutine执行发送操作而向队列插入元素。
-   如果通道的内部队列既不是满的也不是空的，
    -   对该channel执行的发送或接收操作都不会发生阻塞。通过这种方式，channel的缓存队列解耦了接收和发送的goroutine。

注意，不应该把带缓存的通道当作同一个goroutine中的队列使用。虽然语法看似简单，但实际上这是一个错误。channel和goroutine的调度器机制是紧密相连的，如果没有其他goroutine从channel接收，发送者——或许是整个程序——将会面临永远阻塞的风险。

如果在一个goroutine 中向一个无缓存的channel发送数据，并且没有其他goroutine对该channel执行接收操作，那么这个goroutine将会被永远卡住。这种情况，称为goroutines泄漏。和垃圾变量不同，泄漏的goroutines并不会被自动回收，因此确保每个不再需要的goroutine能正常退出是重要的。

关于无缓存或带缓存channels之间的选择，或者是带缓存channels的容量大小的选择，都可能影响程序的正确性。无缓存channel更强地保证了每个发送操作与相应的同步接收操作；但是对于带缓存channel，这些操作是解耦的。同样，即使我们知道将要发送到一个channel的信息的数量上限，创建一个对应容量大小的带缓存channel也是不现实的，因为这要求在执行任何接收操作之前缓存所有已经发送的值。如果未能分配足够的缓存将导致程序死锁。

> Uber Go语言指南推荐，通道要么是无缓存的，要么缓存容量为1。
> [https://github.com/xxjwxc/uber\_go\_guide\_cn#channel-的-size-要么是-1要么是无缓冲的](https://github.com/xxjwxc/uber_go_guide_cn#channel-的-size-要么是-1要么是无缓冲的 "https://github.com/xxjwxc/uber_go_guide_cn#channel-的-size-要么是-1要么是无缓冲的")

### 总结

channel的操作包括创建channel、关闭channel以及接收操作和发送操作。对于后三个操作，

| 操作           | nil channel | closed channel | not nil, not closed                                    |
| ------------ | ----------- | -------------- | ------------------------------------------------------ |
| close        | panic       | panic          | 正常关闭                                                   |
| 接收操作 <-ch    | 阻塞          | 返回对应类型的零值      | 阻塞或正常读取数据。缓冲型 channel 为空或非缓冲型 channel 没有等待发送者时会阻塞。     |
| 发送操作ch<-data | 阻塞          | panic          | 阻塞或正常写入数据。非缓冲型 channel 没有等待接收者或缓冲型 channel buf 满时会被阻塞。 |

总结一下，发生 panic 的情况有三种：关闭一个 nil 的 channel；关闭一个已经关闭的channel；向一个关闭的 channel 进行写操作。另外，读、写一个 nil channel 都会被阻塞。

## 10.3. 基于select的多路复用

为了实现多路复用（multiplex），Go语言使用select语句同时监测多个事件：

```go
select {
case <-ch1: // 1
    // ...
case x := <-ch2: // 2
    // ...use x...
case ch3 <- y: // 3
    // ...
default:
    // ...
}
```

和switch语句相似，select语句也可以包含零个或多个case分支，以及最后的default分支。

-   每一个case包含了一个发送或者接收操作，此时这两种操作都是非阻塞型的。
    -   接收操作：可能只包含接收表达式自身（不使用从通道接收到的数据），就像上面的第1个case；可能包含在一个简短的变量声明中，像第2个case里一样，这种形式能够引用接收到的值。
    -   发送操作：就像第3个case里一样。
-   default分支也可以包含一些语句，用于避免select语句的阻塞。
-   一个没有任何case或defaul分支的select语句写作select{}，会永远地等待下去。

select语句会监测每一个case的通信操作：

-   当一个case的条件满足时，select才会选择该case并执行case之后的语句。此时，其它case是不会执行的。
-   当多个case的条件同时满足时，select会随机选择一个case并执行case之后的语句。这样可以保证每一个case都有相等的被select的机会。
-   如果没有任何case的条件满足且select语句没有最后的default分支，那么select语句会一直阻塞。为了避免阻塞，可以增加一个default分支，来设置一些默认的逻辑。

举例，下面的代码使用select语句和缓存容量为1 的通道，输出偶数。

```go
ch := make(chan int, 1)
for i := 0; i < 10; i++ {
    select {
    case x := <-ch:
        fmt.Println(x) // "0" "2" "4" "6" "8"
    case ch <- i:
    }
}

```

因为通道的缓存大小是1，所以会交替的为空或为满，所以只有一个case可以进行下去，无论i是奇数或者偶数，它都会打印0 2 4 6 8。

举例，下面的select语句会在abort channel中有值时，从其中接收值；无值时什么都不做。这是一个非阻塞的接收操作。反复地做这样的操作叫做“轮询channel”。

```go
select {
case <-abort:
    fmt.Printf("Launch aborted!\n")
    return
default:
    // do nothing
}

```

因为channel的零值是nil，再加上对一个nil的channel发送和接收操作会永远阻塞，所以在select语句中操作nil的channel永远都不会被select到。这使得我们可以用nil来激活或者禁用case，来达成处理其它输入或输出事件时超时和取消的逻辑。

## 10.4. Goroutine和线程

### 10.4.1. 动态栈

操作系统线程一般有一个固定大小的内存块（一般会是2MB）来做栈，这个栈会用来存储当前正在被调用或挂起（指在调用其它函数时）的函数的内部变量。然而在绝大多数情况下，操作系统线程用不了这么多内存，这导致了浪费；另一方面，操作系统线程的栈内存空间在创建和初始化完成之后，其大小就不能再有变化，这导致了在某些特殊场景下（比如深层次的递归函数）有溢出的风险。

相反，一个goroutine会以一个很小的栈开始其生命周期，一般只需要2KB。一个goroutine的栈，和操作系统线程一样，会保存其活跃或挂起的函数调用的本地变量。和操作系统线程不太一样的是，goroutine的栈大小并不是固定的，而是会根据需要动态地伸缩。goroutine的栈的最大值可以达到1GB，比传统的固定大小的线程栈要大得多，尽管一般情况下，大多数goroutine都不需要这么大的栈。

### 10.4.2. Goroutine调度

简单来说，操作系统线程会被操作系统内核调度。每几毫秒，一个硬件计时器会中断处理器，操作系统内核检查线程列表并决定下一次哪个线程可以被运行，然后从内存中恢复执行该线程的现场（比如该线程的寄存器信息）并执行线程。也就是说，从一个线程切换到另一个线程需要完整的上下文切换。操作系统保存一个用户线程的状态到内存，恢复另一个线程的状态，然后更新调度器的数据结构。这几步操作很慢，因为其需要几次内存访问，并且会增加运行的CPU周期。

然而，Go运行时实现了自己的调度器。这个调度器使用了一些技术手段，比如 M:N调度，因为其会在N个操作系统线程上多工（调度）M个goroutine。Go调度器的工作和内核的调度是相似的，但是这个调度器只关注单独的Go程序中的goroutine。

和操作系统的线程调度不同的是，Go调度器并不是用一个硬件定时器，而是被Go语言本身进行调度的。例如当一个goroutine调用了time.Sleep，或者被channel调用或者mutex操作阻塞时，调度器会使其进入休眠并开始执行另一个goroutine，直到时机到了再去唤醒第一个goroutine。因为这种调度方式不需要进入内核的上下文，所以重新调度一个goroutine比调度一个线程代价要低得多。

### 10.4.3. GOMAXPROCS

Goroutine调度器使用了一个叫做GOMAXPROCS的变量来决定会有多少个操作系统的线程同时执行Go的代码。默认的值是运行机器上的CPU的核心数，所以在一个有8个核心的机器上时，调度器一次会在8个操作系统线程上去调度Go代码。在休眠中的或者在通信中被阻塞的goroutine是不需要一个对应的线程来做调度的。在I/O中或系统调用中或调用非Go语言函数时，是需要一个对应的操作系统线程的，但是GOMAXPROCS并不需要将这几种情况计算在内。

可以用GOMAXPROCS的环境变量来显式地控制这个参数，或者也可以在运行时用runtime.GOMAXPROCS函数来修改它。比如：

```go
func main() {
  for {
    go fmt.Print(0)
    fmt.Print(1)
  }
}

// shell
$ GOMAXPROCS=1 go run main.go
111111111111111111110000000000000000000011111...

$ GOMAXPROCS=2 go run main.go
010101010101010101011001100101011010010100110...

```

在第一次执行时，最多同时只能有一个goroutine被执行。初始情况下只有main goroutine被执行，所以会打印很多1。过了一段时间后，Go调度器会将其置为休眠，并唤醒另一个goroutine，这时候就开始打印很多0。在打印的时候，goroutine是被调度到操作系统线程上的。

在第二次执行时，我们设置GOMAXPROCS=2，所以最多有两个goroutine可以一起被执行，以同样的频率交替打印0和1。需要强调的是，goroutine的调度是受很多因子影响的，而且Go语言的runtime也是在不断地发展演进的，所以实际得到的结果可能会因为版本的不同而有所不同。

### 10.4.4. Goroutine没有ID

在大多数支持多线程的操作系统和程序语言中，当前的线程都有一个独特的身份（id），并且这个身份信息可以以一个普通值的形式被很容易地获取到，典型的可以是一个integer或者指针值。这种情况下我们做一个抽象化的thread-local storage（线程本地存储，多线程编程中不希望其它线程访问的内容）就很容易，只需要以线程的id作为key的一个map就可以解决问题，每一个线程以其id就能从中获取到值，且和其它线程互不冲突。

goroutine没有可以被程序员获取到的身份（id）的概念。这一点是设计上故意而为之，由于thread-local storage总是会被滥用。

## 定时器Timer

> [https://my.oschina.net/renhc/blog/3026957](https://my.oschina.net/renhc/blog/3026957 "https://my.oschina.net/renhc/blog/3026957")
> [https://juejin.cn/post/7028191842629845029](https://juejin.cn/post/7028191842629845029 "https://juejin.cn/post/7028191842629845029")

Timer是一种单一事件定时器。在指定的时间到达时，Timer定时器会触发一个事件，这个事件通过其本身的 channel 进行通知。之所以叫单一事件，是因为 Timer 只执行一次就结束。

Timer的源码定义在`src/time/sleep.go`中，如下所示：

```go
type Timer struct {
  C <-chan Time
  r runtimeTimer
}
```

可以看出，Timer 直接对外暴露了其中的channel，所以使用者可以直接使用这个channel。

通过 timer.NewTimer(d Duration) 函数可以创建一个Timer定时器，并传入一个时间间隔。

### 使用场景

#### 延迟执行一个方法

延迟执行一个方法是最简单的使用场景。

代码如下所示：

```go
func DelayFunction() {
  timer := time.NewTimer(5 * time.Second)

  select {
  case <-timer.C:
    log.Println("Delayed 5s, start to do something.")
  }
}

```

#### 设定超时时间

举个例子，假设我们需要从一个通道中读取数据，但是又不想等待太长时间。于是，我们可以设定一个超时时间，如果在超时时间到达之前，通道中仍然没有数据，那我们就可以返回读取失败。

Go 语言的源码中有大量类似的用法，比如从一个连接中等待数据，

```go
func WaitChannel(conn <-chan string) bool {
  timer := time.NewTimer(1 * time.Second)

  select {
  case <-conn:
    timer.Stop()
    return true
  case <-timer.C: // 超时
    println("WaitChannel timeout!")
    return false
  }
}
```

WaitChannel 函数的作用就是检测指定的连接中是否有数据，通过 select 语句轮询 conn 和 timer.C 两个通道。因为timer 会在 1s 后向 timer.C 写入数据，所以如果 conn 通道在1s内还没有数据，那么就会判断为超时。

### 方法介绍

1）创建定时器

使用 `func NewTimer(d Duration)` 函数可以创建一个 Timer，Timer 一经创建便开始计时，不需要额外的启动命令。

实际上，创建 Timer 意味着把一个计时任务交给系统守护协程，该协程管理着所有的 Timer，当 Timer 的时间到达后向 Timer 的管道中发送当前的时间作为事件。

2）停止定时器

3）重置定时器

4）time.After函数

5）time.AfterFunc函数

### 底层实现原理

创建 Timer 意味着把一个计时任务交给系统守护协程，该协程管理着所有的 Timer，当 Timer 的时间到达后向 Timer 的管道中发送当前的时间作为事件。

维护一个定时器的最小堆结构。

TODO

## 定时器Ticker

> [https://www.cnblogs.com/failymao/p/15068712.html](https://www.cnblogs.com/failymao/p/15068712.html "https://www.cnblogs.com/failymao/p/15068712.html")
> [https://my.oschina.net/renhc/blog/3031561](https://my.oschina.net/renhc/blog/3031561 "https://my.oschina.net/renhc/blog/3031561")

Ticker是一种周期性定时器，即周期性的触发一个事件，这个事件通过Ticker本身提供的管道将事件传递出去。

Ticker的源码定义在`src/time/tick.go`中，如下所示：

```go
type Ticker struct {
  C <-chan Time // The channel on which the ticks are delivered.
  r runtimeTimer
}
```

可以看出，Ticker 直接对外暴露了其中的channel，所以使用者可以直接使用这个channel。

通过 timer.NewTicker(d Duration) 函数可以创建一个Ticker定时器，并传入一个时间间隔，作为事件触发的周期。

### 使用场景

#### 定期执行一个任务

比如，定期输出一行日志，

```go
func TickerDemo() {
    ticker := time.NewTicker(1 * time.Second)
    defer ticker.Stop()
 
    for range ticker.C {
        log.Println("Ticker tick.")
    }
}
```

#### 定期处理聚合任务

有时我们希望把一些任务打包进行批量处理。比如，公交车发车场景：

-   公交车每隔5分钟发一班，不管是否已坐满乘客。
-   已经坐满乘客情况下，不足五分钟也发车。

代码如下所示：

```go
func TickerDemoBatchJob() {
  ticker := time.NewTicker(5 * time.Minute)
  maxPassenger := 30 // 每车最大装载人数
  passengers := make([]string, 0, maxPassenger)

  for {
    passenger := GetNewPassenger() // 获取一个新乘客
    if passenger != "" {
      passengers = append(passengers, passenger)
    } else {
      time.Sleep(1 * time.Second)
    }

    select {
    case <-ticker.C: // 时间到，发车
      fmt.Println("Bus will launch!")
      passengers = []string{}
    default:
      if len(passengers) >= maxPassenger { // 时间没到，车已座满，发车
        fmt.Println("Bus is full and will launch now!")
        passengers = []string{}
      }
    }
  }
}
```

### 方法介绍

1）创建定时器

2）停止定时器

### 底层实现原理

TODO

## context

> [https://zhuanlan.zhihu.com/p/553611389](https://zhuanlan.zhihu.com/p/553611389 "https://zhuanlan.zhihu.com/p/553611389")
> [https://go.cyub.vip/concurrency/context.html](https://go.cyub.vip/concurrency/context.html "https://go.cyub.vip/concurrency/context.html")

context是由Go语言在 1.7 版本引入的上下文控制包。这个包提供了上下文接口Context和一些函数，可以用来为goroutine设置一个超时时间，或者传递一些共享信息。

context.Context是一个接口，该接口定义了四个方法：

```go
type Context interface {
    Deadline() (deadline time.Time, ok bool)
    Done() <-chan struct{}
    Err() error
    Value(key interface{}) interface{}
}
```

解释：

-   Deadline：返回绑定该context任务的执行超时时间，若未设置，则ok等于false。
-   Done：返回一个只读通道，当绑定在该context的任务执行完成或者任务执行超时的时候，该通道会被关闭。多次调用 `Done` 方法会返回同一个 Channel。
-   Err：返回一个错误，如果Done返回的通道未关闭则返回nil,如果context如果被取消，返回Canceled错误，如果超时则会返回DeadlineExceeded错误。
-   Value：根据key返回存储在context中k-v数据。

另外context包还提供了 几个函数用来返回一个新的Context：

```go
func Background() Context
func TODO() Context 
func WithCancel(parent Context) (ctx Context, cancel CancelFunc)
func WithDeadline(parent Context, d time.Time) (Context, CancelFunc)
func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) 
func WithValue(parent Context, key, val any) Context

```

解释：

-   Background：返回私有变量background。注意，返回的Context是不会被取消的，也没有deadline。如果在主函数中需要一个Context，可使用这个方法获得。
-   TODO：返回私有变量todo。如果不确定要使用哪一个context，可以使用这个方法返回一个新的context。
-   WithCancel：返回一个传入的context参数的副本。
-   WithDeadline：返回一个传入的context参数的副本，并且给副本设置一个deadline。
-   Timeout：相当于`WithDeadline(parent, time.Now().Add(timeout))`。
-   WithValue：返回一个传入的context参数的副本，并且给副本设置一个key-value。

可以看出，创建一个新的context，要么使用Background或TODO方法返回一个新的context，要么就必须基于一个父context。因为新的context又可以作为其他context的父context，所以有父子关系的context在一起可以构造成一个context树。

### 用途

context包主要有两个用途：超时控制和传递共享信息。

#### 超时控制

如果超时就取消当前的goroutine，减少资源浪费。

举例，

```go
func main() {
  ctx, cancel := context.WithTimeout(context.Background(), time.Second*5)
  defer func() {
    log.Println("Canceling")
    cancel()
  }()
  
  doSomething(ctx)
}

func doSomething(ctx context.Context) {
  done := make(chan int, 1)
  go func() { // 模拟慢操作
    log.Println("Start working...")
    time.Sleep(time.Second * 10)
    done <- 1
  }()

  select {
  case <-ctx.Done():
    log.Println("Context done")
    log.Println("SlowOperation timeout:", ctx.Err())
    return
  case <-done:
    log.Println("Finish work")
  }
}

// 2023/01/12 17:33:35 Start working...
// 2023/01/12 17:33:40 Context done
// 2023/01/12 17:33:40 SlowOperation timeout: context deadline exceeded
// 2023/01/12 17:33:40 Canceling
```

#### 传递共享信息

举例，

```go
func main() {
  ctx := context.WithValue(context.Background(), "name", "CONTEXT")
  passValue(ctx)
}

func passValue(ctx context.Context) {
  log.Println("passValue receiving", ctx.Value("name"))
  ctx = context.WithValue(ctx, "grade", 100)
  passValue2(ctx)
}

func passValue2(ctx context.Context) {
  log.Println("passValue2 receiving", ctx.Value("name"))
  log.Println("passValue2 receiving", ctx.Value("grade"))
}

```

### 底层结构和原理

context包一共有4个类型实现了Context接口, 分别是emptyCtx, cancelCtx,timerCtx,valueCtx。每个类型都关联一个创建方法。

#### emptyCtx

emptyCtx是int类型，emptyCtx实现了Context接口，是一个空context，只能作为根context。

```go
type emptyCtx int

func (*emptyCtx) Deadline() (deadline time.Time, ok bool) {
  return
}

func (*emptyCtx) Done() <-chan struct{} {
  return nil
}

func (*emptyCtx) Err() error {
  return nil
}

func (*emptyCtx) Value(key interface{}) interface{} {
  return nil
}

func (e *emptyCtx) String() string {
  switch e {
  case background:
    return "context.Background"
  case todo:
    return "context.TODO"
  }
  return "unknown empty Context"
}
```

Background和TODO函数返回了一个新的emptyCtx。

```go
var (
  background = new(emptyCtx)
  todo       = new(emptyCtx)
)

func Background() Context {
  return background
}

func TODO() Context {
  return todo
}
```

Background用于创建根context，一般用于主函数、初始化和测试中，我们使用的context一般都是基于Bacground创建的。TODO主要是当我们不确定使用什么样的context的时候使用。

#### cancelCtx

cancelCtx支持取消操作，取消同时也会对实现了canceler接口的子代进行取消操作。我们来看下cancelCtx结构体和cancelceler接口：

```go
type cancelCtx struct {
  Context
  mu       sync.Mutex
  done     chan struct{}
  children map[canceler]struct{}
  err      error
}

type canceler interface {
  cancel(removeFromParent bool, err error)
  Done() <-chan struct{}
}
```

解释：

-   Context变量存储其父context。
-   done变量定义了一个通道，并且只在第一次取消调用才关闭此通道。该通道是惰性创建的。
-   children是一个映射类型，用来存储其子context中实现的canceler方法。当该context取消时候，会遍历该映射来让子代context进行取消操作。
-   err记录错误信息，默认是nil，仅当第一次cancel调用时候，才会设置。

cancelCtx实现了Done、Err和cancel方法。

WithCancel会创建一个新的cancelCtx，以及它关联的取消函数。

```go
func WithCancel(parent Context) (ctx Context, cancel CancelFunc) {
  if parent == nil {
    panic("cannot create context from nil parent")
  }
  c := newCancelCtx(parent)
  propagateCancel(parent, &c)
  return &c, func() { c.cancel(true, Canceled) }
}

// newCancelCtx returns an initialized cancelCtx.
func newCancelCtx(parent Context) cancelCtx {
  return cancelCtx{Context: parent}
}
```

#### timerCtx

timerCtx是基于cancelCtx的context类型，它支持过期取消。

WithDeadline会创建一个timerCtx，以及它关联的取消函数。

WithTimeout用来创建超时就会取消的context，内部实现就是WithDealine，传递给WithDealine的过期时间就是当前时间加上timeout时间。

#### valueCtx

valueCtx是可以传递共享信息的Context实现。

```go
type valueCtx struct {
  Context
  key, val interface{}
}

func (c *valueCtx) Value(key interface{}) interface{} {
  if c.key == key { 
    return c.val
  }
  
  return c.Context.Value(key)
}
```

解释：valueCtx中的Context变量存储其父context。

对于Value方法，如果当前context不存在该key，则会沿着context树，向上递归查找，直到查找到根context，最后返回nil。

WithValue函数用来向context变量中添加个一个key/value对。具体来说，WithValue根据父Context创建了一个子Context，代码如下：

```go
// WithValue returns a copy of parent in which the value associated with key is
// val.
func WithValue(parent Context, key, val interface{}) Context {
  if key == nil {
    panic("nil key")
  }
  if !reflectlite.TypeOf(key).Comparable() {
    panic("key is not comparable")
  }
  return &valueCtx{parent, key, val}
}
```

注意：如果key是不可以比较的时候，则会发生panic。

### 总结

Context一共有4个类型实现了Context接口, 分别是emptyCtx、cancelCtx、timerCtx和valueCtx。

它们的创建方法和功能如下：

| 类型        | 创建方法                          | 功能                     |
| --------- | ----------------------------- | ---------------------- |
| emptyCtx  | Background()/TODO()           | 用做context树的根节点         |
| cancelCtx | WithCancel()                  | 可取消的context            |
| timerCtx  | WithDeadline()/WithTimeout()	 | 可取消的context，过期或超时会自动取消 |
| valueCtx  | WithValue()                   | 可存储共享信息的context        |

Context实现了两种方向的递归操作：

| 递归操作 | 目的                                                                            |
| ---- | ----------------------------------------------------------------------------- |
| 向下递归 | 当对父Context进去手动取消操作，或超时取消时候，向下递归处理对实现了canceler接口的后代进行取消操作。                     |
| 向上递归 | 当对Context查询Key信息时候，若当前Context没有当前K-V信息时候，则向父辈递归查询，一直到查询到跟节点的emptyCtx，返回nil为止。 |

使用Context有几个规范：

1）不要将Context作为结构体的一个字段存储，相反而应该显示传递Context给每一个需要它的函数，Context应该作为函数的第一个参数，并命名为ctx。

2）不要传递一个nil Context给一个函数，即使该函数能够接受它。如果你不确定使用哪一个Context，那你就传递context.TODO。

3）context是并发安全的，相同的Context能够传递给运行在不同goroutine的函数。

## 常见面试题

### 如果其中一个goroutine发生panic会影响其他goroutine吗？

如果一个goroutine发生panic，那么其余goroutine也会退出，程序也会退出。如果不想程序退出，那么必须通过defer延迟调用和recover函数来捕获 panic 并恢复程序。

### defer延迟调用和recover函数可以捕获子goroutine发生的panic吗？

不可以。defer和 recover函数机制只能捕获当前goroutine的panic。

### goroutine死锁有哪些情况？

goroutine死锁错误是：fatal error: all goroutines are asleep - deadlock!。

#### channel阻塞

1）对于无缓冲的channel，如果只有发送数据的操作或只有接收数据操作，会发生死锁。

代码如下：

```go
func send() {
  q := make(chan int)
  q <- 1 // send data
}

func receive() {
  q := make(chan int)
  <- q // receive data
}

```

2）对于有缓冲的channel，

-   如果channel是空的，只有接收操作会发生死锁。
-   如果channel是满的，只有发送操作会发生死锁。

代码如下：

```go
func send() {
  q := make(chan int, 2)
  q <- 1
  q <- 2
  q <- 3
}

func receive() {
  q := make(chan int, 2)
  <-q
}

```

解决死锁的方法通常是使用select语句，监听接收操作和发送操作。

#### 互斥锁阻塞

多个goroutine持有了互斥锁，同时等待获取其他互斥锁，产生循环等待的情况。

对于两个goroutine，二者都在等待获取对方持有的互斥锁，导致死锁。代码如下：

```go
func main() {
  var mu1 sync.Mutex
  var mu2 sync.Mutex
  var wg sync.WaitGroup
  wg.Add(2)

  go func() {
    defer wg.Done()

    mu1.Lock()
    defer mu1.Unlock()

    fmt.Println("goroutine1 get lock-1")
    time.Sleep(time.Second * 1)

    mu2.Lock()
    defer mu2.Unlock()

    fmt.Println("goroutine1 get lock-2")
  }()

  go func() {
    defer wg.Done()

    mu2.Lock()
    defer mu2.Unlock()

    fmt.Println("goroutine2 get lock-2")
    time.Sleep(time.Second * 1)

    mu2.Lock()
    defer mu2.Unlock()

    fmt.Println("goroutine2 get lock-1")
  }()

  wg.Wait()
}

// fatal error: all goroutines are asleep - deadlock!
```

#### 无法recover

需要注意的是，这种严重错误并不是panic，无法通过defer和recover恢复。

代码如下：

```go
func main() {
  defer func() {
    if err := recover(); err != nil {
      fmt.Println("got panic")
    }
  }()

  ch := make(chan int)
  ch <- 1

  fmt.Println("end")
}

// result:
// fatal error: all goroutines are asleep - deadlock!
```

### 通道的底层实现和原理

通道底层使用了循环数组和双向链表。循环数组可以看作一个队列，用于存放channel中的元素，不过只有有缓冲的channel才有循环数组。双向链表用于记录被阻塞的goroutine，这些goroutine由于从channel接收数据或向 channel 发送数据而被阻塞。

先看一下Channel底层的数据结构：

```go
// runtime/chan.go

type hchan struct {
  qcount   uint           // total data in the queue
  dataqsiz uint           // size of the circular queue
  buf      unsafe.Pointer // points to an array of dataqsiz elements
  elemsize uint16
  closed   uint32
  elemtype *_type // element type
  sendx    uint   // send index
  recvx    uint   // receive index
  recvq    waitq  // list of recv waiters
  sendq    waitq  // list of send waiters

  lock mutex
}

type waitq struct {
  first *sudog
  last  *sudog
}

type sudog struct {
  // The following fields are protected by the hchan.lock of the
  // channel this sudog is blocking on. shrinkstack depends on
  // this for sudogs involved in channel ops.

  g *g

  next *sudog
  prev *sudog
  elem unsafe.Pointer // data element (may point to stack)

  // The following fields are never accessed concurrently.
  // For channels, waitlink is only accessed by g.
  // For semaphores, all fields (including the ones above)
  // are only accessed when holding a semaRoot lock.

  acquiretime int64
  releasetime int64
  ticket      uint32

  // isSelect indicates g is participating in a select, so
  // g.selectDone must be CAS'd to win the wake-up race.
  isSelect bool

  // success indicates whether communication over channel c
  // succeeded. It is true if the goroutine was awoken because a
  // value was delivered over channel c, and false if awoken
  // because c was closed.
  success bool

  parent   *sudog // semaRoot binary tree
  waitlink *sudog // g.waiting list or semaRoot
  waittail *sudog // semaRoot
  c        *hchan // channel
}

```

Channel的结构如下图所示：

![image_wPLhSgt7TB](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202311252033791.png)

解释：

-   qcount表示channel中的元素数量。
-   dataqsiz表示循环数组的容量大小。如果dataqsiz=0表示无缓冲的channel，反之表示有缓冲的channel。
-   buf是一个指针，指向底层数组，只用于有缓冲的 channel 。该数组与sendx和recvx配合实现了一个循环数组，所以可以看作为一个队列。
-   closed用来记录channel是否已经关闭。如果closed=0，表示channel未关闭，反之表示已关闭。
-   sendx和recvx表示底层循环数组的下标，表示当前可以发送和接收的数据位置索引值。二者与数组buf配合实现了一个循环数组，使该数组可以被看作成一个队列。另外，sendx和recvx可以分别被认为是队列尾部和头部的位置。
-   sendq和recvq的底层是双向链表，用于记录被阻塞的goroutine。其中sendq用于记录由于向channel 发送数据被阻塞的 goroutine，recvq用于记录由于从 channel接收数据被阻塞的 goroutine。二者可以分别称为等待发送队列和等待接收队列。
-   lock 是互斥锁，用于保证channel的接收操作和发送操作都是并发安全的。

#### **创建Channel**

创建Channel底层使用的是makechan函数。

```go
func makechan(t *chantype, size int64) *hchan
```

该函数创建了一个实例hchan结构体并返回指针，所以我们能在函数中直接传递 channel本身，而不用传递 channel 的指针。

创建Channel时会做一些检查：

-   元素大小不能超过 64K。
-   元素的对齐大小不能超过 maxAlign 也就是 8 字节。
-   计算出来的内存是否超过限制。

创建Channel的策略包括：

-   如果是无缓冲的 channel，会直接给 hchan 分配内存。
-   如果是有缓冲的 channel，并且元素不包含指针，那么会为 hchan 和底层数组分配一段连续的地址。
-   如果是有缓冲的 channel，并且元素包含指针，那么会为 hchan 和底层数组分别分配地址。

#### **发送操作**

> [https://golang.design/go-questions/channel/send/](https://golang.design/go-questions/channel/send/ "https://golang.design/go-questions/channel/send/")

发送操作会由编译器转化为 chansend 函数。该函数有4个参数和1个返回值，其中返回值表示是否发送成功。

```go
func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool
```

发送操作分为阻塞式发送和非阻塞式发送，可以由chansend的第三个参数用来决定。如果block=true，即为阻塞式发送，反之为非阻塞式发送。

1）阻塞式发送是最简单的发送操作。如果发送操作无法执行，会阻塞当前goroutine，直到发送成功或出错。

```go
ch <- 10
```

2）非阻塞式发送是在select中的发送操作。如果发送操作无法执行，就跳过当前操作。

```go
select {
    case ch <- 10:
    default:
}
```

总结，发送操作的流程大致包括：

1）检查channel是否是nil，

-   如果channel是nil，检查是否是阻塞式发送。
    -   如果block=false，即非阻塞式发送，那么就立即返回false，表示无法发送。这意味着select不会该case。
    -   如果block=true，即阻塞式发送，那么无法发送，而且会触发一个致命错误：`fatal error: all goroutines are asleep - deadlock!`。
-   如果channel不是nil。如果block=false，即非阻塞式发送，快速检测一种失败的场景： channel 未关闭（c.closed == 0）并且 channel 没有多余的空间，那么就立即返回false，表示无法发送。
    -   检查条件为`!block && c.closed == 0 && ((c.dataqsiz == 0 && c.recvq.first == nil) || (c.dataqsiz > 0 && c.qcount == c.dataqsiz))`。
    -   channel 没有多余的空间有两种情况：一是channel 是无缓冲的，且等待接收队列里没有 goroutine；二是channel 是有缓冲的，但循环数组buf已经装满了数据。

2）使用channel的lock字段进行加锁。

3）如果channel已经关闭（channel.closed != 0），解锁并触发panic异常。因为向一个已经关闭的channel会导致panic异常。

4）如果channel没有关闭，检查channel的等待接收队列recvq是否存在等待接收数据的goroutine：

-   如果等待接收队列recvq存在等待的接收者，此时有两种情况：
    -   如果是没有缓冲的channel，那么就通过内存拷贝直接把数据发送给第一个等待的goroutine，唤醒该goroutine使其接收数据，继续运行。
    -   如果是有缓冲的channel，说明channel中没有数据，就通过内存拷贝直接把数据发送给等待接收数据的goroutine。注意，此时仍然会修改sendx和recvx变量，假装这个数据经过了channel数组。
-   如果等待接收队列recvq不存在接收者，检查循环数组buf是否还有空间（此时只能是有缓冲的channel）。
    -   如果还有空间，就把数据放在队列尾部，循环数组中的数据个数qcount加一。
    -   如果循环数组buf已满，检查是否是阻塞式发送。
        -   如果block=false，即非阻塞式发送，解锁并返回false，表示无法发送。
        -   如果block=true，那么发送操作就会被阻塞（即阻塞发送的流程），将当前 goroutine 加入发送等待队列sendq，并把当前goroutine设置为waiting状态，即挂起等待唤醒。

#### **接收操作**

接收操作有两种写法，一种不带 “ok”，另一种带 “ok”，true表示成功从channels接收到值，false表示channels已经被关闭并且里面没有值可接收。两种写法，都有各自的应用场景。

接收操作会由编译器转化为 chanrecv1和chanrecv2 函数，二者分别用于不带 “ok” 和带 “ok” 的情形。chanrecv2函数通过返回 received返回值来反应** channel 是否被关闭并且接收操作真的返回了channel中的数据**。而接收值则比较特殊，会“放到”参数 elem 所指向的地址了，这很像 C/C++ 里的写法。如果代码里忽略了接收值，这里的 elem 为 nil。

```go
func chanrecv1(c *hchan, elem unsafe.Pointer) {
  chanrecv(c, elem, true)
}

func chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) {
  _, received = chanrecv(c, elem, true)
  return
}
```

无论如何，chanrecv1和chanrecv2 函数最终都调用了 chanrecv 函数。该函数有两个参数盒两个返回值，其中参数block用来表示是阻塞式的接收操作。

```go
func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool)
```

接收操作也可以分为阻塞式接收和非阻塞式接收，可以由chansend的第二个参数用来决定。如果block=true，即为阻塞式接收，反之为非阻塞式接收。

1）阻塞式接收是最简单的接收操作。如果接收操作无法执行，会阻塞当前goroutine，直到接收成功或出错。

```go
res <- ch
res, ok <- ch
```

2）非阻塞式接收是在select中的接收操作。如果接收操作无法执行，就跳过当前操作。

```go
select {
    case res <- ch:
    default:
}
```

总结，接收操作的流程大致包括：

1）检查channel是否是nil。

-   如果channel是nil ，检查是否是阻塞式接收。
    -   如果block=false，即非阻塞式接收，那么就立即返回selected=false和received=false，表示无法发送。这意味着select不会选择该case。
    -   如果block=true，即阻塞式接收，那么无法接收，而且会触发一个致命错误：`fatal error: all goroutines are asleep - deadlock!`。
-   如果channel不是nil。如果block=false，即非阻塞式接收，快速检测一种失败的场景：如果该channel没有对应接收的goroutine或者循环数组没有数据 ，那么就立即返回selected=false和received=false，表示无法接收。
    -   检查条件为`!block && (c.dataqsiz == 0 && c.sendq.first == nil || c.dataqsiz > 0 && atomic.Loaduint(&c.qcount) == 0) && atomic.Load(&c.closed) == 0`
    -   channel 没有数据有两种情况：一是channel 是无缓冲的，且等待发送列队 sendq 里没有 goroutine 在等待；二是channel 是有缓冲的，但循环数组buf里没有数据。

2）使用channel的lock字段进行加锁。

3）如果channel已经关闭（channel.closed != 0）并且channel的循环数组没有任何数据，解锁，设置对应的零值，然后返回selected=true和received=false。因为从已关闭的channel接收数据不会阻塞。

4）如果channel没有关闭，检查channel的等待发送队列sendq是否存在等待发送数据的goroutine：

-   如果等待发送队列sendq存在发送者，此时有两种情况：
    -   如果是没有缓冲的channel，就通过内存拷贝把数据从发送的goroutine发送到接收的goroutine。
    -   如果是有缓冲的channel，说明此时循环数组是满的，那么接收操作会返回队列头部的数据，并将等待发送的数据放到队列尾部。
-   如果等待发送队列sendq不存在发送者，检查循环数组是否有数据。
    -   如果队列有数据，那么就返回selected=true和received=true以及队列头部的数据。
    -   如果队列没有数据，检查是否是阻塞式接收。
        -   如果block=false，即非阻塞式接收，解锁并返回selected=false和received=false，表示无法发送。
        -   如果block=true，那么接收操作就会被阻塞，将当前 goroutine 加入等待接收队列recvq，并把当前goroutine设置为waiting状态，即挂起等待唤醒。

### 协程调度模型GMP

> [https://github.com/LeoYang90/Golang-Internal-Notes/blob/master/Go 协程调度——基本原理与初始化.md](<https://github.com/LeoYang90/Golang-Internal-Notes/blob/master/Go 协程调度——基本原理与初始化.md> "https://github.com/LeoYang90/Golang-Internal-Notes/blob/master/Go 协程调度——基本原理与初始化.md")
> [https://www.cnblogs.com/secondtonone1/p/11803961.html](https://www.cnblogs.com/secondtonone1/p/11803961.html "https://www.cnblogs.com/secondtonone1/p/11803961.html")
> [https://go.cyub.vip/gmp/gmp-model.html](https://go.cyub.vip/gmp/gmp-model.html "https://go.cyub.vip/gmp/gmp-model.html")
> [https://zhuanlan.zhihu.com/p/37754274](https://zhuanlan.zhihu.com/p/37754274 "https://zhuanlan.zhihu.com/p/37754274")

协程调度是指Go语言运行时按照一定的算法在适当的时候挑选出合适的goroutine并放到操作系统线程上去运行的过程，这种算法可以为协程调度机制。

首先，goroutine是Go语言实现的用户态线程，主要用来解决操作系统线程太“重”的问题。所谓的太重，主要表现在以下两个方面：

-   创建和切换太重：操作系统线程的创建和切换都需要进入内核，而进入内核所消耗的性能代价比较高，开销较大；
-   内存分配使用固定的大小且无法改变：操作系统内核在创建操作系统线程时会为其分配一个较大的栈内存（一般是2M），但是很多线程根本不需要这么大的内存；另一方面，操作系统线程的栈内存空间在创建之后，其大小就不能再有变化，这导致了在某些特殊场景下（比如深层次的递归函数）栈有溢出的风险。

相对来说，用户态的goroutine则轻量得多：

-   goroutine是用户态线程，其创建和切换都在用户代码中完成而无需进入操作系统内核，所以其开销要远远小于系统线程的创建和切换；
-   goroutine启动时默认栈大小只有2k，这在多数情况下已经够用了，即使不够用，goroutine的栈也会自动扩大。另外，如果栈太大了过于浪费它还能自动收缩，这样既没有栈溢出的风险，也不会造成栈内存空间的大量浪费。

其次，goroutine建立在操作系统线程基础之上，它与操作系统线程之间实现了一个多对多（M:N）的两级线程模型。这里的 M:N 是指有M个goroutine运行在N个操作系统线程之上，内核负责对这N个操作系统线程进行调度，而这N个系统线程又负责对这M个goroutine进行调度和运行。

具体地，Go语言使用了GMP模型来实现协程调度：

-   Goroutine（简称G）：Goroutine实现的核心结构，它包含了栈，指令指针，以及一些关于调度goroutine的信息，例如其阻塞的channel。
-   Machine（简称M）：Machine表示由操作系统管理的线程，包含了小对象内存cache、当前执行的goroutine、随机数发生器等信息。Machine是利用系统调用创建出来的操作系统线程实体。如果在Linux平台上则是用clone系统调用创建的，本质上与使用Linux pthread库创建出来的线程是一样的。Machine的作用就是执行Goroutine中包装的任务。Goroutine调度器的主要职责就是将Goroutine公平合理的安排到多个Machine上去执行。
-   Processor（简称P）：Processor主要用来执行goroutine，可以成为。它维护了一个goroutine队列，即runqueue。Processor是实现从N:1调度到M:N调度的关键部分。对于Processor而言，其数量一般是CPU核数，不过也可以在程序启动时通过环境变量GOMAXPROCS进行设置，或者在运行时通过调用函数`GOMAXPROCS()`函数进行设置。Processor数量固定意味着任意时刻只有GOMAXPROCS个线程在运行go语言程序。

在 Go 程序启动之后，Go 运行时会尝试建立若干个 Machine，也就是若干个物理线程。每个物理线程在建立之后，都要进入休眠状态。

在Go程序运行期间，如果通过 go 语句创建一个Goroutine，

-   Goroutine会先保存在Processor的局部队列（local queue），如果局部队列已经满了就会保存在全局队列（global queue）。
-   创建 Goroutine 之后，如果有闲置的 P 就会尝试唤醒物理线程M。
-   如果一个物理线程M 从睡眠状态被唤醒，就要绑定一个 P。一个 M 必须持有一个P，M 与 P 是1:1的关系。如果绑定失败，M就要继续休眠，绑定成功就会回到调度函数，尝试获取一个可运行的 G。

总结，Goroutine调度的本质是不断的监控各个线程的运行状况，如果发现某个线程已经阻塞了，那么就唤醒一个已有的线程或者新建一个线程，尝试让操作系统调度这个物理线程跑满所有的 CPU。

#### Goroutine

G有多个状态：

-   Gidle：G被创建但还未完全被初始化。
-   Grunnable：当前G为可运行的，正在等待被运行。
-   Grunning：当前G正在被运行。
-   Gsyscall：当前G正在被系统调用。
-   Gwaiting：当前G正在因某个原因而等待。
-   Gdead：当前G完成了运行。

Goroutine可能在由于以下情况导致被阻塞：

-   用于**原子、互斥量或通道**操作导致goroutine阻塞，调度器将把当前阻塞的goroutine从本地运行队列**LRQ换出**，并重新调度其它goroutine；
-   由于**网络请求**和**IO**导致的阻塞，Go提供了网络轮询器（Netpoller）来处理，后台用epoll等技术实现IO多路复用。

#### Machine

**自旋线程**：处于运行状态但是没有可执行goroutine的线程，数量最多为GOMAXPROC，若是数量大于GOMAXPROC就会进入休眠。

**非自旋线程**：处于运行状态有可执行goroutine的线程。

#### Processor

P有多个状态：

-   \_Pidle ：处理器没有运行用户代码或者调度器，被空闲队列或者改变其状态的结构持有，运行队列为空
-   \_Prunning ：被线程 M 持有，并且正在执行用户代码或者调度器(如上图)
-   \_Psyscall：没有执行用户代码，当前线程陷入系统调用(如上图)
-   \_Pgcstop ：被线程 M 持有，当前处理器由于垃圾回收被停止
-   \_Pdead ：当前处理器已经不被使用。

P的一个优点是避免锁竞争。每个 P 有自己的本地队列，大幅度的减轻了对全局队列的直接依赖，所带来的效果就是锁竞争的减少。

另一个优点是可以提高线程利用率，减轻某个线程过于繁忙或饥饿的情况。 GMP 模型实现了 Work Stealing 算法，如果 P 的本地队列为空，则会从其他 P 的本地队列或全局队列中窃取可运行的 G 来运行，减少空转，提高了资源利用率。

#### 协程调度算法

Go调度器会在以下三种情况对goroutine进行调度：

1.  goroutine执行某个操作因条件不满足需要等待而发生的调度。
2.  goroutine主动调用Gosched()让出CPU而发生的调度。
3.  goroutine运行时间太长或长时间处于系统调用中，被调度器剥夺运行权而发生的调度。

### 如果优雅的关闭一个channel

> [https://golang.design/go-questions/channel/graceful-close/](https://golang.design/go-questions/channel/graceful-close/ "https://golang.design/go-questions/channel/graceful-close/")
> [https://www.jianshu.com/p/d24dfbb33781](https://www.jianshu.com/p/d24dfbb33781 "https://www.jianshu.com/p/d24dfbb33781")

关于 channel 的使用，有几点不方便的地方：

-   在不改变 channel 自身状态的情况下，无法获知一个 channel 是否关闭。
-   关闭一个 closed channel 会导致 panic。所以，如果关闭 channel 的一方在不知道 channel 是否处于关闭状态时就去贸然关闭 channel 是很危险的事情。
-   向一个 closed channel 发送数据会导致 panic。所以，如果向 channel 发送数据的一方不知道 channel 是否处于关闭状态时就去贸然向 channel 发送数据是很危险的事情。

关闭channel有一个基本的原则：

> don’t close a channel from the receiver side and don’t close a channel if the channel has multiple concurrent senders.

不要从一个 receiver 侧关闭 channel，也不要在有多个 sender 时，关闭 channel。另外，向 channel 发送数据的就是 sender，因此只有sender 可以决定何时不发送数据，然后关闭 channel。但是如果有多个 sender，某个 sender 同样没法确定其他 sender 的情况，这时也不能贸然关闭 channel。

但是上面所说的并不是最本质的，最本质的原则就只有一条：

> don’t close (or send values to) closed channels.

有两个不那么优雅地关闭 channel 的方法：

1）使用 defer-recover 机制，放心大胆地关闭 channel 或者向 channel 发送数据。即使发生了 panic，有 defer-recover 在兜底。

```go
func SafeClose(ch chan T) (justClosed bool) {
    defer func() {
        if recover() != nil {
            justClosed = false
        }
    }()
    
    // assume ch != nil here.
    close(ch) // panic if ch is closed
    return true
}
```

2）使用 sync.Once 来保证只关闭一次。

```go
type MyChannel struct {
    C    chan T
    once sync.Once
}

func NewMyChannel() *MyChannel {
    return &MyChannel{C: make(chan T)}
}

func (mc *MyChannel) SafeClose() {
    mc.once.Do(func(){
        close(mc.C)
    })
}
```

那么到底应该如何优雅地关闭 channel？根据 sender 和 receiver 的个数，分下面几种情况：

1.  一个 sender，一个 receiver。
2.  一个 sender， M 个 receiver。
3.  N 个 sender，一个 receiver。
4.  N 个 sender， M 个 receiver。

对于1，2只有一个 sender 的情况，可以直接从 sender 端关闭就好了，需要重点关注第 3，4 种情况。

对于第3种情况，优雅关闭 channel 的方法是：the only receiver says “please stop sending more” by closing an additional signal channel。

解决方案就是增加一个传递关闭信号的 channel，receiver 通过信号 channel 下达关闭数据 channel 指令。senders 监听到关闭信号后，停止发送数据。代码如下：

```go
func main() {
  rand.Seed(time.Now().UnixNano())

  const Max = 100000
  const NumSenders = 1000

  dataCh := make(chan int, 100)
  stopCh := make(chan struct{})

  // senders
  for i := 0; i < NumSenders; i++ {
    go func() {
      for {
        select {
        case <- stopCh:
          return
        case dataCh <- rand.Intn(Max):
        }
      }
    }()
  }

  // the receiver
  go func() {
    for value := range dataCh {
      if value == Max-1 {
        fmt.Println("send stop signal to senders.")
        close(stopCh)
        return
      }

      fmt.Println(value)
    }
  }()

  select {
  case <- time.After(time.Hour):
  }
}
```

这里的 stopCh 就是信号 channel，它本身只有一个 sender，因此可以直接关闭它。senders 收到了关闭信号后，select 分支 “case <- stopCh” 被选中，退出函数，不再发送数据。

需要说明的是，上面的代码并没有明确关闭 dataCh。在 Go 语言中，对于一个 channel，如果最终没有任何 goroutine 引用它，不管 channel 有没有被关闭，最终都会被 gc 回收。所以，在这种情形下，所谓的优雅地关闭 channel 就是不关闭 channel，让 gc 代劳。

对于第4种情况，优雅关闭 channel 的方法是：any one of them says “let’s end the game” by notifying a moderator to close an additional signal channel。

和第 3 种情况不同，这里有 M 个 receiver，如果直接还是采取第 3 种解决方案，由 receiver 直接关闭 stopCh 的话，就会重复关闭一个 channel，导致 panic。因此需要增加一个中间人，M 个 receiver 都向它发送关闭 dataCh 的“请求”，中间人收到第一个请求后，就会直接下达关闭 dataCh 的指令（通过关闭 stopCh，这时就不会发生重复关闭的情况，因为 stopCh 的发送方只有中间人一个）。另外，这里的 N 个 sender 也可以向中间人发送关闭 dataCh 的请求。

```go
func main() {
  rand.Seed(time.Now().UnixNano())

  const Max = 100000
  const NumReceivers = 10
  const NumSenders = 1000

  dataCh := make(chan int, 100)
  stopCh := make(chan struct{})

  // It must be a buffered channel.
  toStop := make(chan string, 1)

  var stoppedBy string

  // moderator
  go func() {
    stoppedBy = <-toStop
    close(stopCh)
  }()

  // senders
  for i := 0; i < NumSenders; i++ {
    go func(id string) {
      for {
        value := rand.Intn(Max)
        if value == 0 { // 增加随机性
          select {
          case toStop <- "sender#" + id:
          default:
          }
          return
        }

        select {
        case <- stopCh:
          return
        case dataCh <- value:
        }
      }
    }(strconv.Itoa(i))
  }

  // receivers
  for i := 0; i < NumReceivers; i++ {
    go func(id string) {
      for {
        select {
        case <- stopCh:
          return
        case value := <-dataCh:
          if value == Max-1 { // 增加随机性
            select {
            case toStop <- "receiver#" + id:
            default:
            }
            return
          }

          fmt.Println(value)
        }
      }
    }(strconv.Itoa(i))
  }

  select {
  case <- time.After(time.Hour):
  }
}
```

代码里 toStop 就是中间人的角色，使用它来接收 senders 和 receivers 发送过来的关闭 dataCh 请求。

这里将 toStop 声明成了一个 缓冲型的 channel。假设 toStop 声明的是一个非缓冲型的 channel，那么第一个发送的关闭 dataCh 请求可能会丢失。因为无论是 sender 还是 receiver 都是通过 select 语句来发送请求，如果中间人所在的 goroutine 没有准备好，那 select 语句就不会选中，直接走 default 选项，什么也不做。这样，第一个关闭 dataCh 的请求就会丢失。

## 常见应用题

### 轮流打印

#### 使用两个goroutine轮流打印

题目：数字1到100，要求两个goroutine轮流打印奇数和偶数。

版本1）使用匿名gorountine。

```go
func main() {
  channel := make(chan struct{})
  maxNum := 100
  var wg sync.WaitGroup
  wg.Add(2)

  go func() {
    defer wg.Done()
    for i := 1; i <= maxNum; i++ {
      if i%2 == 1 {
        fmt.Println("odd", i)
      }
      channel <- struct{}{}
    }
  }()

  go func() {
    defer wg.Done()
    for i := 1; i <= maxNum; i++ {
      <-channel
      if i%2 == 0 {
        fmt.Println("even", i)
      }
    }
  }()

  wg.Wait()
}
```

版本2）使用函数进行拆分。

```go
func main() {
  channel := make(chan struct{})
  var wg sync.WaitGroup
  wg.Add(2)

  go odd(channel, 100, &wg)
  go even(channel, 100, &wg)

  wg.Wait()
}

func odd(channel chan<- struct{}, maxNum int, wg *sync.WaitGroup) {
  defer wg.Done()
  for i := 1; i < maxNum; i++ {
    channel <- struct{}{}
    if i%2 == 1 {
      fmt.Println("odd", i)
    }
  }
}

func even(channel <-chan struct{}, maxNum int, wg *sync.WaitGroup) {
  defer wg.Done()
  for i := 1; i < maxNum; i++ {
    <-channel
    if i%2 == 0 {
      fmt.Println("even", i)
    }
  }
}
```

#### 使用三个goroutine轮流打印

题目：有三个goroutine，其中goroutine A打印A，goroutine B打印B，goroutine C打印C，轮流打印10次。

代码如下：

```go
func main() {
  chanA := make(chan struct{})
  chanB := make(chan struct{})
  chanC := make(chan struct{})
  N := 10
  var wg sync.WaitGroup
  wg.Add(3)

  go func() { // A
    defer wg.Done()
    for i := 0; i < N; i++ {
      <-chanA
      fmt.Println("chan A prints A", i)
      chanB <- struct{}{}
    }
    <-chanA // IMPORTANT
  }()

  go func() { // B
    defer wg.Done()
    for i := 0; i < N; i++ {
      <-chanB
      fmt.Println("chan B prints B", i)
      chanC <- struct{}{}
    }
  }()

  go func() { // C
    defer wg.Done()
    for i := 0; i < N; i++ {
      <-chanC
      fmt.Println("chan C prints C", i)
      chanA <- struct{}{}
    }
  }()

  chanA <- struct{}{}
  wg.Wait()
}
```

### 设置超时时间

在主goroutine设置超时时间2秒。另外，启动 2个groutine ， 第一个函数需要耗时1秒，第二个函数需要耗时3秒。

使用context设置超时时间，并用select监控多个channel。

代码如下：

```go
func main() {
  ctx, _ := context.WithTimeout(context.Background(), 2*time.Second)
  ch1 := make(chan struct{}, 1)
  ch2 := make(chan struct{}, 1)

  go func() { // f1
    time.Sleep(1 * time.Second)
    ch1 <- struct{}{}
  }()

  go func() { // f2
    time.Sleep(3 * time.Second)
    ch2 <- struct{}{}
  }()

  go func() {
    select {
    case <-ctx.Done():
      fmt.Println("f1 timeout")
      break
    case <-ch1:
      fmt.Println("f1 done")
    }
  }()

  go func() {
    select {
    case <-ctx.Done():
      fmt.Println("f2 timeout")
      break
    case <-ch2:
      fmt.Println("f2 done")
    }
  }()

  var input string
  fmt.Scanln(&input) // blocked by input
}

```

### 使用多个协程并发执行任务

通过启动多个协程，并发执行大量的任务，提高程序效率。

代码大致如下：

```go
func main() {
  const numWorker = 10
  const numJobs = 100
  jobs := make(chan int, numJobs)
  results := make(chan int, numJobs)

  for w := 0; w < numWorker; w++ { 
    go worker(w, jobs, results) // start a worker
  }

  for j := 1; j <= numJobs; j++ {
    jobs <- j
  }
  close(jobs)

  for a := 1; a <= numJobs; a++ {
    <-results
  }
}

func worker(id int, jobs <-chan int, results chan<- int) {
  for job := range jobs {
    fmt.Println("worker", id, "started  job", job)
    time.Sleep(time.Second) // doing something
    fmt.Println("worker", id, "finished job", job)
    results <- j * 2
  }
}

```

举个实际的例子，用协程池计算多个1,...,100的总和。（注：为了模拟多个任务，把1-100分为10个slice。）

```go
func main() {
  const numWorker = 5
  numbers := [][]int{
    {1, 2, 3, 4, 5, 6, 7, 8, 9, 10},
    {11, 12, 13, 14, 15, 16, 17, 18, 19, 20},
    {21, 22, 23, 24, 25, 26, 27, 28, 29, 30},
    {31, 32, 33, 34, 35, 36, 37, 38, 39, 40},
    {41, 42, 43, 44, 45, 46, 47, 48, 49, 50},
    {51, 52, 53, 54, 55, 56, 57, 58, 59, 60},
    {61, 62, 63, 64, 65, 66, 67, 68, 69, 70},
    {71, 72, 73, 74, 75, 76, 77, 78, 79, 80},
    {81, 82, 83, 84, 85, 86, 87, 88, 89, 90},
    {91, 92, 93, 94, 95, 96, 97, 98, 99, 100},
  }
  numJobs := len(numbers)

  jobs := make(chan []int, numJobs)
  results := make(chan int, numJobs)
  for w := 0; w < numWorker; w++ {
    go worker(w, jobs, results)
  }

  for _, nums := range numbers {
    jobs <- nums
  }
  close(jobs)

  var finalResult int
  for i := 0; i < numJobs; i++ {
    finalResult += <-results
  }
  fmt.Println(finalResult == 5050)
}

func worker(id int, jobs <-chan []int, results chan<- int) {
  for nums := range jobs {
    fmt.Println("worker", id)
    var sum int
    for _, num := range nums {
      sum += num
    }
    results <- sum
  }
}
```

### 控制协程的并发数

有缓冲的channel可以用来控制协程的并发数。

代码演示如下：

```go
var limit = make(chan int, 3)

func worker() {
    for job := range jobs {
        limit <- 1
        go func() {
            w(job)
            <-limit
        }()
    }
}
```

在这个例子中，首先创建一个缓冲型的 channel，容量为 3。在执行w(job) 任务之前，先要从 limit 中拿“许可证”，拿到许可证之后，才能执行 w(job)，并且在执行完任务，要将“许可证”归还。这样，就可以控制同时运行的 goroutine 数。

有一点要注意的是，如果 w(job) 发生 panic，那“许可证”可能就还不回去了，因此需要使用 defer 来保证。

另外，还可以用协程池，其原理无外乎是将通道和协程函数解耦，并封装成单独的结构体。

### 协程池

协程池类似线程池，目的是管理协程的数量，使用有限的工作协程运行不同的任务。

一个简单的协程池如下所示：

```go
// Pool contains logic of goroutine reuse.
type Pool struct {
  sem   chan struct{}
  tasks chan func()
}

// NewPool creates new goroutine pool with given size. It also creates a work
// queue of given size. Finally, it spawns given amount of goroutines immediately.
func NewPool(poolSize, taskSize, initialWorker int) *Pool {
  if poolSize <= 0 || taskSize <= 0 {
    panic("both pool size and task size are less than or equal to zero")
  }
  if initialWorker <= 0 { // there must be at least 1 initial worker
    panic("dead queue")
  }
  if initialWorker > poolSize || initialWorker > taskSize {
    panic("initial worker > pool size or initial worker > task size")
  }
  p := &Pool{
    sem:   make(chan struct{}, poolSize),
    tasks: make(chan func(), taskSize),
  }
  for i := 0; i < initialWorker; i++ {
    p.sem <- struct{}{}
    go p.run(func() {})
  }

  return p
}

// Schedule schedules task to be executed over pool's workers.
func (p *Pool) Schedule(task func()) {
  p.schedule(task, nil)
}

// ScheduleTimeout schedules task to be executed over pool's workers.
// It returns timeout error when no free workers met during given timeout.
func (p *Pool) ScheduleTimeout(timeout time.Duration, task func()) error {
  return p.schedule(task, time.After(timeout))
}

func (p *Pool) schedule(task func(), timeout <-chan time.Time) error {
  select {
  case <-timeout:
    return fmt.Errorf("schedule error: timed out")
  case p.tasks <- task:
    return nil
  case p.sem <- struct{}{}:
    go p.run(task)
    return nil
  }
}

// run runs a task like a worker.
func (p *Pool) run(task func()) {
  defer func() { <-p.sem }()

  task()

  for task := range p.tasks {
    task()
  }
}
```

# 11. 基于共享变量的并发

## 11.1. 竞争条件

在一个goroutine中，程序的执行顺序只由程序的逻辑来决定，即按语句的顺序执行。但是，对于不同goroutine中的语句，通常无法判断其执行顺序。比如，事件x和y分别在goroutine G1和G2中，x是在y之前还是之后发生是没法判断的。如果没有办法自信地确认一个事件是在另一个事件的前面或者后面发生的话，就可以认为x和y这两个事件是并发的。

通常来说，一个函数在线性程序中可以正确地工作。如果在并发的情况下，这个函数依然可以正确地工作的话，那么就可以认为这个函数是并发安全的。一个函数在并发调用时没法正常工作的原因有很多，比如死锁（deadlock）、活锁（livelock）和饿死（resource starvation）。但是我们现在先讨论竞争条件。

竞争条件（Race Condition）指的是程序在多个goroutine并发读写同一个数据时，没有给出正确的结果。竞争条件是很恶劣的一种场景，因为这种问题会一直潜伏在程序中，然后在非常少见的时候发生，使得问题难以复现、分析和诊断。

来看一个简单的银行账户程序：

```go
// package bank
var balance int
func Deposit(amount int) { balance = balance + amount }
func Balance() int { return balance }

// package main
func main() {
  // Alice:
  go func() {
      bank.Deposit(200)                // A1
      fmt.Println("Balance:", bank.Balance()) // A2
  }()
  
  // Bob:
  go bank.Deposit(100)                 // B
}
```

Alice和Bob分别向账户中存了200元和100元。直觉上来说，最终的余额应该是300元。但是，由于并发访问产生的数据竞争，余额最终也可能是200元，导致数据错误。

这个程序包含了一个特定的竞争条件，叫作数据竞争。无论任何时候，只要有两个goroutine并发访问同一变量，且至少其中的一个是写操作的时候就会发生数据竞争。再重复一遍，数据竞争是指，在两个以上的goroutine并发访问相同的变量且至少其中一个为写操作时发生。

根据上述定义，有三种方式可以避免数据竞争：

1）避免写变量。比如，对于全局变量，应该在包初始化阶段完成赋值，也就是在程序main函数开始执行之前。在初始化结束后，最好就不要在修改全局变量，因为非常容易产生数据竞争。

2）避免从多个goroutine访问变量。解决办法是保证一个变量只能有一个goroutine访问，导致其他goroutine不能够直接访问，而只能使用channel来发送请求给指定的goroutine来查询或更新变量。这也就是Go的口头禅“不要使用共享数据来通信，而是使用通信来共享数据”。

3）允许很多goroutine去访问变量，但是在同一个时刻最多只有一个goroutine在访问。这种方式被称为“互斥”，即互斥锁。

## 11.2. sync.Mutex互斥锁

sync.Mutex表示互斥锁，其用法也非常简单。Mutex的特点是，在同一时间，只能有一个gorouinte 获得Mutex锁，其他gorouinte阻塞在尝试获得锁的位置，知道持有锁的goroutine释放锁。

对于上一节的银行账户程序，可以使用互斥锁来实现并发安全。代码如下：

```go
var (
    mu      sync.Mutex // guards balance
    balance int
)

func Deposit(amount int) {
    mu.Lock()
    balance = balance + amount
    mu.Unlock()
}

func Balance() int {
    mu.Lock()
    b := balance
    mu.Unlock()
    return b
}
```

每次一个goroutine访问bank变量时（这里只有balance余额），它都会调用mutex的Lock方法来获取一个互斥锁。如果其它的goroutine已经获得了这个锁的话，这个操作会被阻塞直到其它goroutine调用了Unlock来释放锁，使该锁变回可用状态。

mutex会保护共享变量。按照惯例，被mutex所保护的变量应该在mutex变量声明之后立刻声明。如果做法和惯例不符，确保在文档里进行说明。

对于同一个函数的Lock和Unlock之间的代码段，这个代码段叫做临界区，goroutine可以随便读取或者修改。

持有互斥锁的goroutine在其他goroutine获取该锁之前需要调用Unlock。需要注意的是，goroutine在结束后需要释放锁，即使出现错误，也必须要释放锁。在这种情况下，应该使用defer延迟调用。

```go
func Balance() int {
    mu.Lock()
    defer mu.Unlock()
    return balance
}
```

一个deferred Unlock即使在临界区发生panic时依然会执行。defer调用只会比显式地调用Unlock成本高那么一点点，不过却在很大程度上保证了代码的整洁性。稍微解释一下，在这个例子里，Unlock会在return语句读取完balance的值之后执行，所以使用defer调用的Balance函数也是并发安全的。

注意：和Java不同的是，Go的互斥锁不支持重入。也就是说，无法对一个已经锁上的mutex来再次上锁——这会导致程序死锁。

### 底层实现和原理

TODO

## 11.3. sync.RMMutex读写锁

对于上一节的Balance函数：

```go
func Balance() int {
    mu.Lock()
    defer mu.Unlock()
    return balance
}
```

如果多个goroutine并发读取，每个goroutine都需要经历加锁和释放锁的过程，效率很低。但是，并发读取变量并不影响并发安全，应该允许多个goroutine的并发读操作。

RMMutex读写锁正是用在这种场景下，其允许多个只读操作并行执行，但写操作会完全互斥。这种锁叫作“多读单写”锁，或读写锁。读写锁包括读锁和写锁，其中读锁和写锁也可以分别称为共享锁和互斥锁。

RMMutex的特点包括：

-   在同一时间，可以有任意多个 gorouinte 获得读锁。如果现在有一个或者多个goroutine持有读锁，其他goroutine尝试获取读锁，可以获取成功。
-   在同一时间，只能有一个 goroutine 能够获得写锁。
-   在同一时间，只能存在写锁或读锁（读和写互斥）。
    -   如果现在有一个或者多个goroutine持有读锁，其他goroutine尝试获取写锁，要等到所有的读锁释放之后，写锁才能够获取到。
    -   如果现在有一个goroutine持有写锁，其他goroutine尝试获取读锁或者写锁都会一直阻塞，直到持有写锁的goroutine释放锁，其他goroutine才可以获得读锁或者写锁。需要注意的是，写锁权限高于读锁，有写锁时优先进行写锁定。

使用读写锁来修改上一节的银行账户程序，其中Balance函数调用了RLock和RUnlock方法来获取和释放一个读锁。而Deposit函数没有变化，会调用Lock和Unlock方法来获取和释放一个写锁。

```go
var (
    mu      sync.RWMutex // guards balance
    balance int
)

func Deposit(amount int) {
    mu.Lock()
    balance = balance + amount
    mu.Unlock()
}

func Balance() int {
    mu.RLock() // readers lock
    defer mu.RUnlock()
    return balance
}
```

修改之后，多个goroutine调用Balance函数余就可以彼此并行地执行并且会很快地完成了。因为锁在更多的时间范围是可用的，并且存款请求也能够及时地被响应了。

注意，RLock只能在临界区共享变量没有任何写入操作时可用。一般来说，不应该假设一个函数（或方法）不会去更新变量。比如一个方法功可能只是访问一个变量，但它也有可能会修改内部的状态。如果不确定的话，请直接使用互斥锁。

注意，RWMutex更适用于“读多写少”的场景下，也就是大部分goroutine获得锁之后都是进行读操作。如果读写的操作数量相近，请直接使用互斥锁。

### 底层实现和原理

TODO

## 11.4. 内存同步

“同步”不仅仅是一堆goroutine执行顺序的问题，同样也会涉及到内存的问题。现代计算机可能会有一堆处理器，每一个都会有其本地缓存（local cache）。为了效率，对内存的写入一般会先在每一个处理器中缓存，然后在必要时flush到主存。在这种情况下，一些数据可能会以与goroutine写入顺序不同的顺序提交到主存。像channel通信或者互斥锁操作这样的原语会使处理器将缓存的数据flush到内存，这样一个goroutine在某个时间点上的执行结果才能被其它处理器上运行的goroutine观察到。

考虑一下下面代码片段的可能输出：

```go
var x, y int
go func() {                 // A
    x = 1                   // A1
    fmt.Print("y:", y, " ") // A2
}()
go func() {                 // B
    y = 1                   // B1
    fmt.Print("x:", x, " ") // B2
}()

```

因为两个goroutine是并发执行，并且访问共享变量时也没有互斥，会有数据竞争，所以程序的运行结果不是确定的，可能有以下几种可能：

```go
x:0 y:1
x:1 y:1
y:0 x:1
y:1 x:1

x:0 y:0
y:0 x:0

```

最后两种情况虽然很难想到，但是也有可能发生。这是因为，在一个独立的goroutine中，每一个语句的执行顺序是可以被保证的，也就是一个goroutine内的语句肯定按顺序执行。但是，在不使用channel且不使用mutex这样的显式同步操作时，就无法保证一个goroutine中的事件顺序在不同的goroutine中看到的执行顺序是一致的。尽管goroutine A中一定需要观察到x=1执行成功之后才会去读取y，但它没法确保自己观察得到goroutine B中对y的写入，所以A还可能会打印出y的一个旧版的值。

对于goroutine的并发运行，可以将其理解为不同goroutine语句的交错执行。但对于上面的例子，现代的编译器和CPU的工作方式可能会超过我们的想象。因为goroutine 中的赋值和打印指向不同的变量，编译器可能会断定两条语句的顺序不会影响执行结果，并且会交换两个语句的执行顺序。如果两个goroutine在不同的CPU上执行，每一个核心有自己的缓存，这样一个goroutine的写入对于其它goroutine来说，在主存同步之前就是不可见的。

所有并发的问题都可以用一致的、简单的既定的模式来规避。最简单的方法是将变量限定在goroutine内部；如果是多个goroutine都需要访问的变量，使用互斥条件来访问。

## 11.5. 竞争条件检测

> [https://gopl-zh.github.io/ch9/ch9-06.html](https://gopl-zh.github.io/ch9/ch9-06.html "https://gopl-zh.github.io/ch9/ch9-06.html")

即使我们小心到不能再小心，但在并发程序中犯错还是太容易了。幸运的是，Go语言的runtime和工具链为我们装备了一个复杂但好用的动态分析工具，竞争检查器（the race detector）。

只要在go build，go run或者go test命令后面加上-race的flag，就会使编译器创建一个你的应用的“修改”版或者一个附带了能够记录所有运行期对共享变量访问工具的test，并且会记录下每一个读或者写共享变量的goroutine的身份信息。另外，修改版的程序会记录下所有的同步事件，比如go语句，channel操作，以及对`(*sync.Mutex).Lock`，`(*sync.WaitGroup).Wait`等语句的调用。

竞争检查器会检查这些事件，并寻找在哪一个goroutine中出现了这样的case，例如其读或者写了一个共享变量，这个共享变量是被另一个goroutine在没有进行干预同步操作便直接写入的。这种情况也就表明了是对一个共享变量的并发访问，即数据竞争。

## 原子操作atomic

atomic是Go语言内置的原子操作包。这个包提供了用于实现同步机制的底层原子内存原语。

原子（atom）本意是“不能被进一步分割的最小粒子”，而原子操作是指不会被线程调度机制打断的一个或一系列操作；这种操作一旦开始，就一直运行到结束，中间不会有任何上下文切换，即不会切换到另一个线程。

atomic包提供的原子操作可以分为三类：

1）对整数类型T的操作。这种操作通过汇编源码实现的。

```go
func AddT(addr *T, delta T) (new T)
func CompareAndSwapT(addr *T, old, new T) (swapped bool)
func LoadT(addr *T) (val T)
func StoreT(addr *T, val T)
func SwapT(addr *T, new T) (old T)
```

AddT原子地向一个指针指向的T类型变量增加delta的大小。

CompareAndSwapT原子地交换两个值。

2）对于unsafe.Pointer类型的操作。这种操作通过汇编源码实现的。

```go
func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool)
func LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer)
func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer)
func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer)
```

3） atomic.Value类型的Load和Store操作。

atomic提供了atomic.Value类型，用来原子地加载和存储类型一致的值。atomic.Value提供了对任何类型的原子性操作。atomic.Value底层存储的实际上是interface{}类型，所以支持任何类型。

```go
func (v *Value) Load() (x interface{}) 
func (v *Value) Store(x interface{})
func (v *Value) Swap(new any) (old any)
func (v *Value) CompareAndSwap(old, new any) (swapped bool)

```

Load原子地返回刚刚存储的值，若没有值返回nil。

Store原子地存储值x，x可以是nil，但存的值都必须是同一个类型。每次调用Store方法时候，会将传入参数转换成interface{}类型，并把参数的类型下来。如果后续传入的参数类型不一致，就直接报panic异常。

## sync.Map

> [https://go.cyub.vip/concurrency/sync-map.html](https://go.cyub.vip/concurrency/sync-map.html "https://go.cyub.vip/concurrency/sync-map.html")
> [https://www.cnblogs.com/qcrao-2018/p/12833787.html](https://www.cnblogs.com/qcrao-2018/p/12833787.html "https://www.cnblogs.com/qcrao-2018/p/12833787.html")

sync.Map是sync包提供的并发安全的map，适用于读多写少的场景。

sync.Map提供了如下方法：

-   Load：用来获取Key对应的Value值。
-   Store：用来设置Key以及对应的Value值。
-   LoadOrStore：用来获取Key对应的Value值。如果Key不存在，就进行设置。
-   Delete：用来删除Key以及对应的Value值。
-   Range：用来遍历一个Map。

### 底层实现和原理

sync.Map的数据结构如下：

```go
// Map is like a Go map[interface{}]interface{} but is safe for concurrent use
// by multiple goroutines without additional locking or coordination.
// Loads, stores, and deletes run in amortized constant time.
type Map struct {
  mu Mutex

  read atomic.Value // readOnly

  dirty map[any]*entry

  misses int
}

type entry struct {
  p unsafe.Pointer // *interface{}
}

```

解释：

-   mu是互斥锁，用于保护 read 和 dirty。
-   read 和 dirty 字段用来存储key/value。read 使用 atomic.Value，这是不需要加锁的基础，因为其直接使用原子操作。dirty 则直接用了一个原始的 map，对于它的 load/store 操作需要加锁。
-   misses 用来统计从 read 中读取失败的次数。每次从read读取失败，misses计数值加 1。当加到一定阈值以后，需要将 dirty 提升为 read，以期减少 miss的情形。

虽然read 和 dirty 各自维护了一套 key，但是key 指向的都是同一个 value。也就是说，只要修改了这个 entry，对 read 和 dirty 都是可见的。如下图所示：

![image_0lWXSmaqWT](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202311252034063.png)

entry包含一个指针，这个指针的状态有三种：

-   当 p == nil 时，说明这个键值对已被删除，并且 m.dirty == nil或 m.dirty\[k] 指向该 entry。
-   当 p == expunged 时，说明这条键值对已被删除，并且 m.dirty != nil，且 m.dirty 中没有这个 key。
-   其他情况，p 指向一个正常的值，表示实际 interface{} 的地址，并且被记录在 m.read.m\[key] 中。如果这时 m.dirty 不为 nil，那么它也被记录在 m.dirty\[key] 中。两者实际上指向的是同一个值。

> 问题：为什么不使用sync.Mutex和普通map实现并发的map呢？sync.Map相比sync.Mutex和普通map实现并发map有哪些优势？
> sync.Map优势在于当key存在read map时候，如果进行Store操作，可以使用原子性操作更新，而sync.Mutex+map形式每次写操作都要加锁，这个成本更高。
> 另外，在并发读写两个不同的key时，写操作需要加锁，而读操作是不需要加锁的。

总结：

-   sync.Map是不能值传递的。
-   sync.Map采用空间换时间策略。底层结构存在两个map，分别是read map和dirty map。对于读取操作，优先从read map中读取，是不需要加锁的，若key不存在read map中时候，再从dirty map中读取，这个过程是加锁的。当新增key操作，只会将新增key添加到dirty map中，此操作是加锁的，但不会影响read map的读操作。当更新key操作时候，如果key已存在read map中时候，只需无锁更新read map就行，负责加锁处理在dirty map中情况了。总之，sync.Map会优先从read map中读取、更新、删除，因为对read map的读取不需要锁。
-   当sync.Map读取key操作时候，若从read map中一直未读到，若dirty map中存在read map中不存在的keys时，则会把dirty map升级为read map，这个过程是加锁的。这样下次读取时候只需要考虑从read map读取，且读取过程是无锁的。
-   延迟删除机制，删除一个键值时只是打上删除标记，只有在提升dirty map为read map的时候才清理删除的数据。
-   sync.Map中的dirty map要么是nil，要么包含read map中所有未删除的key-value。
-   sync.Map适用于读多写少场景。比如：1） 一个key只写入一次但读取多次时，比如在只会增长的缓存中；2）当多个goroutine读取、写入和更新不相交的键值对时。

## sync.WaitGroup

sync.WaitGroup是sync包提供的用来等待多个goroutine结束的工具。

举一个实际的例子：

```go
func main() {
  var wg sync.WaitGroup
  wg.Add(2)

  go func() {
    time.Sleep(time.Second)
    wg.Done()
  }()

  go func() {
    time.Sleep(time.Second)
    wg.Done()
  }()

  wg.Wait() // waiting
}
```

#### 底层实现和原理

sync.WaitGroup的定义如下：

```go
type WaitGroup struct {
  noCopy noCopy

  state1 uint64
  state2 uint32
}

// Add adds delta, which may be negative, to the WaitGroup counter.
// If the counter becomes zero, all goroutines blocked on Wait are released.
// If the counter goes negative, Add panics.
func (wg *WaitGroup) Add(delta int) {...}

// Done decrements the WaitGroup counter by one.
func (wg *WaitGroup) Done() {
  wg.Add(-1)
}

// Wait blocks until the WaitGroup counter is zero.
func (wg *WaitGroup) Wait() {...}

```

解释：

-   Add方法用来增加等待的goroutine的个数。参数可以是负数，但加上该传值之后的WaitGroup计数器值不能是负值，否砸直接panic。
-   Done用来减小等待的goroutine的个数，减小的值为1。
-   Wait方法用来阻塞当前goroutine，直到WaitGroup计数器为0。

总结：

-   WaitGroup是不能值传递的，必须传递地址。
-   Add方法的传值可以是负数，但加上该传值之后的waitgroup计数器值不能是负值。
-   Done方法实际上调用的是Add(-1)。
-   Add方法和Wait方法不能并发调用。
-   Wait方法可以多次调用，调用此方法的goroutine会阻塞，一直阻塞到waitgroup计数器值变为0。

## sync.Once

> [https://juejin.cn/post/7088305487753510925](https://juejin.cn/post/7088305487753510925 "https://juejin.cn/post/7088305487753510925")

sync.Once用来使提供的使函数只执行一次，常应用于单例模式，例如初始化配置、保持数据库连接等。它可以在代码的任意位置初始化和调用，因此可以延迟到使用时再执行，并发场景下是线程安全的。

举个实际的例子，这个例子实现了单例模式。

```go
type Singleton struct{}
var singleton *Singleton
var once sync.Once

func GetSingletonObj() *Singleton {
   once.Do(func() {
      singleton = new(Singleton)
   })
   return singleton
}

```

#### 底层实现和原理

sync.Once的定义如下：

```go
type Once struct {
  done uint32
  m    Mutex
}

func (o *Once) Do(f func()) {
    if atomic.LoadUint32(&o.done) == 0 {
      o.doSlow(f)
   }
}

func (o *Once) doSlow(f func()) {
   o.m.Lock()
   defer o.m.Unlock()
   if o.done == 0 {
      defer atomic.StoreUint32(&o.done, 1)
      f()
   }
}

```

解释：

-   只有在当前的 Once 实例第一次调用 Do 方法时，才会真正执行 `f`。哪怕在多次调用 Do 中间 `f` 的值有所变化，也只会被实际调用一次；
-   Do方法是只希望执行一次的初始化操作，由于`f` 是没有参数的，如果需要传参，可以采用包装一层 func 的形式来实现。
-   不要嵌套调用Do方法。在对`f` 的调用返回之前，不会返回对Do的调用，所以如果f方法中又调用来Do方法，将会死锁。
-   如果 `f` 抛出了 panic，此时Do会认为`f`已经返回，后续再调用Do也不会再触发对 `f` 的调用。

总结：

-   Once使用原子操作atomic、互斥锁和defer机制。
-   atomic.LoadUint32 用于原子加载地址（也就是 \&o.done），返回加载到的值；o.done 为 0 是代表尚未执行。
-   `doSlow` 使用 `sync.Mutex` 来加锁，一个协程进去，其他的被阻塞在获取锁的地方。
-   经过 `o.m.Lock()` 获取到锁以后，如果此时 o.done 还是 0，意味着依然没有被执行，此时就可以放心的调用 `f`来执行了。否则，说明当前协程在被阻塞的过程中，已经失去了调用`f` 的机会，直接返回。
-   Once还使用了defer机制。 `defer atomic.StoreUint32(&o.done, 1)` 在等到`f()` 返回，才去更新 o.done 的值为 1。

需要注意的是，

-   once应该是一个包内的全局变量，而不是函数内的局部变量。
-   不要拷贝一个 sync.Once 使用或作为参数传递，然后去执行 `Do`，值传递时 `done` 会归0，无法起到限制一次的效果。

## sync.Pool

> [https://go.cyub.vip/concurrency/sync-pool.html](https://go.cyub.vip/concurrency/sync-pool.html "https://go.cyub.vip/concurrency/sync-pool.html")

sync.Pool提供了临时对象缓存池，存在池子的对象可能在任何时刻被自动移除，我们对此不能做任何预期。sync.Pool可以并发使用，它通过复用对象来减少对象内存分配和GC的压力。当负载大的时候，临时对象缓存池会扩大，缓存池中的对象会在每2个GC循环中清除。

#### 底层实现和原理

sync.Pool的数据结构如下：

```go
type Pool struct {
  noCopy noCopy

  local     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal
  localSize uintptr        // size of the local array

  victim     unsafe.Pointer // local from previous cycle
  victimSize uintptr        // size of victims array

  New func() any
}

// Put adds x to the pool.
func (p *Pool) Put(x any) {...}

func (p *Pool) Get() any {...}

```

Get和Put分别用于从缓存池中获取临时对象，和将临时对象放回到缓存池中。

# 12. 反射

反射（reflect）机制能够在运行时更新变量和检查它们的值、调用它们的方法和它们支持的内在操作，而不需要知道这些变量的具体类型。

## 12.1 reflect.Type 和 reflect.Value

反射是由 reflect 包提供的。它定义了两个重要的类型，Type 和 Value。

### reflect.Type

一个 Type 表示一个Go类型。它是一个接口，有许多方法来区分类型以及检查它们的组成部分，例如一个结构体的成员或一个函数的参数等。唯一能反映 reflect.Type 实现的是接口的类型描述信息，也正是这个实体标识了接口值的动态类型。

函数 reflect.TypeOf 接受任意的 interface{} 类型，并以 reflect.Type 形式返回其动态类型，如下所示：

```go
t := reflect.TypeOf(3)  // a reflect.Type
fmt.Println(t.String()) // "int"
fmt.Println(t)          // "int"
```

reflect.Type 接口是满足 fmt.Stringer 接口的。因为打印一个接口的动态类型对于调试和日志是有帮助的， 所以fmt.Printf函数 提供了一个缩写 %T 参数，内部使用 reflect.TypeOf 来输出，如下所示：

```python
fmt.Printf("%T\n", 3) // "int"
```

### reflect.Value

reflect 包中另一个重要的类型是 Value。一个 reflect.Value 可以装载任意类型的值。

函数 reflect.ValueOf 接受任意的 interface{} 类型，并返回一个装载着其动态值的 reflect.Value。和 reflect.TypeOf 类似，reflect.ValueOf 返回的结果也是具体的类···型，但是 reflect.Value 也可以持有一个接口值。

```go
v := reflect.ValueOf(3) // a reflect.Value
fmt.Println(v)          // "3"
fmt.Printf("%v\n", v)   // "3"
fmt.Println(v.String()) // NOTE: "<int Value>"
```

和 reflect.Type 类似，reflect.Value 也满足 fmt.Stringer 接口，但是除非 Value 持有的是字符串，否则 String 方法只返回其类型。而使用 fmt 包的 %v 标志参数会对 reflect.Values 特殊处理。

对 Value 调用 Type 方法将返回具体类型所对应的 reflect.Type：

```python
t := v.Type()           // a reflect.Type
fmt.Println(t.String()) // "int"

```

reflect.ValueOf 的逆操作是 reflect.Value.Interface 方法。它返回一个 interface{} 类型，装载着与 reflect.Value 相同的具体值：

```go
v := reflect.ValueOf(3) // a reflect.Value
x := v.Interface()      // an interface{}
i := x.(int)            // an int
fmt.Printf("%d\n", i)   // "3"

```

reflect.Value 和 interface{} 都能装载任意的值。不同的是，一个空的接口隐藏了值内部的表示方式和所有方法，因此只有我们知道具体的动态类型才能使用类型断言来访问内部的值，否则就没办法访问。相比之下，一个 Value 则有很多方法来检查其内容，无论它的具体类型是什么。

reflect.Value 的 Kind 方法可以用来替代类型switch。虽然还是有无穷多的类型，但是它们的 kinds 类型却是有限的：

-   Bool、String 和 所有数字类型的基础类型；
-   Array 和 Struct 对应的聚合类型；
-   Chan、Func、Ptr、Slice 和 Map 对应的引用类型；
-   interface 类型；
-   还有表示空值的 Invalid 类型。（空的 reflect.Value 的 kind 即为 Invalid）

## 12.2 通过reflect.Value修改值

Go语言中类似x、x.f\[1]和\*p形式的表达式都可以表示变量，但是其它如x + 1和f(2)则不是变量。一个变量就是一个可寻址的内存空间，里面存储了一个值，并且存储的值可以通过内存地址来更新。

reflect.Value也有类似的区别。有一些reflect.Value是可取地址的，其它一些则不可以，可以通过调用CanAddr方法来判断其是否可以被取地址。

```go
x := 2                   // value   type    variable?
a := reflect.ValueOf(2)  // 2       int     no
b := reflect.ValueOf(x)  // 2       int     no
c := reflect.ValueOf(&x) // &x      *int    no
d := c.Elem()            // 2       int     yes (x)

fmt.Println(a.CanAddr()) // "false"
fmt.Println(b.CanAddr()) // "false"
fmt.Println(c.CanAddr()) // "false"
fmt.Println(d.CanAddr()) // "true"

```

由上可知，a对应的变量不可取地址，因为a中的值仅仅是整数2的拷贝副本。b中的值也同样不可取地址。c中的值还是不可取地址，它只是一个指针`&x`的拷贝。实际上，所有通过reflect.ValueOf(x)返回的reflect.Value都是不可取地址的。但是对于d，它是c的解引用方式生成的，指向另一个变量，因此是可取地址的。

所以，可以通过调用reflect.ValueOf(\&x).Elem()，来获取任意变量x对应的可取地址的Value。

要从变量对应的可取地址的reflect.Value来访问变量需要三个步骤：

1.  第一步是调用Addr()方法，它返回一个Value，里面保存了指向变量的指针。
2.  然后是在Value上调用Interface()方法，也就是返回一个interface{}，里面包含指向变量的指针。
3.  最后，如果我们知道变量的类型，我们可以使用类型的断言机制将得到的interface{}类型的接口强制转为普通的类型指针。

这样就可以通过这个普通指针来更新变量了，示例如下：

```go
x := 2
d := reflect.ValueOf(&x).Elem()   // d refers to the variable x
px := d.Addr().Interface().(*int) // px := &x
fmt.Println(x)                    // "2"
*px = 3                           // x = 3
fmt.Println(x)                    // "3"
```

另一种方法更简单，没有使用指针，而是通过调用**可取地址的reflect.Value**的Set方法来更新对应的值：

```go
x := 2
d := reflect.ValueOf(&x).Elem()   // d refers to the variable x
d.Set(reflect.ValueOf(4))
fmt.Println(x) // "4"

d.Set(reflect.ValueOf(int64(5))) // panic: int64 is not assignable to int

```

Set方法将在运行时执行和编译时进行类似的可赋值性约束的检查。在上面的代码中，变量和值都是int类型，Set方法会正常工作；但是，如果传入了一个int64类型的值，那么将导致一个panic异常，所以关键问题是要确保改类型的变量可以接受对应的值。

有很多用于基本数据类型的Set方法：SetInt、SetUint、SetString和SetFloat等。例如，

```go
d := reflect.ValueOf(&x).Elem()
d.SetInt(3)
fmt.Println(x) // "3"

```

从某种程度上说，这些Set方法总是尽可能地完成任务。以SetInt为例，只要变量是某种类型的有符号整数就可以工作，即使是一些命名的类型、甚至只要底层数据类型是有符号整数就可以，而且如果对于变量类型值太大的话会被自动截断。但需要谨慎的是：对于一个引用interface{}类型的reflect.Value调用SetInt会导致panic异常，即使那个interface{}变量对于整数类型也不行。

```go
x := 1
rx := reflect.ValueOf(&x).Elem()
rx.SetInt(2)                     // OK, x = 2
rx.Set(reflect.ValueOf(3))       // OK, x = 3
rx.SetString("hello")            // panic: string is not assignable to int
rx.Set(reflect.ValueOf("hello")) // panic: string is not assignable to int

var y interface{}
ry := reflect.ValueOf(&y).Elem()
ry.SetInt(2)                     // panic: SetInt called on interface Value
ry.Set(reflect.ValueOf(3))       // OK, y = int(3)
ry.SetString("hello")            // panic: SetString called on interface Value
ry.Set(reflect.ValueOf("hello")) // OK, y = "hello"

```

反射可以越过Go语言的导出规则的限制读取结构体中未导出的成员。然而，利用反射机制并不能修改这些未导出的成员。一个可取地址的reflect.Value会记录一个结构体成员是否是未导出成员，如果是的话则拒绝修改操作。

## 12.3 显示一个类型的方法集

使用reflect.Type来打印任意值的类型和枚举它的方法，代码如下：

```go
// Print prints the method set of the value x.
func Print(x interface{}) {
    v := reflect.ValueOf(x)
    t := v.Type()
    fmt.Printf("type %s\n", t)

    for i := 0; i < v.NumMethod(); i++ {
        methType := v.Method(i).Type()
        fmt.Printf("func (%s) %s%s\n", t, t.Method(i).Name,
            strings.TrimPrefix(methType.String(), "func"))
    }
}
```

reflect.Type和reflect.Value都提供了一个Method方法。每次t.Method(i)调用将一个reflect.Method的实例，对应一个用于描述一个方法的名称和类型的结构体。每次v.Method(i)方法调用都返回一个reflect.Value以表示对应的值，也就是一个方法是绑到它的接收者的。

time.Duration类型的方法如下（Go 1.18）：

```go
type time.Duration
func (time.Duration) Hours() float64
func (time.Duration) Microseconds() int64
func (time.Duration) Milliseconds() int64
func (time.Duration) Minutes() float64
func (time.Duration) Nanoseconds() int64
func (time.Duration) Round(time.Duration) time.Duration
func (time.Duration) Seconds() float64
func (time.Duration) String() string
func (time.Duration) Truncate(time.Duration) time.Duration
```

## 12.4 慎用反射

虽然反射是一个强大并富有表达力的工具，但是应该小心地使用它。

第一个原因是，基于反射的代码是比较脆弱的。对于每一个会导致编译器报告类型错误的问题，在反射中都有与之相对应的误用问题，不同的是编译器会在构建时马上报告错误，而反射则是在真正运行到的时候才会抛出panic异常。

第二个原因是，即使对应类型提供了相同文档，但是反射的操作不能做静态类型检查，而且大量反射的代码通常难以理解。总是需要小心翼翼地为每个导出的类型和其它接受interface{}或reflect.Value类型参数的函数维护说明文档。

第三个原因，基于反射的代码通常比正常的代码运行速度慢一到两个数量级。对于一个典型的项目，大部分函数的性能和程序的整体性能关系不大，所以当反射能使程序更加清晰的时候可以考虑使用。

## 底层实现和原理

### reflect.Type

### reflect.Value

## 常见应用题

### 如何获取一个结构体的所有tag？

代码如下：

```go
type Author struct {
  Name         int      `json:"Name"`
  Publications []string `json:"Publication,omitempty"`
}

func main() {
  t := reflect.TypeOf(Author{})
  for i := 0; i < t.NumField(); i++ {
    name := t.Field(i).Name
    s, _ := t.FieldByName(name)
    fmt.Println(name, s.Tag)
    fmt.Println(s.Tag.Get("json"))
  }
}
```

# 13. 底层编程

TODO

# 14. 内存管理

## 14.1. 内存分配

> [https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/](https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/ "https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/")

程序中的数据和变量都会被分配到程序所在的虚拟内存中，内存空间包含两个重要区域：栈区（Stack）和堆区（Heap）。

-   对于栈，函数调用的参数、返回值以及局部变量大都会被分配到栈上，这部分内存会由编译器进行管理。
    -   栈内存分配速度比较快。
-   对于堆，不同编程语言使用不同的方法管理堆区的内存，C++ 等编程语言会由工程师主动申请和释放内存，Go 以及 Java 等编程语言会由工程师和编译器共同管理，堆中的对象由内存分配器分配并由垃圾收集器回收。
    -   堆适合不可预知大小的内存分配。堆分配内存需要找到一块大小合适的内存块，使用之后需要手动释放内存或通过垃圾回收释放内存。
    -   堆内存分配速度较慢，而且会形成内存碎片。

编程语言的内存管理一般包含三个不同的组件，分别是用户程序（Mutator）、分配器（Allocator）和收集器（Collector），当用户程序申请内存时，它会通过内存分配器申请新内存，而分配器会负责从堆中初始化相应的内存区域。

### 设计原理

一般来说，内存分配器有两种分配方法：

-   线性分配器（Sequential Allocator，Bump Allocator）。
-   空闲链表分配器（Free-List Allocator）。

线性分配（Bump Allocator）是一种高效的内存分配方法，但是有较大的局限性。线性分配器通过在内存中维护一个指向内存特定位置的指针，如果用户程序向分配器申请内存，分配器只需要检查剩余的空闲内存，移动指针并返回分配的内存区域。虽然线性分配器实现为它带来了较快的执行速度以及较低的实现复杂度，但是线性分配器无法在内存被释放时重用内存。

空闲链表分配器通过在内部会维护一个类似链表的数据结构，当用户程序申请内存时，空闲链表分配器会依次遍历空闲的内存块，找到足够大的内存，然后申请新的资源并修改链表。因为不同的内存块通过指针构成了链表，所以使用这种方式的分配器可以重新利用回收的资源，但是因为分配内存时需要遍历链表，所以它的时间复杂度是O(N)。

另外还有一种分级分配的策略。Go 语言的内存分配器就借鉴了 TCMalloc （Thread-Caching Malloc，TCMalloc）的设计实现高速的内存分配，它的核心理念是使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略。

### Go语言的内存分配器

Go 语言的内存分配器使用了分级分配的策略：把内存分成不同的级别进行管理，并根据申请分配的内存大小选择不同的处理逻辑。

Go 语言在运行时根据对象的大小将对象分成微对象、小对象和大对象三种：

| 类别  | 大小           |
| --- | ------------ |
| 微对象 | (0, 16B)     |
| 小对象 | \[16B, 32KB] |
| 大对象 | (32KB, +∞)   |

因为程序中的绝大多数对象的大小都在 32KB 以下，而申请的内存大小影响 Go 语言运行时的开销，所以分别处理大对象和小对象有利于提高内存分配器的性能。

为了处理不同大小的内存分配，Go 语言把内存分成了三个级别：

-   线程缓存（Thread Cache）：线程缓存属于每一个独立的线程，它能够满足线程上绝大多数的内存分配需求，因为不涉及多线程，所以也不需要使用互斥锁来保护内存，这能够减少锁竞争带来的性能损耗。
-   中心缓存（Central Cache）：当线程缓存不能满足需求时，运行时会使用中心缓存作为补充解决小对象的内存分配
-   页堆（Page Heap）：在遇到 32KB 以上的对象时，内存分配器会选择页堆直接分配大内存。

Go语言的内存分配器会根据对象大小选择不同的分配逻辑：

-   微对象：先使用微型分配器，再依次尝试线程缓存、中心缓存和堆分配内存。
-   小对象：依次尝试使用线程缓存、中心缓存和堆分配内存。
-   大对象：对于 32KB 以上的大对象时，内存分配器会直接在堆上分配内存。

### 内存管理组件

Go 语言的内存分配器包括内存管理单元、线程缓存、中心缓存和页堆等组件。

内存管理单元是一个双向链表结构，其中每个结点可以看作是一个最基本的内存管理单元，管理着一份内存。

线程缓存，它会与线程上的处理器一一绑定，主要用来缓存用户程序申请的微对象和小对象。它能够满足线程上绝大多数的内存分配需求，因为不涉及多线程，所以也不需要使用互斥锁来保护内存，这能够减少锁竞争带来的性能损耗。线程缓存中还有一个微对象分配器，专门管理 16 B大小以下的对象。

中心缓存，与线程缓存不同，访问中心缓存中的内存管理单元需要使用互斥锁。每个中心缓存都会管理某个跨度类的内存管理单元，它会同时存储包含空闲对象和不包含空闲对象的内存管理单元。

页堆用来负责堆内存的分配，在堆上初始化的所有对象都由页堆进行统一管理。

## 14.2. 垃圾回收

> [https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/](https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/ "https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/")
> [https://golang.design/go-questions/memgc/principal/](https://golang.design/go-questions/memgc/principal/ "https://golang.design/go-questions/memgc/principal/")
> [https://juejin.cn/post/7101973304960892964](https://juejin.cn/post/7101973304960892964 "https://juejin.cn/post/7101973304960892964")

垃圾回收就是回收程序中不再使用的内存资源。因为这样的内存可以称为垃圾内存，所以回收这样的内存资源称为垃圾回收。

高级编程语言通常会使用手动和自动两种方式管理内存。C、C++ 以及 Rust 等编程语言使用手动的方式管理内存，也就是在代码中主动申请或者释放内存；而 Python、Ruby、Java 和 Go 等语言使用自动的内存管理系统，不需要主动释放垃圾内存。

### 常见的垃圾回收算法

1）引用计数

每个对象维护一个引用计数，当被引用对象被创建或被赋值给其他对象时，引用计数自动加 +1；当引用该对象的对象被销毁时，则计数 -1 ，当计数为 0 时，回收该对象。

-   优点：对象可以很快被回收，不会出现内存耗尽或到达阀值才回收。
-   缺点：不能很好的处理循环引用.

2）标记清除

标记清除（Mark-Sweep）算法是最常见的垃圾收集算法。标记清除的执行过程一般可以分成标记（Mark）和清除（Sweep）两个阶段：

-   标记阶段：从根对象出发查找并标记所有被引用的对象。
-   清除阶段：遍历堆中的全部对象，回收未被标记的对象占用的内存，并把回收的内存加入空闲链表。

标记清除解决了引用计数的缺点，但是在清除阶段需要 STW（stop the world），暂停用户程序。

3）分代收集

分代收集算法按照对象生命周期长短划分不同的代空间。简单来说，生命周期短的放入新生代空间，生命周期长的放入老年代空间。不同代有不同的回收算法和回收频率。

-   优点：回收性能好。
-   缺点：算法复杂。

### 三色标记

Go语言的垃圾回收使用了**三色标记清除法**。三色标记法将程序中的对象分成白色、黑色和灰色三类：

-   白色对象：潜在的垃圾，其内存可能会被垃圾收集器回收。
-   黑色对象：活跃的对象，从根对象可达的对象，不会被回收。
-   灰色对象：活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象。

当垃圾回收开始时，所有对象都认为是白色对象。

-   在标记阶段，所有根对象会被标记成灰色，并组成一个灰色对象集合。
    -   垃圾收集器从灰色对象集合中取出一个灰色对象标记为黑色，将该对象指向的所有对象都标记成灰色（加入灰色对象集合），保证该对象和被该对象引用的对象都不会被回收。
    -   当整个堆遍历完成时，灰色对象集合为空。此时，所有对象都被标记为黑色对象或白色对象，其中黑色对象为可达对象，白色对象为不可达对象。
-   在清除阶段，垃圾收集器可以回收白色对象占用的内存。

这个过程可以视为以灰色对象为波面，将黑色对象和白色对象分离，使波面不断向前推进，直到所有可达的灰色对象都变为黑色对象为止的过程。

### 根对象

根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：

1）全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。

2）执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。

3）寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。

### STW

为了避免用户程序可能在垃圾回收的过程中修改对象的指针，三色标记清除算法无法和用户程序并发运行，而是需要 STW，即暂停用户程序。STW对会影响用户程序的性能，但是Go语言目前已经可以做到STW在1ms以下。

在如下所示的三色标记过程中，用户程序建立了从 A 对象到 D 对象的引用，但是因为程序中已经不存在灰色对象了，所以 D 对象会被垃圾收集器错误地回收。

![image_FdermoYxuv](https://raw.githubusercontent.com/shengchaohua/my-images/main/images/202311252034243.png)

本来不应该被回收的对象却被回收了，这在内存管理中是非常严重的错误，我们将这种错误称为悬挂指针，即指针没有指向特定类型的合法对象，影响了内存的安全性。

### 内存屏障技术

内存屏障技术是一种屏障指令，它能够保证内存操作的顺序性，在内存屏障前执行的操作一定会先于内存屏障后执行的操作。

想要在并发或者增量的标记算法中保证正确性，我们需要达成以下两种三色不变性（Tri-color invariant）中的一种：

-   强三色不变性：黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象。
-   弱三色不变性：黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径。

只要遵循上述两个不变性中的任意一个，就能保证垃圾收集算法的正确性，而屏障技术就是在并发或者增量标记过程中保证三色不变性的重要技术。

屏障技术更像是一个钩子方法，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成读屏障（Read barrier）和写屏障（Write barrier）两种，因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。

Go 语言中使用的两种写屏障技术，分别是 Dijkstra 提出的插入写屏障和 Yuasa 提出的删除写屏障。

#### 插入写屏障

Dijkstra 在 1978 年提出了插入写屏障，通过如下所示的写屏障，用户程序和垃圾收集器可以在交替工作的情况下保证程序执行的正确性。

```纯文本
writePointer(slot, ptr):
    shade(ptr)
    *slot = ptr
```

上述插入写屏障的伪代码非常好理解，每当执行类似 `*slot = ptr` 的表达式时，我们会执行上述写屏障通过 `shade` 函数尝试改变指针的颜色。如果 `ptr` 指针是白色的，那么该函数会将该对象设置成灰色，其他情况则保持不变。

插入写屏障是一种相对保守的屏障技术，它会将**有存活可能的对象都标记成灰色**以满足强三色不变性。

插入写屏障虽然实现非常简单并且也能保证强三色不变性，但是它也有明显的缺点。因为栈上的对象在垃圾收集中也会被认为是根对象，所以为了保证内存的安全，Dijkstra 必须为栈上的对象增加写屏障或者在标记阶段完成重新对栈上的对象进行扫描

#### 删除写屏障

Yuasa 在 1990 年的论文 Real-time garbage collection on general-purpose machines 中提出了删除写屏障，因为一旦该写屏障开始工作，它会保证开启写屏障时堆上所有对象的可达，所以也被称作快照垃圾收集（Snapshot GC）。

该算法会使用如下所示的写屏障保证增量或者并发执行垃圾收集时程序的正确性：

```纯文本
writePointer(slot, ptr):
  shade(*slot)
  *slot = ptr
```

上述代码会在老对象的引用被删除时，将白色的老对象涂成灰色，这样删除写屏障就可以保证弱三色不变性，老对象引用的下游对象一定可以被灰色对象引用。

#### 混合写屏障

### 增量和并发

传统的垃圾收集算法会在垃圾收集的执行期间暂停应用程序，一旦触发垃圾收集，垃圾收集器会抢占 CPU 的使用权占据大量的计算资源以完成标记和清除工作，然而很多追求实时的应用程序无法接受长时间的 STW。

垃圾收集器一旦开始执行就会浪费大量的计算资源，为了减少应用程序暂停的最长时间和垃圾收集的总暂停时间，我们会使用下面的策略优化现代的垃圾收集器：

-   增量垃圾收集 — 增量地标记和清除垃圾，降低应用程序暂停的最长时间；
-   并发垃圾收集 — 利用多核的计算资源，在用户程序执行时并发标记和清除垃圾；

因为增量和并发两种方式都可以与用户程序交替运行，所以我们需要**使用屏障技术**保证垃圾收集的正确性；与此同时，应用程序也不能等到内存溢出时触发垃圾收集，因为当内存不足时，应用程序已经无法分配内存，这与直接暂停程序没有什么区别，增量和并发的垃圾收集需要提前触发并在内存不足前完成整个循环，避免程序的长时间暂停。

#### 增量收集器

增量式（Incremental）的垃圾收集是减少程序最长暂停时间的一种方案，它可以将原本时间较长的暂停时间切分成多个更小的 GC 时间片，虽然从垃圾收集开始到结束的时间更长了，但是这也减少了应用程序暂停的最大时间。

需要注意的是，增量式的垃圾收集需要与**三色标记法**一起使用，为了保证垃圾收集的正确性，我们需要在垃圾收集开始前打开写屏障，这样用户程序修改内存都会先经过写屏障的处理，保证了堆内存中对象关系的强三色不变性或者弱三色不变性。

虽然增量式的垃圾收集能够减少最大的程序暂停时间，但是增量式收集也会增加一次 GC 循环的总时间，在垃圾收集期间，因为写屏障的影响用户程序也需要承担额外的计算开销，所以增量式的垃圾收集也不是只带来好处的，但是总体来说还是利大于弊。

#### 并发收集器

并发（Concurrent）的垃圾收集不仅能够减少程序的最长暂停时间，还能减少整个垃圾收集阶段的时间，通过开启读写屏障、**利用多核优势与用户程序并行执行**，并发垃圾收集器确实能够减少垃圾收集对应用程序的影响。

虽然并发收集器能够与用户程序一起运行，但是并不是所有阶段都可以与用户程序一起运行，部分阶段还是需要暂停用户程序的，不过与传统的算法相比，并发的垃圾收集可以将能够并发执行的工作尽量并发执行；当然，因为读写屏障的引入，并发的垃圾收集器也一定会带来额外开销，不仅会增加垃圾收集的总时间，还会影响用户程序，这是我们在设计垃圾收集策略时必须要注意的。

### 垃圾回收的触发机制

垃圾回收的触发机制可以分为主动触发和被动触发。

主动触发是指在程序代码中调用 runtime.GC函数来触发垃圾回收。主动触发主要用于GC的性能测试和统计，不要使用生产代码中。

被动触发有两种情况：

1）内存分配量达到阈值

每次内存分配时都会检查当前内存分配量是否已达到阈值，如果达到阈值立即启动GC。内存分配量的阈值公式如下：

```text
阈值 = 上次GC时内存分配量 × 内存增长率
```

内存增长率由环境变量GOGC控制，默认为100，即每当内存扩大一倍时启动GC。

2）定期触发

默认情况下，最长2分钟触发一次GC，这个时间间隔可以通过 runtime.forcegcperiod变量设置。

### 演进过程

#### 并发垃圾收集

Go 语言在 v1.5 中引入了并发的垃圾收集器，该垃圾收集器使用了我们上面提到的三色抽象和写屏障技术保证垃圾收集器执行的正确性。

首先，并发垃圾收集器必须在合适的时间点触发垃圾收集循环。Go 语言的并发垃圾收集器会在扫描对象之前暂停程序做一些标记对象的准备工作，其中包括启动后台标记的垃圾收集器以及开启写屏障。

#### 混合写屏障

在 Go 语言 v1.7 版本之前，运行时会使用 Dijkstra 插入写屏障保证强三色不变性，但是运行时并没有在所有的垃圾收集根对象上开启插入写屏障。因为应用程序可能包含成百上千的 Goroutine，而垃圾收集的根对象一般包括全局变量和栈对象，如果运行时需要在几百个 Goroutine 的栈上都开启写屏障，会带来巨大的额外开销，所以 Go 团队在实现上选择了在标记阶段完成时**暂停程序、将所有栈对象标记为灰色并重新扫描**，在活跃 Goroutine 非常多的程序中，重新扫描的过程需要占用 10 \~ 100ms 的时间。

Go 语言在 v1.8 组合 Dijkstra 插入写屏障和 Yuasa 删除写屏障构成了如下所示的混合写屏障，该写屏障会**将被覆盖的对象标记成灰色并在当前栈没有扫描时将新对象也标记成灰色**：

```纯文本
writePointer(slot, ptr):
    shade(*slot)
    if current stack is grey:
        shade(ptr)
    *slot = ptr

```

为了移除栈的重扫描过程，除了引入混合写屏障之外，在垃圾收集的标记阶段，我们还需要**将创建的所有新对象都标记成黑色**，防止新分配的栈内存和堆内存中的对象被错误地回收，因为栈内存在标记阶段最终都会变为黑色，所以不再需要重新扫描栈空间。

## 内存逃逸

> [https://segmentfault.com/a/1190000040450335](https://segmentfault.com/a/1190000040450335 "https://segmentfault.com/a/1190000040450335")
> [https://driverzhang.github.io/post/golang内存分配逃逸分析/](https://driverzhang.github.io/post/golang内存分配逃逸分析/ "https://driverzhang.github.io/post/golang内存分配逃逸分析/")

在一段程序中，调用一个函数会由编译器在栈中分配一个栈桢，用于存放局部变量等数据，在函数运行结束后进行销毁。但是，如果编译器认为一个局部变量不适合在栈上分配内存，那么就会把这个变量在堆上分配，这种从"栈"上逃逸到"堆"上的现象可以称为内存逃逸。

-   栈内存分配速度非常快，函数返回直接释放，不会引起垃圾回收，对性能没有影响。
-   堆适合不可预知大小的内存分配，但是分配速度较慢，会引起垃圾回收。

在Go语言中，编译器会**在程序编译阶段**进行逃逸分析，根据代码中的数据流，决定哪些变量需要在栈中分配，哪些变量需要在堆上分配。

因为逃逸分析是在编译阶段进行的，那我们就可以通过`go build -gcflags '-m -m -l'`命令查看到逃逸分析的结果，其中`-l`表示禁用掉内联优化。

内存逃逸有好几种情况，接下来使用Go1.18.10版本进行介绍。

#### 指针逃逸

如果返回了局部变量的指针（地址），那么该变量必须在堆上分配内存。如果该变量在栈中分配内存，由于函数执行结束后，对应的栈桢会被销毁，在函数外部通过指针访问数据就会导致访问非法内存。

代码如下：

```go
package main

func main() {
  add(1, 2)
}

func add(x, y int) *int {
  res := x + y
  return &res
}
```

逃逸分析结果如下：

```bash
$ go build -gcflags="-m -m -l" main.go
# command-line-arguments
./main.go:8:2: res escapes to heap:
./main.go:8:2:   flow: ~r0 = &res:
./main.go:8:2:     from &res (address-of) at ./main.go:9:9
./main.go:8:2:     from return &res (return) at ./main.go:9:2
./main.go:8:2: moved to heap: res
```

#### 动态类型逃逸（不确定长度大小）

很多函数参数为interface类型，比如fmt.Println(a …interface{})，编译期间很难确定其参数的具体类型，也能产生逃逸。

代码如下：

```go
package main

import "fmt"

func main() {
  str := "golang"
  fmt.Printf("%v", str)
}

```

逃逸分析结果如下：

```bash
$ go build -gcflags="-m -m -l" main.go
# command-line-arguments
./main.go:7:13: str escapes to heap:
./main.go:7:13:   flow: {storage for ... argument} = &{storage for str}:
./main.go:7:13:     from str (spill) at ./main.go:7:13
./main.go:7:13:     from ... argument (slice-literal-element) at ./main.go:7:12
./main.go:7:13:   flow: {heap} = {storage for ... argument}:
./main.go:7:13:     from ... argument (spill) at ./main.go:7:12
./main.go:7:13:     from fmt.Printf("%v", ... argument...) (call parameter) at ./main.go:7:12
./main.go:7:12: ... argument does not escape
./main.go:7:13: str escapes to heap

```

str是main函数中的一个局部变量，传递给`fmt.Println()`函数后发生了逃逸，这是因为`fmt.Println()`函数的入参是一个`interface{}`类型，如果函数参数为`interface{}`，那么在编译期间就很难确定其参数的具体类型，也会发送逃逸。

#### 函数闭包引发内存逃逸

函数闭包会返回一个匿名函数。因为函数也是指针类型，所以匿名函数当作返回值时也发生了内存逃逸，其中使用的外部变量会一直存在直到匿名函数被销毁。

代码如下：

```go
package main

import "fmt"

func main() {
  in := increase()
  fmt.Println(in()) // 1
  fmt.Println(in()) // 2
}

func increase() func() int {
  n := 0
  return func() int {
    n++
    return n
  }
}
```

逃逸分析结果如下：

```bash
$ go build -gcflags="-m -m -l" main.go
# command-line-arguments
./main.go:12:2: increase capturing by ref: n (addr=false assign=true width=8)
./main.go:13:9: func literal escapes to heap:
./main.go:13:9:   flow: ~r0 = &{storage for func literal}:
./main.go:13:9:     from func literal (spill) at ./main.go:13:9
./main.go:13:9:     from return func literal (return) at ./main.go:13:2
./main.go:12:2: n escapes to heap:
./main.go:12:2:   flow: {storage for func literal} = &n:
./main.go:12:2:     from n (captured by a closure) at ./main.go:14:3
./main.go:12:2:     from n (reference) at ./main.go:14:3
./main.go:12:2: moved to heap: n
./main.go:13:9: func literal escapes to heap
./main.go:8:16: in() escapes to heap:
./main.go:8:16:   flow: {storage for ... argument} = &{storage for in()}:
./main.go:8:16:     from in() (spill) at ./main.go:8:16
./main.go:8:16:     from ... argument (slice-literal-element) at ./main.go:8:13
./main.go:8:16:   flow: {heap} = {storage for ... argument}:
./main.go:8:16:     from ... argument (spill) at ./main.go:8:13
./main.go:8:16:     from fmt.Println(... argument...) (call parameter) at ./main.go:8:13
./main.go:7:16: in() escapes to heap:
./main.go:7:16:   flow: {storage for ... argument} = &{storage for in()}:
./main.go:7:16:     from in() (spill) at ./main.go:7:16
./main.go:7:16:     from ... argument (slice-literal-element) at ./main.go:7:13
./main.go:7:16:   flow: {heap} = {storage for ... argument}:
./main.go:7:16:     from ... argument (spill) at ./main.go:7:13
./main.go:7:16:     from fmt.Println(... argument...) (call parameter) at ./main.go:7:13
./main.go:7:13: ... argument does not escape
./main.go:7:16: in() escapes to heap
./main.go:8:13: ... argument does not escape
./main.go:8:16: in() escapes to heap
```

#### 变量大小不确定及栈空间不足引发逃逸

先使用`ulimit -a`查看操作系统的栈空间：

```bash
~ ulimit -a
-t: cpu time (seconds)              unlimited
-f: file size (blocks)              unlimited
-d: data seg size (kbytes)          unlimited
-s: stack size (kbytes)             8192
-c: core file size (blocks)         0
-v: address space (kbytes)          unlimited
-l: locked-in-memory size (kbytes)  unlimited
-u: processes                       5568
-n: file descriptors                256
```

代码如下所示：

```go
package main

func main() {
  _ = make([]byte, 0, 10000)  // 10000 byte will not escape
  _ = make([]byte, 0, 100000) // 100000 byte will escape
}
```

逃逸分析结果如下：

```bash
$ go build -gcflags="-m -m -l" main.go
# command-line-arguments
./main.go:5:10: make([]byte, 0, 100000) escapes to heap:
./main.go:5:10:   flow: {heap} = &{storage for make([]byte, 0, 100000)}:
./main.go:5:10:     from make([]byte, 0, 100000) (too large for stack) at ./main.go:5:10
./main.go:4:10: make([]byte, 0, 10000) does not escape
./main.go:5:10: make([]byte, 0, 100000) escapes to heap
```

可以看到，当栈空间足够时，不会发生逃逸，但是当变量过大时，已经完全超过栈空间的大小时，将会发生逃逸。

#### 总结

关于堆区内存和栈区内存：

-   栈上分配内存比在堆中分配内存有更高的效率。
-   栈上分配的内存不需要GC处理。
-   堆上分配的内存使用完毕会交给GC处理。

逃逸分析在编译阶段完成，好处包括：

-   能够确定哪些变量可以分配在栈上，栈的分配比堆快，性能好（逃逸的局部变量会在堆上分配 ,而没有发生逃逸的则有编译器在栈上分配）。
-   能够减少GC的压力，不逃逸的对象分配在栈上，当函数返回时就回收了资源，不需要GC标记清除。
-   同步消除。如果你定义的对象的方法上有同步锁，但在运行时，却只有一个线程在访问，此时逃逸分析后的机器码，会去掉同步锁运行。

## 内存泄漏和内存溢出

> [https://www.hitzhangjie.pro/blog/2021-04-14-go程序内存泄露问题快速定位/](https://www.hitzhangjie.pro/blog/2021-04-14-go程序内存泄露问题快速定位/ "https://www.hitzhangjie.pro/blog/2021-04-14-go程序内存泄露问题快速定位/")

内存泄漏是指程序在申请和使用堆内存后，无法释放某些内存空间的情况。比如程序中有用不到的对象，占用着内存，无法释放。如果这样的对象越来越多，可用内存就会越来越少，最终会导致内存溢出。

内存溢出是指程序无法申请新的内存，导致程序出错。内存溢出通常是由于内存泄漏导致的，但是也有可能是机器内存过小，无法满足程序所需内存。

内存泄漏也可以分为“临时性”内存泄露和“永久性”内存泄露：

-   临时性泄露，指的是该释放的内存资源没有及时释放，对应的内存资源仍然有机会在更晚些时候被释放，即便如此在内存资源紧张情况下，也会是个问题。这类主要是string、slice底层buffer的错误共享，导致无用数据对象无法及时释放，或者defer函数导致的资源没有及时释放。
-   永久性泄露，指的是在进程后续生命周期内，泄露的内存都没有机会回收，如goroutine内部预期之外的`for-loop`或者`chan select-case`导致的无法退出的情况，导致协程栈及引用内存永久泄露问题。

### 内存泄漏的一些场景

> [https://gfw.go101.org/article/memory-leaking.html](https://gfw.go101.org/article/memory-leaking.html "https://gfw.go101.org/article/memory-leaking.html")

#### 子字符串造成的暂时性内存泄露

比如，一个包级别的字符串变量引用了一个局部的字符串变量，因为二者可能会共用相同的底层数据，导致局部变量无法释放。

代码如下：

```go
var globalStr string // 一个包级变量

func foo(str string) {
  globalStr = str[:50]
}

func demo() {
  s := string(make([]byte, 0, 10000))
  foo(s)
}
```

为了避免这种情况，需要手动复制字符串，如下所示：

```go
func foo2(str string) {
  var b strings.Builder
  b.Grow(50)
  b.WriteString(str[:50])
  globalStr = b.String()
}

```

#### 子切片造成的暂时性内存泄露

和上一个场景类似，子切片也可能会造成暂时性的内存泄露。

在下面这段代码中，当函数`g`被调用之后，globalSlice会引用`s1`的部分数据，导致s1占用的内存得不到释放。

```go
var globalSlice []int

func g(s1 []int) {
  globalSlice = s1[len(s1)-30:]
}
```

为了避免这种情况，需要复制切片，如下所示：

```go
func g(s1 []int) {
  s0 = make([]int, 30)
  copy(s0, s1[len(s1)-30:])
}

```

#### 协程被永久阻塞而造成的永久性内存泄露

一个程序中的某些协程会永久处于阻塞状态。 Go运行时并不会将处于永久阻塞状态的协程杀掉，因此永久处于阻塞状态的协程所占用的资源将永得不到释放。

Go运行时出于两个原因并不杀掉处于永久阻塞状态的协程。 一是有时候Go运行时很难分辨出一个处于阻塞状态的协程是永久阻塞还是暂时性阻塞；二是有时我们可能故意永久阻塞某些协程。

#### 因为没有停止不再使用的time.Ticker值而造成的永久性内存泄露

当一个time.Timer值不再被使用，一段时间后它将被自动垃圾回收掉。 但对于一个不再使用的time.Ticker值，我们必须调用它的Stop方法结束它，否则它将永远不会得到回收。

#### 延迟调用导致的暂时性内存泄露

如果一个defer调用被放在了循环中，那么这些调用会累积起来，直到整个函数结束才会被执行。

代码如下：

```go
func demo(files []string) error {
  for _, file := range files {
    f, err := os.Open(file)
    if err != nil {
      return err
    }
    defer f.Close() // might leak memory

    fmt.Println("reading file", f)
  }

  return nil
}
```

### 如何排查内存泄漏

> [https://www.hitzhangjie.pro/blog/2021-04-14-go程序内存泄露问题快速定位/](https://www.hitzhangjie.pro/blog/2021-04-14-go程序内存泄露问题快速定位/ "https://www.hitzhangjie.pro/blog/2021-04-14-go程序内存泄露问题快速定位/")

#### 借助pprof排查

go提供了pprof工具方便对运行中的go程序进行采样分析，支持对多种类型的采样分析：

-   goroutine - stack traces of all current goroutines
-   heap - a sampling of all heap allocations
-   threadcreate - stack traces that led to the creation of new OS threads
-   block - stack traces that led to blocking on synchronization primitives
-   mutex - stack traces of holders of contended mutexes
-   profile - cpu profile
-   trace - allows collecting all the profiles for a certain duration

# 15. 内置模块
