[TOC]

# 前言
> [最硬核的操作系统常见问题总结！](https://gitee.com/SnailClimb/JavaGuide/blob/master/docs/operating-system/basis.md)


# 基础
## 什么是操作系统
1. 操作系统（Operating System，OS）是管理计算机硬件与软件资源的程序，是计算机系统的内核与基石；
1. 操作系统本质上是运行在计算机上的软件程序 ；
1. 操作系统为用户提供一个与系统交互的操作界面 ；
1. 操作系统分内核与外壳（我们可以把外壳理解成围绕着内核的应用程序，而内核就是能操作硬件的程序）。


## 什么是系统调用
根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：
- 用户态（user mode）：用户态运行的进程可以直接读取用户程序的数据。
- 内核态（kernel mode）：内核态运行的进程或程序可以访问计算机的绝大部分资源，不受限制。

我们运行的程序基本都是运行在用户态，如果要调用操作系统提供的系统态级别的子功能，就需要借助系统调用！

也就是说，在我们运行的用户程序中，凡是与系统态级别的资源有关的操作，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

这些系统调用按功能大致可分为如下几类：
- 设备管理。完成设备的请求或释放，以及设备启动等功能。
- 文件管理。完成文件的读、写、创建及删除等功能。
- 进程控制。完成进程的创建、撤销、阻塞及唤醒等功能。
- 进程通信。完成进程之间的消息传递或信号传递等功能。
- 内存管理。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。


# 进程与线程
## 进程和线程的区别
进程是程序的一次执行过程，是系统运行程序、分配资源的基本单位。

线程是系统调度的基本单位。线程存在于进程中，一个进程中至少有一个线程。一个进程中的多个线程能够共享进程的堆和方法区等资源，每个线程有自己私有的程序计数器、虚拟机栈和本地方法栈。

线程和进程最大的不同在于基本上各进程是独立的，而各线程则不一定，因为同一进程中的线程极有可能会相互影响。线程执行开销小，但不利于资源的管理和保护；而进程正相反。


## 进程的生命周期和状态
一般把进程大致分为5种状态：
- 创建状态（new）：进程正在被创建，尚未到就绪状态。
- 就绪状态（ready）：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- 运行状态（running）：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- 阻塞状态（waiting）：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- 结束状态（terminated）：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。


## 进程间通信
> [《进程间通信 IPC (InterProcess Communication)》](https://www.jianshu.com/p/c1015f5ffa74)

进程间通信的方式：
- 管道/匿名管道（Pipes）：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。只存在于内存中的文件。
- 有名管道（Named Pipes）：匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循先进先出(first in first out)。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。
- 信号（Signal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
- 消息队列（Message Queuing）：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道不同的是消息队列存放在内核中，只有在内核重启或者显示地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取，也可以按消息的类型读取。比FIFO更有优势。消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺。
- 信号量（Semaphores）：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。
- 共享内存（Shared memory）：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。
- 套接字（Sockets）：此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持TCP/IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。


## 进程的调度算法
进程的调度算法是为了决定进程执行的顺序，以实现最大 CPU 利用率。

进程调度算法有：
- 先到先服务（FCFS）：从就绪队列中选择最先进入队列的进程分配资源并执行，使它一直执行到完成或发生某事件而被阻塞放弃占用CPU，再重新调度。
- 短作业优先（SJF）：从就绪队列中选出一个估计运行时间最短的进程分配资源并执行，使它一直执行到完成或发生某事件而被阻塞放弃占用CPU，再重新调度。
- 时间片轮转：时间片轮转调度是一种最古老、最简单、使用最广泛的算法。每个进程被分配一个时间段，称作时间片，即该进程允许运行的时间。
- 多级反馈队列：前面介绍的几种进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业迅速完成，因次被认为是一种较好的进程调度算法，UNIX操作系统采取的便是这种调度算法。
- 优先级调度：为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以FCFS方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。


## 线程间的同步方式
线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：

- 互斥量（Mutex）：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
- 信号量（Semphares）：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
- 事件（Event）：通过通知操作的方式来保持多线程同步，比如Java中的Wait/Notify机制。


## 互斥锁和自旋锁
互斥锁（mutex lock）：最常使用于线程同步的锁；标记用来保证在任一时刻，只能有一个线程访问该对象，同一线程多次加锁操作会造成死锁；临界区和互斥量都可用来实现此锁，通常情况下锁操作失败会将该线程睡眠等待锁释放时被唤醒。

在多任务操作系统中，同时运行的多个任务可能都需要使用同一种资源。互斥锁是一种简单的加锁的方法来控制对共享资源的访问，互斥锁只有两种状态,即上锁( lock )和解锁( unlock )。
1. 原子性：把一个互斥量锁定为一个原子操作，这意味着操作系统（或pthread函数库）保证了如果一个线程锁定了一个互斥量，没有其他线程在同一时间可以成功锁定这个互斥量；
2. 唯一性：如果一个线程锁定了一个互斥量，在它解除锁定之前，没有其他线程可以锁定这个互斥量；
3. 非繁忙等待：如果一个线程已经锁定了一个互斥量，第二个线程又试图去锁定这个互斥量，则第二个线程将被挂起（不占用任何cpu资源），直到第一个线程解除对这个互斥量的锁定为止，第二个线程则被唤醒并继续执行，同时锁定这个互斥量。

自旋锁（spin lock）：同样用来标记只能有一个线程访问该对象，在同一线程多次加锁操作会造成死锁；使用硬件提供的swap指令或test_and_set指令实现；同互斥锁不同的是在锁操作需要等待的时候并不是睡眠等待唤醒，而是循环检测保持者已经释放了锁，互斥量阻塞后休眠让出cpu，而自旋锁阻塞后不会让出CPU，会一直忙等待，直到得到锁。这样做的好处是节省了线程从睡眠状态到唤醒之间内核会产生的消耗，在加锁时间短暂的环境下这点会提高很大效率。适用于锁的持有时间比较短。


# 内存管理
## 内存管理的主要工作
操作系统的内存管理主要负责内存的分配与回收，还有把逻辑地址转换成相应的物理地址。

## 内存管理机制
内存管理机制可以分为连续分配管理方式和非连续分配管理方式。连续分配管理方式是指为一个用户程序分配一块连续的内存空间，比如块式管理 。非连续分配管理方式允许一个程序使用的内存分布在不相邻的内存中，比如页式管理、段式管理。

内存管理机制的具体方式：
1. 块式管理：远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，如果程序运行需要内存的话，操作系统就分配一块。如果一个程序只需要很小的空间，分配的一块内存很大一部分几乎被浪费了。在每个块中未被利用的空间，称之为碎片。
2. 页式管理：把主存分为大小相等且固定的一页一页的形式，页比较小，相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
3. 段式管理：页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，段是有实际意义的，每个段定义了一组逻辑信息，比如有主程序段MAIN、子程序段X、数据段及栈段等。 段式管理通过段表对应逻辑地址和物理地址。
4. 段页式管理机制。段页式管理机制结合了段式管理和页式管理的优点。简单来说，段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 段页式管理机制 中段与段之间以及段的内部的都是离散的。


## 分页机制和分段机制的共同点和区别
共同点 ：
- 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
- 页和段都是离散存储的，两者都是离散分配内存的方式，但是每个页和段中的内存是连续的。

区别 ：
- 页的大小是固定的，由操作系统决定；段的大小不固定，取决于当前运行的程序。
- 分页仅仅是为了满足操作系统内存管理的需求；段是具有逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好地满足用户的需要。


## 逻辑地址和物理地址
编程一般只和逻辑地址打交道，比如在C语言中，指针里面存储的地址就是逻辑地址，逻辑地址由操作系统决定。逻辑地址地址也称为虚拟地址。物理地址指的是真实物理内存中地址，具体一点就是内存地址或寄存器地址。物理地址是内存单元真正的地址。

现代处理器使用的是一种称为虚拟寻址的寻址方式。使用虚拟寻址，CPU需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。实际上完成虚拟地址转换为物理地址转换的硬件是内存管理单元。

为什么要有虚拟地址？如果没有虚拟地址空间的时候，程序都是直接访问和操作的都是物理地址，可能会引发一些问题，比如：
- 用户程序可以访问任意内存，甚至修改操作系统的内存空间，这样可能会破坏操作系统，造成操作系统崩溃。
- 想要同时运行多个程序特别困难，因为不同程序分配的物理地址容易重复，影响程序运行。

总结来说，如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。

通过虚拟地址访问内存有以下优势：
- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存不够时，内存管理器会将物理内存页保存到磁盘文件。
- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。


# 缓存
> [《大话处理器》Cache一致性协议之MESI](https://blog.csdn.net/muxiqingyang/article/details/6615199)

==TODO==


# 虚拟内存
## 什么是虚拟内存
虚拟内存是计算机系统内存管理的一种技术，它为每个进程提供了一个私有的地址空间，让每个进程以为拥有一个连续的内存空间。虚拟内存的重要意义是它定义了一个连续的虚拟地址空间，能有效地管理内存并减少出错。

> 虚拟内存 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM）的使用也更有效率。目前，大多数操作系统都使用了虚拟内存，如 Windows 家族的“虚拟内存”；Linux 的“交换空间”等。


## 局部性原理
要想更好地理解虚拟内存技术，必须要知道计算机中著名的局部性原理。局部性原理表现在以下两个方面：
- 时间局部性 ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
- 空间局部性 ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。


## 虚拟内存器
由于虚拟内存，计算机好像为用户提供了一个比实际内存大的多的存储器——虚拟存储器。

基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。

虚拟内存同样是一种时间换空间的策略，你用CPU的计算时间，页的调入调出花费的时间，换来了一个虚拟的更大的空间来支持程序的运行。不得不感叹，程序世界几乎不是时间换空间就是空间换时间。


## 虚拟内存的实现技术
虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。

虚拟内存的实现有以下三种方式：
- 请求分页存储管理：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
- 请求分段存储管理：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
- 请求段页式存储管理：


## 页面置换算法
虚拟地址映射为物理地址的过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断。缺页中断就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。在这个时候，被内存映射的文件实际上成了一个分页交换文件。

当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。页面置换算法用来选择淘汰哪一个内存中的页，置换算法包括：
- 最佳页面置换算法：该算法选择的被淘汰页面是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。由于无法预知进程哪个页面是在最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- 先进先出页面置换算法（FIFO，First In First Out）：该算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- 最近最久未使用页面置换算法（LRU，Least Currently Used）：该算法给每个页面设置一个访问时间，访问一次，更新一次时间。淘汰一个页面时，选择现有页面中访问时间最早的，即最近最久未使用的页面。
- 最少使用页面置换算法（LFU，Least Frequently Used）：该算法选择使用最少的页面作为淘汰页。


# IO
## 阻塞非阻塞与同步异步的区别？
> [怎样理解阻塞非阻塞与同步异步的区别？](https://www.zhihu.com/question/19732473/answer/20851256)

同步和异步关注的是消息通信机制，也可以称为同步/异步通信（synchronous/asynchronous communication）。所谓**同步**，就是调用者发出一个调用，在没有得到结果之前，该调用就不返回。但是一旦调用返回，调用者就得到返回结果了。换句话说，调用者主动等待这个调用返回结果。**异步**则相反，调用者发出一个调用之后，这个调用就直接返回了，没有返回结果。换句话说，调用者不会立刻得到结果，而是在调用返回后，被调用者通过状态来通知调用者，或通过回调函数处理这个调用。

阻塞和非阻塞关注的是程序（或线程）在等待调用返回结果时的状态。**阻塞**调用是指调用返回结果之前，调用者所处的程序会被挂起，只有在得到结果之后才会恢复运行。**非阻塞**调用是指在调用不能立刻得到结果之前，调用者所处的程序不会发生阻塞，可以先去做其他事情。


# Linux
## 常用命令
查看进程：ps

查看线程：ps/top -H

查看服务器性能、资源使用情况：top

查看磁盘：df/du

杀死进程：kill -s 9

查看监听的IP和端口：netstat -ano | find /i "listening"

统计一个文件中指定字符串出现次数：cat xxx | grep "xxx" | wc -l

